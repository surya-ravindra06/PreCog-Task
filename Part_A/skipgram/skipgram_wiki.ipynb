{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:22:21.818087Z",
     "iopub.status.busy": "2024-07-29T08:22:21.817843Z",
     "iopub.status.idle": "2024-07-29T08:22:24.736285Z",
     "shell.execute_reply": "2024-07-29T08:22:24.732468Z",
     "shell.execute_reply.started": "2024-07-29T08:22:21.818058Z"
    },
    "id": "TsUSZYWDVfrT",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mImportError\u001b[0m\u001b[0;31m:\u001b[0m cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages for CBOW\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import matutils\n",
    "from numpy import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:30.649243Z",
     "iopub.status.busy": "2024-07-29T08:27:30.648767Z",
     "iopub.status.idle": "2024-07-29T08:27:30.718723Z",
     "shell.execute_reply": "2024-07-29T08:27:30.718088Z",
     "shell.execute_reply.started": "2024-07-29T08:27:30.649211Z"
    },
    "id": "u9LSU559Vfrb",
    "outputId": "14669060-3418-4346-d580-0117fd98e9c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print device name: get_device_name()\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:30.864970Z",
     "iopub.status.busy": "2024-07-29T08:27:30.864329Z",
     "iopub.status.idle": "2024-07-29T08:27:30.869785Z",
     "shell.execute_reply": "2024-07-29T08:27:30.869214Z",
     "shell.execute_reply.started": "2024-07-29T08:27:30.864938Z"
    },
    "id": "CYPn_r-lVfrd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from file and store list of sentences where sentences are list of words\n",
    "class MakeSentences():\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.sentences = self.read_file()\n",
    "\n",
    "    def read_file(self):\n",
    "        sentences = []\n",
    "        with open(self.file_name, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                sentences += ([x for x in line.strip().split('.') if x!=''])\n",
    "                i+=1\n",
    "                if i==10000:\n",
    "                    break\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:49.883882Z",
     "iopub.status.busy": "2024-07-29T08:27:49.883398Z",
     "iopub.status.idle": "2024-07-29T08:27:49.910859Z",
     "shell.execute_reply": "2024-07-29T08:27:49.910200Z",
     "shell.execute_reply.started": "2024-07-29T08:27:49.883846Z"
    },
    "id": "DoQ5VEj1Vfre",
    "outputId": "1de5aa09-7e62-4347-d065-c89b9a6cc67d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25137\n"
     ]
    }
   ],
   "source": [
    "sentences = MakeSentences('/projects/rtelidevara/pk/Part_A/wikitext-2-raw-v1/wikitext-2-raw/wiki.train.raw').sentences\n",
    "print(len(sentences))\n",
    "# for sentence in sentences:\n",
    "#     print(type(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d52Gzvk1Vfrf"
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:50.980099Z",
     "iopub.status.busy": "2024-07-29T08:27:50.979657Z",
     "iopub.status.idle": "2024-07-29T08:27:50.991549Z",
     "shell.execute_reply": "2024-07-29T08:27:50.990900Z",
     "shell.execute_reply.started": "2024-07-29T08:27:50.980066Z"
    },
    "id": "wZSwLzufVfrh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class Preprocess():\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def tokenize(self):\n",
    "        # Split sentences into words using regex to handle various punctuation\n",
    "        self.sentences = [re.findall(r'\\b\\w+\\b', sentence.lower()) for sentence in self.sentences]\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.sentences = [[word.lower() for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_stop_words(self):\n",
    "        # Common English stop words; expand as necessary\n",
    "        stop_words = set([\"the\", \"is\", \"at\", \"which\", \"on\", \"and\", \"a\", \"an\"])\n",
    "        self.sentences = [[word for word in sentence if word not in stop_words] for sentence in self.sentences]\n",
    "\n",
    "    def stemmer(self):\n",
    "        # Simple stemming using suffix stripping, can be improved\n",
    "        def simple_stem(word):\n",
    "            suffixes = [\"ing\", \"ly\", \"ed\", \"ious\", \"ies\", \"ive\", \"es\", \"s\", \"ment\"]\n",
    "            for suffix in sorted(suffixes, key=len, reverse=True):\n",
    "                if word.endswith(suffix):\n",
    "                    return word[:-len(suffix)]\n",
    "            return word\n",
    "        self.sentences = [[simple_stem(word) for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        self.sentences = [[word for word in sentence if word.isalpha()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        self.sentences = [[word for word in sentence if not word.isdigit()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_single_letter(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 1] for sentence in self.sentences]\n",
    "\n",
    "    def remove_extra_spaces(self):\n",
    "        self.sentences = [[word for word in sentence if word.strip()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_less_than_3(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 2] for sentence in self.sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:51.204846Z",
     "iopub.status.busy": "2024-07-29T08:27:51.204296Z",
     "iopub.status.idle": "2024-07-29T08:27:52.478548Z",
     "shell.execute_reply": "2024-07-29T08:27:52.477868Z",
     "shell.execute_reply.started": "2024-07-29T08:27:51.204816Z"
    },
    "id": "XmmPEsYnVfrj",
    "outputId": "7feb2815-90d9-40dd-881c-bd9365ab8ea8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done\n",
      "25137\n"
     ]
    }
   ],
   "source": [
    "# preprocess\n",
    "preprocess = Preprocess(sentences)\n",
    "preprocess.tokenize()\n",
    "# print(preprocess.sentences)\n",
    "preprocess.lowercase()\n",
    "preprocess.remove_stop_words()\n",
    "# preprocess.stemmer()\n",
    "preprocess.remove_punctuation()\n",
    "preprocess.remove_numbers()\n",
    "preprocess.remove_single_letter()\n",
    "preprocess.remove_extra_spaces()\n",
    "preprocess.remove_less_than_3()\n",
    "\n",
    "print(\"Preprocessing done\")\n",
    "# print(preprocess.sentences)\n",
    "sentences = preprocess.sentences\n",
    "print(len(sentences))\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is4d8bsdVfrk"
   },
   "source": [
    "### Create word index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:52.480270Z",
     "iopub.status.busy": "2024-07-29T08:27:52.479923Z",
     "iopub.status.idle": "2024-07-29T08:27:52.621476Z",
     "shell.execute_reply": "2024-07-29T08:27:52.620827Z",
     "shell.execute_reply.started": "2024-07-29T08:27:52.480241Z"
    },
    "id": "KSmnCYN8Vfrl",
    "outputId": "a7948c87-a65d-4d95-baa9-ce7d23033d42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab:  30214\n",
      "Most common words:  [('was', 5340), ('that', 3928), ('for', 3841), ('with', 3758), ('from', 2329), ('his', 2328), ('were', 1987), ('had', 1638), ('are', 1262), ('her', 1248)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten list of sentences into list of words\n",
    "word_list = list(itertools.chain.from_iterable(sentences))\n",
    "# print(word_list)\n",
    "\n",
    "# Create a vocabulary of words\n",
    "word_freq = Counter(word_list)\n",
    "\n",
    "# Remove words that occur less than 5 times\n",
    "vocab = set(word if word_freq[word] > 0 else '<unk>' for word in word_list)\n",
    "# print(vocab)\n",
    "\n",
    "# Add padding and unknown token to vocab\n",
    "vocab.add('<pad>')\n",
    "vocab.add('<unk>')\n",
    "# Add start and end token to vocab\n",
    "vocab.add('<start>')\n",
    "vocab.add('<end>')\n",
    "\n",
    "# Print length of vocab\n",
    "print(\"Size of vocab: \", len(vocab))\n",
    "\n",
    "# Create word to index and index to word mapping\n",
    "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx:word for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Print most common words\n",
    "print(\"Most common words: \", word_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:52.622908Z",
     "iopub.status.busy": "2024-07-29T08:27:52.622410Z",
     "iopub.status.idle": "2024-07-29T08:27:52.626122Z",
     "shell.execute_reply": "2024-07-29T08:27:52.625533Z",
     "shell.execute_reply.started": "2024-07-29T08:27:52.622877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2251\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(word_to_idx['intelligent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmEx5qHlVfrm"
   },
   "source": [
    "### Create dataset (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:52.627851Z",
     "iopub.status.busy": "2024-07-29T08:27:52.627608Z",
     "iopub.status.idle": "2024-07-29T08:27:52.694199Z",
     "shell.execute_reply": "2024-07-29T08:27:52.693326Z",
     "shell.execute_reply.started": "2024-07-29T08:27:52.627825Z"
    },
    "id": "8Zg7mU3eVfrn",
    "outputId": "5fe9954a-9c82-446f-a3bb-b45c2cb58c3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# define constants\n",
    "window_size = 2\n",
    "sliding_window = 2 * window_size + 1\n",
    "num_neg_samples = 1\n",
    "# print(sentences)\n",
    "\n",
    "# sentences = [sentences[0]]\n",
    "# print(sentences)\n",
    "def select_negative_samples(target_word, num_window_size, unigram_table):\n",
    "    negative_samples = []\n",
    "    while len(negative_samples) < 2*num_window_size:\n",
    "        sampled_word = random.choice(unigram_table)  # unigram_table is precomputed based on the distribution\n",
    "        if sampled_word != target_word:\n",
    "            negative_samples.append(sampled_word)\n",
    "    return negative_samples\n",
    "\n",
    "def create_unigram_table(vocab, table_size=len(vocab)):\n",
    "    unigram_table = []\n",
    "    total_count_power = sum([count**0.75 for count in vocab.values()])\n",
    "    for word, count in vocab.items():\n",
    "        p_wi = (count**0.75) / total_count_power\n",
    "        # Fill the table with the index of the word\n",
    "        unigram_table.extend([word] * int(p_wi * table_size))\n",
    "    return unigram_table\n",
    "\n",
    "unigram_table = create_unigram_table(word_freq)\n",
    "# print(unigram_table)\n",
    "\n",
    "def get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_sample , vocab , unigram_table):\n",
    "    X = []\n",
    "    y = []\n",
    "    for sentence in sentences:\n",
    "        # add start and end token to sentence\n",
    "        sentence = ['<start>'] + sentence + ['<end>']\n",
    "        for i in range(len(sentence)):\n",
    "            context_word = sentence[i]\n",
    "            # print(\"target word: \", target_word)\n",
    "            target_words = []\n",
    "            temp1 = max(0,i - window_size)\n",
    "            temp2 = min(len(sentence)-1,i + window_size + 1)\n",
    "            # print(\"temp1: \", temp1)\n",
    "            # print(\"temp2: \", temp2)\n",
    "            for j in range(max(0,i - window_size),min(len(sentence)-1,i + window_size)+1):\n",
    "                if j != i:\n",
    "                    # print(sentence[j])\n",
    "                    target_words.append(sentence[j])\n",
    "                # print(\"context words: \", context_words)\n",
    "\n",
    "\n",
    "            # pad context words if length is less than sliding window\n",
    "            if len(target_words) < sliding_window:\n",
    "                target_words += ['<pad>'] * (sliding_window - len(target_words)-1)\n",
    "\n",
    "            target_words.append(context_word)\n",
    "            # print(\"length of target words: \", len(target_words))\n",
    "\n",
    "            # get positive samples\n",
    "            positive_samples = [word_to_idx[word] if word in vocab else word_to_idx['<unk>'] for word in target_words]\n",
    "            # print(\"lenght of positive samples: \", len(positive_samples))\n",
    "\n",
    "            X.append(positive_samples)\n",
    "            y.append(1)\n",
    "\n",
    "\n",
    "            # get negative samples\n",
    "            for i in range(num_neg_samples):\n",
    "                negative_samples = select_negative_samples(context_word, window_size, unigram_table)\n",
    "                negative_samples = [word_to_idx[word] if word in vocab else word_to_idx['<unk>'] for word in negative_samples]\n",
    "                negative_samples += [word_to_idx['<pad>']] * (sliding_window - len(negative_samples)-1)\n",
    "                negative_samples.append(word_to_idx[context_word])\n",
    "                X.append(negative_samples)\n",
    "                y.append(0)\n",
    "                # print(\"length of negative samples: \", len(negative_samples))\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:52.695818Z",
     "iopub.status.busy": "2024-07-29T08:27:52.695454Z",
     "iopub.status.idle": "2024-07-29T08:27:57.412540Z",
     "shell.execute_reply": "2024-07-29T08:27:57.411695Z",
     "shell.execute_reply.started": "2024-07-29T08:27:52.695787Z"
    },
    "id": "AcdYWIpNVfrp",
    "outputId": "e5873b2f-3f9f-4f90-8664-565a90b83efe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating samples\n",
      "[17959, 11551, 16418, 4112, 28683]\n",
      "1\n",
      "Samples created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating samples\")\n",
    "X, y = get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_samples, vocab, unigram_table)\n",
    "print(X[2])\n",
    "print(y[2])\n",
    "print(\"Samples created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:27:57.414160Z",
     "iopub.status.busy": "2024-07-29T08:27:57.413790Z",
     "iopub.status.idle": "2024-07-29T08:28:02.051896Z",
     "shell.execute_reply": "2024-07-29T08:28:02.050784Z",
     "shell.execute_reply.started": "2024-07-29T08:27:57.414127Z"
    },
    "id": "eGsJePZmVfrq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "data = list(zip(X,y))\n",
    "random.shuffle(data)\n",
    "X,y = zip(*data)\n",
    "\n",
    "# Turn into numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:02.053665Z",
     "iopub.status.busy": "2024-07-29T08:28:02.053250Z",
     "iopub.status.idle": "2024-07-29T08:28:02.140364Z",
     "shell.execute_reply": "2024-07-29T08:28:02.139699Z",
     "shell.execute_reply.started": "2024-07-29T08:28:02.053629Z"
    },
    "id": "yWqUDDJFVfrr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save X and y\n",
    "np.save('/projects/rtelidevara/pk/Part_A/skipgram/datasets/wikiskip_X_25k.npy', X)\n",
    "np.save('/projects/rtelidevara/pk/Part_A/skipgram/datasets/wikiskip_y_25k.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:02.142800Z",
     "iopub.status.busy": "2024-07-29T08:28:02.142470Z",
     "iopub.status.idle": "2024-07-29T08:28:02.228709Z",
     "shell.execute_reply": "2024-07-29T08:28:02.227768Z",
     "shell.execute_reply.started": "2024-07-29T08:28:02.142771Z"
    },
    "id": "LXnZMdQVVfrs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load X and y\n",
    "X = np.load('/projects/rtelidevara/pk/Part_A/skipgram/datasets/wikiskip_X_25k.npy')\n",
    "y = np.load('/projects/rtelidevara/pk/Part_A/skipgram/datasets/wikiskip_y_25k.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8vrxSIcVfrt"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:02.230022Z",
     "iopub.status.busy": "2024-07-29T08:28:02.229757Z",
     "iopub.status.idle": "2024-07-29T08:28:02.238089Z",
     "shell.execute_reply": "2024-07-29T08:28:02.237549Z",
     "shell.execute_reply.started": "2024-07-29T08:28:02.229994Z"
    },
    "id": "gnjj1fWUVfrt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the forward pass for SkipGram\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # self.embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # extract context and target from x\n",
    "        context = x[:, :-1]\n",
    "        input = x[:, -1]\n",
    "\n",
    "        context_embedding = self.embeddings(context)\n",
    "        input_embedding = self.embeddings(input)\n",
    "\n",
    "        # Dot product between each context embedding and input embedding to get batch_size*context_size*embedding_dim\n",
    "\n",
    "        dot_products = torch.bmm(context_embedding, input_embedding.unsqueeze(2))  # [batch_size, context_length, 1]\n",
    "        sum_dot_products = torch.sum(dot_products, dim=1)  # [batch_size, 1]\n",
    "\n",
    "        # Squeeze the last dimension to get the final scores\n",
    "        scores = sum_dot_products.squeeze(1)  # [batch_size]\n",
    "\n",
    "        return F.sigmoid(scores)\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        out = self.embeddings.weight.data\n",
    "        return out.cpu().numpy()\n",
    "\n",
    "    def get_word_embedding(self, word):\n",
    "        # If word is not in vocab, return unk\n",
    "        if word not in word_to_idx:\n",
    "            word = '<unk>'\n",
    "        word_tensor = torch.LongTensor([word_to_idx[word]])\n",
    "        word_tensor = word_tensor.to(next(self.parameters()).device)\n",
    "        out = self.embeddings(word_tensor).data\n",
    "        return out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:02.239082Z",
     "iopub.status.busy": "2024-07-29T08:28:02.238852Z",
     "iopub.status.idle": "2024-07-29T08:28:03.276226Z",
     "shell.execute_reply": "2024-07-29T08:28:03.275405Z",
     "shell.execute_reply.started": "2024-07-29T08:28:02.239056Z"
    },
    "id": "NwIXaXXUVfru",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 250\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Create model, loss function and optimizer\n",
    "model = SkipGram(vocab_size, embedding_dim)\n",
    "model.to(device)\n",
    "# Cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define dataloader\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(X).long(), torch.from_numpy(y).float())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:03.278314Z",
     "iopub.status.busy": "2024-07-29T08:28:03.277585Z",
     "iopub.status.idle": "2024-07-29T08:28:03.353739Z",
     "shell.execute_reply": "2024-07-29T08:28:03.353099Z",
     "shell.execute_reply.started": "2024-07-29T08:28:03.278271Z"
    },
    "id": "n-f6rzzXVfrv",
    "outputId": "95e1d396-4b8b-4e19-b7ac-fbeb4f77e5b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20374,  6984,  4112,  4112, 17959],\n",
      "        [19458,  5062,  3148,  6701, 15265],\n",
      "        [17371, 21346, 28682, 14761, 22087],\n",
      "        [ 8316,   190,  9880, 15951, 12122],\n",
      "        [17288, 24502, 18371,  7186, 29631],\n",
      "        [ 5698, 12693,  6708, 19806, 19245],\n",
      "        [ 5062, 14879, 25084, 16924, 12536],\n",
      "        [  750, 12241,  9286, 21153, 24736],\n",
      "        [14045,  5027, 22664, 17633, 10803],\n",
      "        [30089, 14531, 19024, 11509, 28096],\n",
      "        [17959, 29907,  4112,  4112, 10803],\n",
      "        [ 4926, 21722,  4112,  4112, 17959],\n",
      "        [24928, 10588,  1553, 26038, 16624],\n",
      "        [19361, 21757,  5062, 18719, 29357],\n",
      "        [ 3892,  2311, 16948,  6090,  5062],\n",
      "        [ 5320, 21117, 22574,  1082, 14764],\n",
      "        [14147, 29392,  2776, 14147,  2796],\n",
      "        [ 5698, 13870, 15270, 11713, 12390],\n",
      "        [16398,  8463,  5160, 17837, 15560],\n",
      "        [17959, 20886, 17906, 10803, 24622],\n",
      "        [17959,  3398,  8373,  4112, 14159],\n",
      "        [17837, 25483, 27546, 24928,  3398],\n",
      "        [12184, 16169, 21717, 20008, 18513],\n",
      "        [15270,  7315, 28716, 18023, 14010],\n",
      "        [ 8070,  5020, 10185,  1467,  5983],\n",
      "        [ 1225,  2776, 15231, 27179, 10185],\n",
      "        [  874,  3398,  6832,  1748,  1271],\n",
      "        [12403, 28425, 10803,  4112, 28660],\n",
      "        [ 2928, 13280,  3505, 13910, 11317],\n",
      "        [13107, 10226,  2310, 15656, 11353],\n",
      "        [ 2838, 30089,  2823, 11304,  5972],\n",
      "        [13625, 20077, 24273, 23426, 17959],\n",
      "        [11698, 25438, 25084, 12536,  8518],\n",
      "        [19379, 14965, 26547,  7789, 26266],\n",
      "        [19740, 18621, 26746, 24371,  2182],\n",
      "        [ 5391,  3398,  2964, 22732, 28027],\n",
      "        [ 1886, 19169,  4112,  4112, 10803],\n",
      "        [   45, 14717,  4503,  6353, 23990],\n",
      "        [17959, 26694, 23990,  4112, 29525],\n",
      "        [ 3280, 26099, 21495, 16590,  3398],\n",
      "        [ 1154, 20438,  1154,  7380,  7719],\n",
      "        [25490,  9131,  5996, 15533,  6138],\n",
      "        [ 8227, 26432,  2310, 24118,  5698],\n",
      "        [14544, 14696, 10125, 21754, 14986],\n",
      "        [16372, 25241,  9914, 28803, 17959],\n",
      "        [20704, 22098, 29392, 11854, 17959],\n",
      "        [11430, 13367, 24663, 20656,  6039],\n",
      "        [10185,  5029,  8692, 16169, 12536],\n",
      "        [19628, 19164, 14637,  1696,   294],\n",
      "        [13556, 10630, 10660, 28478, 12417],\n",
      "        [20113, 21579, 13587, 13402, 29396],\n",
      "        [23134, 15029, 12288, 24820, 20957],\n",
      "        [28503,  7913, 24599, 20113, 27284],\n",
      "        [27107, 22292,  4207,  2182, 29530],\n",
      "        [10261, 28582, 12850, 29405,  5062],\n",
      "        [11037, 25201, 19806, 13736, 22574],\n",
      "        [14132,  5084, 23772, 14861,  4302],\n",
      "        [10630,  6984,  5062,   300, 20679],\n",
      "        [23360, 17936,  6115,  1467, 24273],\n",
      "        [19314, 20650, 21146, 25218, 10803],\n",
      "        [15565, 11047, 10567, 12536, 28683],\n",
      "        [22748, 27224,  2930, 16017,  6504],\n",
      "        [ 5062, 29417,  6690, 23348,  8294],\n",
      "        [ 6969, 16091, 16406, 10803, 25953],\n",
      "        [25734, 23003,   750,  4782, 20231],\n",
      "        [ 3922, 16575, 16941,  5062,   935],\n",
      "        [28086,  1993, 26273, 21015, 10597],\n",
      "        [ 4868, 17944, 15108,  3652, 17959],\n",
      "        [18613, 17147, 22903, 12635, 10803],\n",
      "        [15951, 14908, 22240, 19883,  7789],\n",
      "        [17959, 13935, 23278,  4112,  3398],\n",
      "        [18594, 16227,  8177, 26977, 17959],\n",
      "        [10841, 15570, 17148, 13975, 26129],\n",
      "        [23080,  8171, 11584,  1433,  9111],\n",
      "        [11534,  8505, 21015, 14040,  5983],\n",
      "        [20113, 17837, 10803,  4112, 14601],\n",
      "        [15713,  3505, 25457,  6003,   547],\n",
      "        [14010, 14546, 14492, 25201,  3398],\n",
      "        [17537, 20510,  3583, 20835,   416],\n",
      "        [ 5511, 13890,  6587, 28294, 26988],\n",
      "        [17959, 12536, 15507,  4112,  6905],\n",
      "        [11876,  1044, 29095, 28192, 22451],\n",
      "        [17959, 13395,  9407,  4112, 18925],\n",
      "        [13828,   839,  5221,  5204, 24761],\n",
      "        [ 6914,   296, 24928, 11420, 17959],\n",
      "        [ 4576, 17002, 10803,  4112, 18146],\n",
      "        [  750,  4503, 14637,  8041, 28890],\n",
      "        [18602,  8505, 22164,  6733, 12699],\n",
      "        [27746,  3398,  5062,  1736,  2906],\n",
      "        [11622, 29723, 20542,  6770, 14834],\n",
      "        [12850, 28099, 25093, 23664, 17553],\n",
      "        [24757, 28553,  4112,  4112, 10803],\n",
      "        [ 5062, 20682, 26545, 15981, 17959],\n",
      "        [18337, 14684, 14678, 20387, 14334],\n",
      "        [ 4863, 19806, 29991, 26038, 27890],\n",
      "        [ 5062, 13322,  8182, 10803, 20076],\n",
      "        [27002, 12785, 19673, 24982, 28820],\n",
      "        [ 7060, 29449, 15210, 14102, 17728],\n",
      "        [ 2282,   128, 20878, 29626, 23827],\n",
      "        [21015, 11033,  7841, 17956, 14834],\n",
      "        [14294,  9027, 24391,  5733, 27766],\n",
      "        [23004,  3262, 13622, 21013,  1847],\n",
      "        [26048,  5143,  1648,  8130, 19806],\n",
      "        [10630,  3571, 16528, 16933, 23851],\n",
      "        [  846,  9519,  7283, 17727, 10803],\n",
      "        [ 6587, 27730, 26025, 20720, 20758],\n",
      "        [12536, 27140, 19474, 30060, 16244],\n",
      "        [24273, 19971, 26375,  9407, 17959],\n",
      "        [23990, 28503,  4112,  4112, 17959],\n",
      "        [ 4118, 14339, 23957, 11346, 17959],\n",
      "        [ 3476,  5455,  8524, 17321, 17959],\n",
      "        [  411, 16794,  9486,  1277, 18602],\n",
      "        [17592, 12617, 25714,  5204, 18254],\n",
      "        [ 9407, 19314,  5698, 15659, 24811],\n",
      "        [ 3583, 26891,  3076, 22748, 28264],\n",
      "        [14274, 13322, 13322,  5128, 12428],\n",
      "        [ 6984,  4576, 24297, 28503, 22880],\n",
      "        [22748,  1538,  6376, 28398, 10803],\n",
      "        [12536,   324, 10803,  4112, 12660],\n",
      "        [19224, 12536, 17933, 25201, 10612],\n",
      "        [10660, 10395,  4352,  9805,  3968],\n",
      "        [18278,  2310, 10803,  4112, 20720],\n",
      "        [ 2054, 13729, 27140, 27335, 21985],\n",
      "        [15057, 27849,  5062, 18853,  3892],\n",
      "        [ 4392, 18886, 28428,  6535, 17959],\n",
      "        [27296, 25646, 15077, 29351, 27292],\n",
      "        [13684, 16794, 18593,   834,  1884],\n",
      "        [15503,   548,  4615,  5132,  5698]])\n",
      "tensor([1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Check dataset\n",
    "for i, (inputs, targets) in enumerate(dataloader):\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:03.355033Z",
     "iopub.status.busy": "2024-07-29T08:28:03.354680Z",
     "iopub.status.idle": "2024-07-29T08:28:03.361343Z",
     "shell.execute_reply": "2024-07-29T08:28:03.360784Z",
     "shell.execute_reply.started": "2024-07-29T08:28:03.355004Z"
    },
    "id": "baDqgCJMVfrw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train SkipGram model\n",
    "def train(model, criterion, optimizer, dataloader, epochs):\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        labels = []\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # get predictions\n",
    "            preds = [1 if x > 0.5 else 0 for x in outputs]\n",
    "            train_preds.extend(preds)\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            labels.extend(targets)\n",
    "        \n",
    "        train_loss /= len(dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Epoch: \", epoch+1, \"Loss: \", train_loss)\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:28:03.362631Z",
     "iopub.status.busy": "2024-07-29T08:28:03.362148Z",
     "iopub.status.idle": "2024-07-29T08:34:16.629903Z",
     "shell.execute_reply": "2024-07-29T08:34:16.629069Z",
     "shell.execute_reply.started": "2024-07-29T08:28:03.362604Z"
    },
    "id": "heiTsqTEVfrw",
    "outputId": "1c2f3430-9fe4-4293-ed21-b86f60608fd3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  19.377816736449454\n",
      "Epoch:  2 Loss:  15.425116831470431\n",
      "Epoch:  3 Loss:  13.469231214576372\n",
      "Epoch:  4 Loss:  12.325349500845801\n",
      "Epoch:  5 Loss:  11.525228786410477\n",
      "Epoch:  6 Loss:  10.903555735344682\n",
      "Epoch:  7 Loss:  10.41192080969605\n",
      "Epoch:  8 Loss:  10.023455788719472\n",
      "Epoch:  9 Loss:  9.708742364930178\n",
      "Epoch:  10 Loss:  9.447700829101372\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_losses = train(model, criterion, optimizer, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:16.631626Z",
     "iopub.status.busy": "2024-07-29T08:34:16.631240Z",
     "iopub.status.idle": "2024-07-29T08:34:16.636043Z",
     "shell.execute_reply": "2024-07-29T08:34:16.635484Z",
     "shell.execute_reply.started": "2024-07-29T08:34:16.631592Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot train accuracy\n",
    "def plot_train_losses(train_losses):\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Train Loss')\n",
    "    plt.title('Train Loss vs Epochs')\n",
    "    plt.savefig('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/plots/skip_train_losses.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:16.637784Z",
     "iopub.status.busy": "2024-07-29T08:34:16.636877Z",
     "iopub.status.idle": "2024-07-29T08:34:16.886439Z",
     "shell.execute_reply": "2024-07-29T08:34:16.885842Z",
     "shell.execute_reply.started": "2024-07-29T08:34:16.637749Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call function to plot train accuracy\n",
    "plot_train_losses(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:16.887914Z",
     "iopub.status.busy": "2024-07-29T08:34:16.887349Z",
     "iopub.status.idle": "2024-07-29T08:34:16.995005Z",
     "shell.execute_reply": "2024-07-29T08:34:16.994316Z",
     "shell.execute_reply.started": "2024-07-29T08:34:16.887883Z"
    },
    "id": "7Zd_ROK9c_Lj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/partA_pth/skipgram_25k_250_001.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:16.996538Z",
     "iopub.status.busy": "2024-07-29T08:34:16.996042Z",
     "iopub.status.idle": "2024-07-29T08:34:17.114890Z",
     "shell.execute_reply": "2024-07-29T08:34:17.114251Z",
     "shell.execute_reply.started": "2024-07-29T08:34:16.996506Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipGram(\n",
       "  (embeddings): Embedding(30214, 250)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = SkipGram(vocab_size, embedding_dim)\n",
    "model.load_state_dict(torch.load('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/partA_pth/skipgram_25k_250_001.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.116460Z",
     "iopub.status.busy": "2024-07-29T08:34:17.115873Z",
     "iopub.status.idle": "2024-07-29T08:34:17.131900Z",
     "shell.execute_reply": "2024-07-29T08:34:17.131313Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.116429Z"
    },
    "id": "QsC8hX0WVfrx",
    "outputId": "9e2cf61f-7206-4730-8f2b-7158d489a760",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
      "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
      "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
      "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
      "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
      "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
      "\n",
      "   SimAssoc333  SD(SimLex)  \n",
      "0            1        0.41  \n",
      "1            1        0.67  \n",
      "2            1        1.19  \n",
      "3            1        2.18  \n",
      "4            1        0.93  \n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "# Load into dataframe\n",
    "df = pd.read_csv('../SimLex-999/SimLex-999.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.135752Z",
     "iopub.status.busy": "2024-07-29T08:34:17.135398Z",
     "iopub.status.idle": "2024-07-29T08:34:17.138915Z",
     "shell.execute_reply": "2024-07-29T08:34:17.138382Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.135724Z"
    },
    "id": "_pfU1jobVfry",
    "outputId": "88935fb9-aabe-403b-ff21-f2f65f8663b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart\n"
     ]
    }
   ],
   "source": [
    "# Print 2nd row word1\n",
    "print(df['word1'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.140041Z",
     "iopub.status.busy": "2024-07-29T08:34:17.139694Z",
     "iopub.status.idle": "2024-07-29T08:34:17.153829Z",
     "shell.execute_reply": "2024-07-29T08:34:17.153300Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.140014Z"
    },
    "id": "ACaFnePdVfry",
    "outputId": "6dde4fcb-1ee9-4b27-9ea6-59d16be2372f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 250)\n",
      "(250,)\n",
      "[-1.5358365   0.05137305 -0.4908331  -0.16647385  0.93517655  0.43104717\n",
      " -0.32810932  0.6541595   0.41588026  1.0162601   0.6652014   0.47509214\n",
      " -0.11213211  2.8427708   1.4588454  -0.70051247 -0.6000427   0.2805503\n",
      " -0.48067024 -0.33536616  1.4367045  -1.2524589   0.00317763  1.3812842\n",
      " -0.25874364  0.48225957  0.07318012  0.77316105 -0.609945   -0.50662476\n",
      "  1.7377322   0.6862923  -0.34714907  1.3125672   0.4656059   0.90382487\n",
      "  0.71483123 -0.3091026   0.2813525  -0.8590123  -0.86166525 -1.3092524\n",
      " -0.81069756 -0.38326034  1.4355015   0.28166535  1.1205599  -0.2971966\n",
      " -0.28286907  0.3531304  -0.6691736  -0.92634517 -0.85368043  1.0277278\n",
      " -0.44134557 -0.8840528   1.0057528  -0.42734897 -0.92878807  1.1038818\n",
      " -0.17799468  1.3747474   0.73067987 -0.82195944  0.30636337  0.31339073\n",
      " -1.1388446   0.18408062  1.5731115   0.39216235 -0.7458719   1.5357684\n",
      " -0.50700176  0.72557974 -0.27191088  0.69531065  0.48785332  0.6060374\n",
      "  1.2687219   1.3156883   1.3612874   0.9399939  -1.1282781   0.2705017\n",
      " -1.6178012   1.6810286   1.2068831   0.7844688  -0.13893585  0.70845854\n",
      " -0.96114284  0.15441786 -1.0867064   0.40630254 -0.88866955 -0.07433597\n",
      " -0.6337586  -0.41531083 -1.8605658  -0.7420222   0.04002112  1.3197603\n",
      " -0.6184637   0.6394157   1.062158    0.08591347 -0.17077053  1.5928673\n",
      "  0.95936966 -0.24282442 -1.0780275  -3.095343    0.85429543  2.668273\n",
      "  0.2848641  -0.26071554  1.3850002   0.27769962 -0.30901596 -0.6241721\n",
      "  0.12067589  1.450806   -0.64729947  0.4707349   0.3229422   0.36339\n",
      "  0.41056395 -1.3050506  -0.56991214 -1.2008538   1.4847845  -1.0458614\n",
      " -2.4732068   0.46309215  1.8810337   1.271937   -0.39447412 -0.9576202\n",
      " -0.81509864 -0.20157418 -1.74889    -1.4295363   0.7330742   0.20224\n",
      " -0.20793965 -1.4538792  -0.00928969 -0.6697394  -0.24796642 -0.01212403\n",
      " -0.04973057 -0.5794609   1.3887198   0.9030832  -0.85772216  0.36216456\n",
      " -2.4176235  -0.9660711   0.30996832  0.54694766 -0.3606663  -0.581295\n",
      "  0.6491501  -0.08886632 -1.3232998  -0.5431966   0.25778893  0.15930104\n",
      "  0.0343503  -0.74725217  0.14962333 -0.31073582 -1.6725893   0.684912\n",
      " -1.0608522  -0.9091776  -0.13298294  1.4423167   0.30498382 -1.3390137\n",
      "  0.43470934 -0.1460424  -0.8424937   0.5680177   0.8221381  -0.63507175\n",
      "  0.8245252  -0.1324117   1.7218169  -0.17770694 -1.439425    0.13398427\n",
      "  0.6143259   0.49864194 -0.03875958  0.4885986  -0.26285073 -2.2404675\n",
      " -0.23607427 -0.6500336  -0.5123469   0.82446885 -0.6765221   0.18820505\n",
      " -0.810622    1.6134065  -0.68215436 -0.5975373   1.1892056   0.35205916\n",
      "  0.66927135  0.155285   -0.06873947  0.9849406  -0.65653443  1.0091571\n",
      " -1.362232    0.8019415  -0.11513878 -1.2573414  -0.06126234 -0.23893061\n",
      "  0.6223426   1.5235611   0.27279752 -0.03128862 -1.3001449   0.4789312\n",
      "  0.98216134  0.32065073  0.46748522  0.7962869  -0.83282274 -0.01161625\n",
      "  0.02709927  0.68062943 -0.9316332  -0.8573321   2.0031614   0.25842026\n",
      "  0.18895563  0.35747182  0.09437636 -0.21799682  1.8949097  -0.9609442\n",
      "  0.40820283 -0.4895081   0.80954945  0.67359686]\n"
     ]
    }
   ],
   "source": [
    "# Get word embeddings\n",
    "sample_embedding = model.get_word_embedding(df['word1'][1])\n",
    "print(sample_embedding.shape)\n",
    "sample_embedding = sample_embedding.squeeze()\n",
    "print(sample_embedding.shape)\n",
    "print(sample_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.154929Z",
     "iopub.status.busy": "2024-07-29T08:34:17.154593Z",
     "iopub.status.idle": "2024-07-29T08:34:17.161607Z",
     "shell.execute_reply": "2024-07-29T08:34:17.161067Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.154903Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check similarity between two words\n",
    "word1 = df['word1'][1]\n",
    "word2 = df['word1'][1]\n",
    "\n",
    "# Use gensim or any other model to get word embeddings\n",
    "w1 = model.get_word_embedding(word1).squeeze()\n",
    "w2 = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "print(type(w1))\n",
    "\n",
    "# Calculate cosine similarity using numpy\n",
    "def unitvec(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "sim = np.dot(unitvec(w1), unitvec(w2))\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.162833Z",
     "iopub.status.busy": "2024-07-29T08:34:17.162356Z",
     "iopub.status.idle": "2024-07-29T08:34:17.170930Z",
     "shell.execute_reply": "2024-07-29T08:34:17.170421Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.162806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to check if word is in vocab\n",
    "def check_vocab(word):\n",
    "    if word in vocab:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.172098Z",
     "iopub.status.busy": "2024-07-29T08:34:17.171674Z",
     "iopub.status.idle": "2024-07-29T08:34:17.181987Z",
     "shell.execute_reply": "2024-07-29T08:34:17.181477Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.172072Z"
    },
    "id": "XUOiHPqcVfrz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get cosine similarity\n",
    "import numpy as np\n",
    "\n",
    "def cos_similarity(word1_embedding, word2_embedding):\n",
    "    def unitvec(vec):\n",
    "        return vec / np.linalg.norm(vec)\n",
    "\n",
    "    ans = np.dot(unitvec(word1_embedding), unitvec(word2_embedding))\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Function to get Pearson correlation\n",
    "def pearson_correlation(word1_embedding, word2_embedding):\n",
    "    emb1 = np.array(word1_embedding)\n",
    "    emb2 = np.array(word2_embedding)\n",
    "\n",
    "    correlation, _ = pearsonr(emb1, emb2)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.183142Z",
     "iopub.status.busy": "2024-07-29T08:34:17.182745Z",
     "iopub.status.idle": "2024-07-29T08:34:17.194062Z",
     "shell.execute_reply": "2024-07-29T08:34:17.193551Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.183116Z"
    },
    "id": "7upp-39oVfr0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_sim(df, model, lemmatizer, stemmer):\n",
    "    cosine_similarity_scores = []\n",
    "    pearson_correlation_scores = []\n",
    "    simlex_scores = []\n",
    "    not_in_vocab = 0\n",
    "  \n",
    "    for _, row in df.iterrows():\n",
    "        word1 = row['word1']\n",
    "        word2 = row['word2']\n",
    "        form = row['POS']\n",
    "        form = form.lower()\n",
    "       \n",
    "        # Check if word is in vocab\n",
    "        if not check_vocab(word1) or not check_vocab(word2):\n",
    "            not_in_vocab += 1\n",
    "\n",
    "        # Get embeddings\n",
    "        word1_embedding = model.get_word_embedding(word1).squeeze()\n",
    "        word2_embedding = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "        # Get cosine similarity\n",
    "        cosine_similarity_scores.append(cos_similarity(word1_embedding, word2_embedding))\n",
    "        \n",
    "        # Get pearson correlation\n",
    "        pearson_correlation_scores.append(pearson_correlation(word1_embedding, word2_embedding))\n",
    "\n",
    "        # Get simlex score\n",
    "        simlex_scores.append(row['SimLex999'])\n",
    "        \n",
    "    return cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:17.195146Z",
     "iopub.status.busy": "2024-07-29T08:34:17.194810Z",
     "iopub.status.idle": "2024-07-29T08:34:18.653904Z",
     "shell.execute_reply": "2024-07-29T08:34:18.653213Z",
     "shell.execute_reply.started": "2024-07-29T08:34:17.195119Z"
    },
    "id": "017GL4PjVfr0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cosine similarity and pearson correlation scores\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab = test_sim(df, model, lemmatizer, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.655557Z",
     "iopub.status.busy": "2024-07-29T08:34:18.654927Z",
     "iopub.status.idle": "2024-07-29T08:34:18.659129Z",
     "shell.execute_reply": "2024-07-29T08:34:18.658571Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.655522Z"
    },
    "id": "ZzTVRgyvX-Tu",
    "outputId": "5979a4ee-9fe0-4689-fc7f-0a80860c17b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Check cosine similarity and pearson correlation scores\n",
    "print(type(cosine_similarity_scores))\n",
    "print(type(pearson_correlation_scores))\n",
    "print(type(simlex_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.660266Z",
     "iopub.status.busy": "2024-07-29T08:34:18.659910Z",
     "iopub.status.idle": "2024-07-29T08:34:18.670454Z",
     "shell.execute_reply": "2024-07-29T08:34:18.669809Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.660239Z"
    },
    "id": "y09A6xWTYArg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funtcion to get spearman correlation using cosine similarity scores\n",
    "def spearman_correlation(cosine_similarity_scores, simlex_scores):\n",
    "    # Scale cosine similarity scores to 0-10\n",
    "    cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "    cosine_similarity_scores = (1+cosine_similarity_scores)*5\n",
    "    simlex_scores = np.array(simlex_scores)\n",
    "\n",
    "    correlation, _ = spearmanr(cosine_similarity_scores, simlex_scores)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.671635Z",
     "iopub.status.busy": "2024-07-29T08:34:18.671188Z",
     "iopub.status.idle": "2024-07-29T08:34:18.683734Z",
     "shell.execute_reply": "2024-07-29T08:34:18.683170Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.671608Z"
    },
    "id": "kiOl-gKHYDQw",
    "outputId": "af2ae4c8-a077-4630-c9d3-046c3fdf5465",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Spearman correlation Sim:  -0.05085695870408465\n"
     ]
    }
   ],
   "source": [
    "# Print the initial spearman correlation\n",
    "spearman_value_sim = spearman_correlation(cosine_similarity_scores, simlex_scores)\n",
    "\n",
    "print(\"Initial Spearman correlation Sim: \", spearman_value_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.684927Z",
     "iopub.status.busy": "2024-07-29T08:34:18.684488Z",
     "iopub.status.idle": "2024-07-29T08:34:18.691929Z",
     "shell.execute_reply": "2024-07-29T08:34:18.691399Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.684900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points not in vocab:  128\n"
     ]
    }
   ],
   "source": [
    "# Print the number of data points not in vocab\n",
    "print(\"Number of data points not in vocab: \", not_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.693095Z",
     "iopub.status.busy": "2024-07-29T08:34:18.692689Z",
     "iopub.status.idle": "2024-07-29T08:34:18.708991Z",
     "shell.execute_reply": "2024-07-29T08:34:18.708432Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.693068Z"
    },
    "id": "vmxDwm3gYGWL",
    "outputId": "0a9ffc8e-9e2d-459b-bee1-803b86fe90e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0    old          new   A       1.58        7.25          -0.036983   \n",
      "1  smart  intelligent   A       9.20        7.11           0.077122   \n",
      "2   hard    difficult   A       8.77        5.94           0.018874   \n",
      "3  happy     cheerful   A       9.55        5.85          -0.058335   \n",
      "4   hard         easy   A       0.95        5.82           0.156685   \n",
      "\n",
      "   Pearson Correlation  \n",
      "0            -0.039171  \n",
      "1             0.078803  \n",
      "2             0.019935  \n",
      "3            -0.058580  \n",
      "4             0.154234  \n"
     ]
    }
   ],
   "source": [
    "# Make a dataframe of cosine similarity scores and pearson correlation scores along with Simlex-999 scores and Assoc(USF)\n",
    "simlex_scores = df['SimLex999']\n",
    "assoc_scores = df['Assoc(USF)']\n",
    "cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "pearson_correlation_scores = np.array(pearson_correlation_scores)\n",
    "simlex_scores = np.array(simlex_scores)\n",
    "assoc_scores = np.array(assoc_scores)\n",
    "# print(cosine_similarity_scores.shape)\n",
    "# print(pearson_correlation_scores.shape)\n",
    "\n",
    "# Make a dataframe along with word1, word2, POS, SimLex-999 scores, Assoc(USF), cosine similarity scores and pearson correlation scores\n",
    "datat = {'word1': df['word1'], 'word2': df['word2'], 'POS': df['POS'], 'SimLex999': simlex_scores, 'Assoc(USF)': assoc_scores, 'Cosine Similarity': cosine_similarity_scores, 'Pearson Correlation': pearson_correlation_scores}\n",
    "ndf = pd.DataFrame(data=datat)\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.710200Z",
     "iopub.status.busy": "2024-07-29T08:34:18.709782Z",
     "iopub.status.idle": "2024-07-29T08:34:18.721150Z",
     "shell.execute_reply": "2024-07-29T08:34:18.720604Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.710173Z"
    },
    "id": "Ig5Adsa7YIro",
    "outputId": "4e079f74-c2ab-43dd-b1ae-b70ec8a3c759",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0       old          new   A       1.58        7.25          -0.036983   \n",
      "1     smart  intelligent   A       9.20        7.11           0.077122   \n",
      "2      hard    difficult   A       8.77        5.94           0.018874   \n",
      "3     happy     cheerful   A       9.55        5.85          -0.058335   \n",
      "4      hard         easy   A       0.95        5.82           0.156685   \n",
      "..      ...          ...  ..        ...         ...                ...   \n",
      "994    join      acquire   V       2.85        0.00          -0.032211   \n",
      "995    send       attend   V       1.67        0.00           0.069109   \n",
      "996  gather       attend   V       4.80        0.00          -0.097130   \n",
      "997  absorb     withdraw   V       2.97        0.00           0.053648   \n",
      "998  attend       arrive   V       6.08        0.00          -0.007084   \n",
      "\n",
      "     Pearson Correlation  \n",
      "0              -0.039171  \n",
      "1               0.078803  \n",
      "2               0.019935  \n",
      "3              -0.058580  \n",
      "4               0.154234  \n",
      "..                   ...  \n",
      "994            -0.032829  \n",
      "995             0.069114  \n",
      "996            -0.095870  \n",
      "997             0.056251  \n",
      "998            -0.007857  \n",
      "\n",
      "[999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print df\n",
    "print(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10G686jpYLa7"
   },
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.722489Z",
     "iopub.status.busy": "2024-07-29T08:34:18.721947Z",
     "iopub.status.idle": "2024-07-29T08:34:18.727919Z",
     "shell.execute_reply": "2024-07-29T08:34:18.727305Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.722459Z"
    },
    "id": "FVuLgyQ5YPiP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "def create_dataset(df, model):\n",
    "    # Create a list of tuples\n",
    "    emb1 = []\n",
    "    emb2 = []\n",
    "    simlex_scores = []\n",
    "    assoc_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "            word1 = row['word1']\n",
    "            word2 = row['word2']\n",
    "            emb1.append(torch.tensor(model.get_word_embedding(word1).squeeze()))\n",
    "            emb2.append(torch.tensor(model.get_word_embedding(word2).squeeze()))\n",
    "            simlex_scores.append(row['SimLex999'])\n",
    "            assoc_scores.append(row['Assoc(USF)'])\n",
    "\n",
    "    # print(emb1[0].shape)\n",
    "    emb1_stack = torch.stack(emb1)\n",
    "    emb2_stack = torch.stack(emb2)\n",
    "\n",
    "    return emb1_stack, emb2_stack, torch.tensor(simlex_scores, dtype=torch.float), torch.tensor(assoc_scores, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:18.729335Z",
     "iopub.status.busy": "2024-07-29T08:34:18.728781Z",
     "iopub.status.idle": "2024-07-29T08:34:19.110796Z",
     "shell.execute_reply": "2024-07-29T08:34:19.110131Z",
     "shell.execute_reply.started": "2024-07-29T08:34:18.729307Z"
    },
    "id": "VX-9UOKGYQq0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call create_dataset\n",
    "train_df, test_df = train_test_split(ndf, test_size=0.1, random_state=42)\n",
    "train_emb1, train_emb2, train_simlex_scores, train_assoc_scores = create_dataset(train_df, model)\n",
    "test_emb1, test_emb2, test_simlex_scores, test_assoc_scores = create_dataset(test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.112109Z",
     "iopub.status.busy": "2024-07-29T08:34:19.111780Z",
     "iopub.status.idle": "2024-07-29T08:34:19.115606Z",
     "shell.execute_reply": "2024-07-29T08:34:19.115061Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.112080Z"
    },
    "id": "wv_-44vYYUrT",
    "outputId": "4d52e675-c1c9-4983-d6a3-67fcec246f31",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([899, 250])\n",
      "torch.Size([899])\n"
     ]
    }
   ],
   "source": [
    "# check train_emb1\n",
    "print(train_emb1.shape)\n",
    "print(train_simlex_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.116804Z",
     "iopub.status.busy": "2024-07-29T08:34:19.116369Z",
     "iopub.status.idle": "2024-07-29T08:34:19.126258Z",
     "shell.execute_reply": "2024-07-29T08:34:19.125728Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.116776Z"
    },
    "id": "I9YI_RUpYZ4F",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creare TensorDataset\n",
    "train_dataset = torch.utils.data.TensorDataset(train_emb1, train_emb2, train_simlex_scores, train_assoc_scores)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_emb1, test_emb2, test_simlex_scores, test_assoc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.127416Z",
     "iopub.status.busy": "2024-07-29T08:34:19.127045Z",
     "iopub.status.idle": "2024-07-29T08:34:19.137342Z",
     "shell.execute_reply": "2024-07-29T08:34:19.136822Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.127389Z"
    },
    "id": "-SLh3kMMYbEM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.138555Z",
     "iopub.status.busy": "2024-07-29T08:34:19.138080Z",
     "iopub.status.idle": "2024-07-29T08:34:19.149790Z",
     "shell.execute_reply": "2024-07-29T08:34:19.149268Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.138528Z"
    },
    "id": "ajZzT_bwYhoC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class that takes CBOW embeddings, and outputs similarity scores: loss is MSE between predicted similarity scores and actual similarity scores(Simlex-999)\n",
    "# We're basically optimizing these weights over here used to produce this score out of 10, minimizing the distance between this score and the simlex score.\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2*embedding_dim, 50)\n",
    "        self.linear2 = nn.Linear(50, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        # emb1 = emb1.squeeze()\n",
    "        # emb2 = emb2.squeeze()\n",
    "        emb = torch.cat((emb1, emb2), dim=1)\n",
    "\n",
    "        out = self.linear1(emb)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # Project the output between 0 and 10\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out*10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.150961Z",
     "iopub.status.busy": "2024-07-29T08:34:19.150520Z",
     "iopub.status.idle": "2024-07-29T08:34:19.161690Z",
     "shell.execute_reply": "2024-07-29T08:34:19.161164Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.150933Z"
    },
    "id": "g-9VMxgiYkWc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dim = 250\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize model\n",
    "lmodel = RegressionModel(embedding_dim).to(device)\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(lmodel.parameters(), lr=learning_rate, weight_decay=0.01) # weight_decay is L2 regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.162766Z",
     "iopub.status.busy": "2024-07-29T08:34:19.162454Z",
     "iopub.status.idle": "2024-07-29T08:34:19.173824Z",
     "shell.execute_reply": "2024-07-29T08:34:19.173290Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.162741Z"
    },
    "id": "6h_RY03MYnhj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train model\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for emb1, emb2, simlex_scores, assoc_scores in train_loader:\n",
    "            emb1 = emb1.to(device)\n",
    "            emb2 = emb2.to(device)\n",
    "            simlex_scores = simlex_scores.to(device)\n",
    "            assoc_scores = assoc_scores.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(emb1, emb2)\n",
    "\n",
    "            simlex_scores = simlex_scores.unsqueeze(1)\n",
    "            # print(outputs[0])\n",
    "            loss = criterion(outputs, simlex_scores)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(\"Epoch: {}, Train_Loss: {}\".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:19.175006Z",
     "iopub.status.busy": "2024-07-29T08:34:19.174581Z",
     "iopub.status.idle": "2024-07-29T08:34:20.472598Z",
     "shell.execute_reply": "2024-07-29T08:34:20.471957Z",
     "shell.execute_reply.started": "2024-07-29T08:34:19.174979Z"
    },
    "id": "-yhHpOiLYswb",
    "outputId": "26d3b0df-260a-4d4e-f540-3c5bd789c0e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_Loss: 8.02236820089406\n",
      "Epoch: 2, Train_Loss: 5.965077918434823\n",
      "Epoch: 3, Train_Loss: 5.031144234012759\n",
      "Epoch: 4, Train_Loss: 4.480747850889145\n",
      "Epoch: 5, Train_Loss: 3.8353834656516086\n",
      "Epoch: 6, Train_Loss: 3.466308196754426\n",
      "Epoch: 7, Train_Loss: 2.96922486801244\n",
      "Epoch: 8, Train_Loss: 3.0436085194620928\n",
      "Epoch: 9, Train_Loss: 2.6714784596510093\n",
      "Epoch: 10, Train_Loss: 2.496807610488991\n",
      "Epoch: 11, Train_Loss: 2.091494006517874\n",
      "Epoch: 12, Train_Loss: 2.0270237402875995\n",
      "Epoch: 13, Train_Loss: 1.7742764356381586\n",
      "Epoch: 14, Train_Loss: 1.7704875695385018\n",
      "Epoch: 15, Train_Loss: 1.5307422062024216\n",
      "Epoch: 16, Train_Loss: 1.6630876303413296\n",
      "Epoch: 17, Train_Loss: 1.448501004024137\n",
      "Epoch: 18, Train_Loss: 1.5298689464468993\n",
      "Epoch: 19, Train_Loss: 1.3944883012899696\n",
      "Epoch: 20, Train_Loss: 1.3797388620216577\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train(lmodel, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:20.473904Z",
     "iopub.status.busy": "2024-07-29T08:34:20.473555Z",
     "iopub.status.idle": "2024-07-29T08:34:20.480431Z",
     "shell.execute_reply": "2024-07-29T08:34:20.479886Z",
     "shell.execute_reply.started": "2024-07-29T08:34:20.473875Z"
    },
    "id": "iUU1Go8aYwoM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to test model, Calculate test loss and Spearman correlation\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    true_simlex_scores = []\n",
    "    pred_simlex_scores = []\n",
    "    for emb1, emb2, simlex_scores, assoc_scores in test_loader:\n",
    "        emb1 = emb1.to(device)\n",
    "        emb2 = emb2.to(device)\n",
    "        simlex_scores = simlex_scores.to(device)\n",
    "        assoc_scores = assoc_scores.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(emb1, emb2)\n",
    "        simlex_scores = simlex_scores.unsqueeze(1)\n",
    "        loss = criterion(outputs, simlex_scores)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get true labels and predicted labels\n",
    "        true_simlex_scores.extend(simlex_scores.cpu().detach().numpy().tolist())\n",
    "        pred_simlex_scores.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(\"Test_Loss: {}\".format(test_loss))\n",
    "    # Calculate Spearman correlation\n",
    "    # print(\"True Simlex scores: \", true_simlex_scores)\n",
    "    # print(\"Predicted Simlex scores: \", pred_simlex_scores)\n",
    "\n",
    "    true_simlex_scores = np.array(true_simlex_scores)\n",
    "    pred_simlex_scores = np.array(pred_simlex_scores)\n",
    "    spear = spearmanr(true_simlex_scores, pred_simlex_scores)\n",
    "    print(\"Spearman correlation: {}\".format(spear[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:20.481646Z",
     "iopub.status.busy": "2024-07-29T08:34:20.481218Z",
     "iopub.status.idle": "2024-07-29T08:34:20.499811Z",
     "shell.execute_reply": "2024-07-29T08:34:20.499268Z",
     "shell.execute_reply.started": "2024-07-29T08:34:20.481617Z"
    },
    "id": "4vGeq0zhYxSz",
    "outputId": "27d8e53a-ee2f-4e1a-83bc-b5787f66ee37",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Loss: 8.80013370513916\n",
      "Spearman correlation: 0.08242745747928441\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test(lmodel, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:34:20.500957Z",
     "iopub.status.busy": "2024-07-29T08:34:20.500591Z",
     "iopub.status.idle": "2024-07-29T08:34:21.107774Z",
     "shell.execute_reply": "2024-07-29T08:34:21.107093Z",
     "shell.execute_reply.started": "2024-07-29T08:34:20.500931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a790c73a1ab443980a8d23b9651bf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/subprocess.py:941: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "Host key verification failed.\n",
      "Connection closed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f958c683a52d496583593d6ccf4e7a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DownloadWidget(children=(HBox(children=(Password(description='Dropzone Password:', style=DescriptionStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:publish_metrics_list failed due to SigFxClient_client is none...\n"
     ]
    }
   ],
   "source": [
    "%dropzone -p -src 'skipgram_wiki.ipynb' -tgt 'skipgram_wiki.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
