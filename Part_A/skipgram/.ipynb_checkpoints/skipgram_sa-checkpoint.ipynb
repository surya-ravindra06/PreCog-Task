{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T14:39:56.512469Z",
     "iopub.status.busy": "2024-07-27T14:39:56.512034Z",
     "iopub.status.idle": "2024-07-27T14:39:56.522507Z",
     "shell.execute_reply": "2024-07-27T14:39:56.521782Z",
     "shell.execute_reply.started": "2024-07-27T14:39:56.512434Z"
    },
    "id": "TsUSZYWDVfrT",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mImportError\u001b[0m\u001b[0;31m:\u001b[0m cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages for CBOW\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import matutils\n",
    "from numpy import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:40.062634Z",
     "iopub.status.busy": "2024-07-27T23:23:40.062165Z",
     "iopub.status.idle": "2024-07-27T23:23:40.066967Z",
     "shell.execute_reply": "2024-07-27T23:23:40.066389Z",
     "shell.execute_reply.started": "2024-07-27T23:23:40.062597Z"
    },
    "id": "u9LSU559Vfrb",
    "outputId": "14669060-3418-4346-d580-0117fd98e9c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print device name: get_device_name()\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:41.331113Z",
     "iopub.status.busy": "2024-07-27T23:23:41.330668Z",
     "iopub.status.idle": "2024-07-27T23:23:41.336382Z",
     "shell.execute_reply": "2024-07-27T23:23:41.335804Z",
     "shell.execute_reply.started": "2024-07-27T23:23:41.331078Z"
    },
    "id": "CYPn_r-lVfrd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from file and store list of sentences where sentences are list of words\n",
    "class MakeSentences():\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.sentences = self.read_file()\n",
    "\n",
    "    def read_file(self):\n",
    "        sentences = []\n",
    "        with open(self.file_name, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                sentences += ([x for x in line.strip().split('.') if x!=''])\n",
    "                i+=1\n",
    "                if i==10000:\n",
    "                    break\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:43.868470Z",
     "iopub.status.busy": "2024-07-27T23:23:43.868012Z",
     "iopub.status.idle": "2024-07-27T23:23:44.203031Z",
     "shell.execute_reply": "2024-07-27T23:23:44.202153Z",
     "shell.execute_reply.started": "2024-07-27T23:23:43.868433Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/rtelidevara/pk/Part_A_Word_Similarity\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:47.257608Z",
     "iopub.status.busy": "2024-07-27T23:23:47.257163Z",
     "iopub.status.idle": "2024-07-27T23:23:47.286404Z",
     "shell.execute_reply": "2024-07-27T23:23:47.285659Z",
     "shell.execute_reply.started": "2024-07-27T23:23:47.257567Z"
    },
    "id": "DoQ5VEj1Vfre",
    "outputId": "1de5aa09-7e62-4347-d065-c89b9a6cc67d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25137\n"
     ]
    }
   ],
   "source": [
    "sentences = MakeSentences('/projects/rtelidevara/pk/Part_A_Word_Similarity/wikitext-2-raw-v1/wikitext-2-raw/wiki.train.raw').sentences\n",
    "print(len(sentences))\n",
    "# for sentence in sentences:\n",
    "#     print(type(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d52Gzvk1Vfrf"
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:24:45.904994Z",
     "iopub.status.busy": "2024-07-27T23:24:45.904615Z",
     "iopub.status.idle": "2024-07-27T23:24:45.918128Z",
     "shell.execute_reply": "2024-07-27T23:24:45.917312Z",
     "shell.execute_reply.started": "2024-07-27T23:24:45.904960Z"
    },
    "id": "wZSwLzufVfrh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class Preprocess():\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def tokenize(self):\n",
    "        # Split sentences into words using regex to handle various punctuation\n",
    "        self.sentences = [re.findall(r'\\b\\w+\\b', sentence.lower()) for sentence in self.sentences]\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.sentences = [[word.lower() for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_stop_words(self):\n",
    "        # Common English stop words; expand as necessary\n",
    "        stop_words = set([\"the\", \"is\", \"at\", \"which\", \"on\", \"and\", \"a\", \"an\"])\n",
    "        self.sentences = [[word for word in sentence if word not in stop_words] for sentence in self.sentences]\n",
    "\n",
    "    def stemmer(self):\n",
    "        # Simple stemming using suffix stripping, can be improved\n",
    "        def simple_stem(word):\n",
    "            suffixes = [\"ing\", \"ly\", \"ed\", \"ious\", \"ies\", \"ive\", \"es\", \"s\", \"ment\"]\n",
    "            for suffix in sorted(suffixes, key=len, reverse=True):\n",
    "                if word.endswith(suffix):\n",
    "                    return word[:-len(suffix)]\n",
    "            return word\n",
    "        self.sentences = [[simple_stem(word) for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        self.sentences = [[word for word in sentence if word.isalpha()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        self.sentences = [[word for word in sentence if not word.isdigit()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_single_letter(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 1] for sentence in self.sentences]\n",
    "\n",
    "    def remove_extra_spaces(self):\n",
    "        self.sentences = [[word for word in sentence if word.strip()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_less_than_3(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 2] for sentence in self.sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T23:24:48.932051Z",
     "iopub.status.busy": "2024-07-27T23:24:48.931294Z",
     "iopub.status.idle": "2024-07-27T23:24:49.737123Z",
     "shell.execute_reply": "2024-07-27T23:24:49.736217Z",
     "shell.execute_reply.started": "2024-07-27T23:24:48.932009Z"
    },
    "id": "XmmPEsYnVfrj",
    "outputId": "7feb2815-90d9-40dd-881c-bd9365ab8ea8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done\n",
      "25137\n"
     ]
    }
   ],
   "source": [
    "# preprocess\n",
    "preprocess = Preprocess(sentences)\n",
    "preprocess.tokenize()\n",
    "# print(preprocess.sentences)\n",
    "preprocess.lowercase()\n",
    "preprocess.remove_stop_words()\n",
    "# preprocess.stemmer()\n",
    "preprocess.remove_punctuation()\n",
    "preprocess.remove_numbers()\n",
    "preprocess.remove_single_letter()\n",
    "preprocess.remove_extra_spaces()\n",
    "preprocess.remove_less_than_3()\n",
    "\n",
    "print(\"Preprocessing done\")\n",
    "# print(preprocess.sentences)\n",
    "sentences = preprocess.sentences\n",
    "print(len(sentences))\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is4d8bsdVfrk"
   },
   "source": [
    "### Create word index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T23:25:02.815999Z",
     "iopub.status.busy": "2024-07-27T23:25:02.815248Z",
     "iopub.status.idle": "2024-07-27T23:25:02.976569Z",
     "shell.execute_reply": "2024-07-27T23:25:02.975691Z",
     "shell.execute_reply.started": "2024-07-27T23:25:02.815958Z"
    },
    "id": "KSmnCYN8Vfrl",
    "outputId": "a7948c87-a65d-4d95-baa9-ce7d23033d42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab:  30214\n",
      "Most common words:  [('was', 5340), ('that', 3928), ('for', 3841), ('with', 3758), ('from', 2329), ('his', 2328), ('were', 1987), ('had', 1638), ('are', 1262), ('her', 1248)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten list of sentences into list of words\n",
    "word_list = list(itertools.chain.from_iterable(sentences))\n",
    "# print(word_list)\n",
    "\n",
    "# Create a vocabulary of words\n",
    "word_freq = Counter(word_list)\n",
    "\n",
    "# Remove words that occur less than 5 times\n",
    "vocab = set(word if word_freq[word] > 0 else '<unk>' for word in word_list)\n",
    "# print(vocab)\n",
    "\n",
    "# Add padding and unknown token to vocab\n",
    "vocab.add('<pad>')\n",
    "vocab.add('<unk>')\n",
    "# Add start and end token to vocab\n",
    "vocab.add('<start>')\n",
    "vocab.add('<end>')\n",
    "\n",
    "# Print length of vocab\n",
    "print(\"Size of vocab: \", len(vocab))\n",
    "\n",
    "# Create word to index and index to word mapping\n",
    "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx:word for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Print most common words\n",
    "print(\"Most common words: \", word_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:25:14.733743Z",
     "iopub.status.busy": "2024-07-27T23:25:14.733369Z",
     "iopub.status.idle": "2024-07-27T23:25:14.738435Z",
     "shell.execute_reply": "2024-07-27T23:25:14.737606Z",
     "shell.execute_reply.started": "2024-07-27T23:25:14.733710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(word_to_idx['intelligent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmEx5qHlVfrm"
   },
   "source": [
    "### Create dataset (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T23:32:50.955463Z",
     "iopub.status.busy": "2024-07-27T23:32:50.955002Z",
     "iopub.status.idle": "2024-07-27T23:32:50.968138Z",
     "shell.execute_reply": "2024-07-27T23:32:50.967538Z",
     "shell.execute_reply.started": "2024-07-27T23:32:50.955425Z"
    },
    "id": "8Zg7mU3eVfrn",
    "outputId": "5fe9954a-9c82-446f-a3bb-b45c2cb58c3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# define constants\n",
    "window_size = 2\n",
    "sliding_window = 2 * window_size + 1\n",
    "num_neg_samples = 5\n",
    "# print(sentences)\n",
    "\n",
    "# sentences = [sentences[0]]\n",
    "# print(sentences)\n",
    "def select_negative_samples(target_word, num_window_size, unigram_table):\n",
    "    negative_samples = []\n",
    "    while len(negative_samples) < 2*num_window_size:\n",
    "        sampled_word = random.choice(unigram_table)  # unigram_table is precomputed based on the distribution\n",
    "        if sampled_word != target_word:\n",
    "            negative_samples.append(sampled_word)\n",
    "    return negative_samples\n",
    "\n",
    "def create_unigram_table(vocab, table_size=len(vocab)):\n",
    "    unigram_table = []\n",
    "    total_count_power = sum([count**0.75 for count in vocab.values()])\n",
    "    for word, count in vocab.items():\n",
    "        p_wi = (count**0.75) / total_count_power\n",
    "        # Fill the table with the index of the word\n",
    "        unigram_table.extend([word] * int(p_wi * table_size))\n",
    "    return unigram_table\n",
    "\n",
    "# unigram_table = create_unigram_table(word_freq)\n",
    "# print(unigram_table)\n",
    "\n",
    "def get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_sample , vocab , unigram_table):\n",
    "    X = []\n",
    "    y = []\n",
    "    for sentence in sentences:\n",
    "        # add start and end token to sentence\n",
    "        sentence = ['<start>'] + sentence + ['<end>']\n",
    "        for i in range(len(sentence)):\n",
    "            context_word = sentence[i]\n",
    "            # print(\"target word: \", target_word)\n",
    "            target_words = []\n",
    "            temp1 = max(0,i - window_size)\n",
    "            temp2 = min(len(sentence)-1,i + window_size + 1)\n",
    "            # print(\"temp1: \", temp1)\n",
    "            # print(\"temp2: \", temp2)\n",
    "            for j in range(max(0,i - window_size),min(len(sentence)-1,i + window_size)+1):\n",
    "                if j != i:\n",
    "                    # print(sentence[j])\n",
    "                    target_words.append(sentence[j])\n",
    "                # print(\"context words: \", context_words)\n",
    "\n",
    "\n",
    "            # pad context words if length is less than sliding window\n",
    "            if len(target_words) < sliding_window:\n",
    "                target_words += ['<pad>'] * (sliding_window - len(target_words)-1)\n",
    "\n",
    "            target_words.append(context_word)\n",
    "            # print(\"length of target words: \", len(target_words))\n",
    "\n",
    "            # get positive samples\n",
    "            positive_samples = [word_to_idx[word] if word in vocab else word_to_idx['<unk>'] for word in target_words]\n",
    "            # print(\"lenght of positive samples: \", len(positive_samples))\n",
    "\n",
    "            X.append(positive_samples)\n",
    "            y.append(1)\n",
    "\n",
    "\n",
    "            # get negative samples\n",
    "            for i in range(num_neg_samples):\n",
    "                negative_samples = select_negative_samples(context_word, window_size, unigram_table)\n",
    "                negative_samples = [word_to_idx[word] if word in vocab else word_to_idx['<unk>'] for word in negative_samples]\n",
    "                negative_samples += [word_to_idx['<pad>']] * (sliding_window - len(negative_samples)-1)\n",
    "                negative_samples.append(word_to_idx[context_word])\n",
    "                X.append(negative_samples)\n",
    "                y.append(0)\n",
    "                # print(\"length of negative samples: \", len(negative_samples))\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-27T23:54:23.245498Z",
     "iopub.status.busy": "2024-07-27T23:54:23.245022Z",
     "iopub.status.idle": "2024-07-27T23:54:37.332767Z",
     "shell.execute_reply": "2024-07-27T23:54:37.332107Z",
     "shell.execute_reply.started": "2024-07-27T23:54:23.245464Z"
    },
    "id": "AcdYWIpNVfrp",
    "outputId": "e5873b2f-3f9f-4f90-8664-565a90b83efe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating samples\n",
      "[15930, 7094, 30201, 18605, 21304]\n",
      "0\n",
      "Samples created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating samples\")\n",
    "X, y = get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_samples, vocab, unigram_table)\n",
    "print(X[2])\n",
    "print(y[2])\n",
    "print(\"Samples created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:19:29.301544Z",
     "iopub.status.busy": "2024-07-28T00:19:29.301062Z",
     "iopub.status.idle": "2024-07-28T00:19:41.225427Z",
     "shell.execute_reply": "2024-07-28T00:19:41.224654Z",
     "shell.execute_reply.started": "2024-07-28T00:19:29.301509Z"
    },
    "id": "eGsJePZmVfrq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "data = list(zip(X,y))\n",
    "random.shuffle(data)\n",
    "X,y = zip(*data)\n",
    "\n",
    "# Turn into numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:19:44.512073Z",
     "iopub.status.busy": "2024-07-28T00:19:44.511592Z",
     "iopub.status.idle": "2024-07-28T00:19:44.725663Z",
     "shell.execute_reply": "2024-07-28T00:19:44.723381Z",
     "shell.execute_reply.started": "2024-07-28T00:19:44.512038Z"
    },
    "id": "yWqUDDJFVfrr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save X and y\n",
    "np.save('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/datasets/wikiskip_X_25k.npy', X)\n",
    "np.save('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/datasets/wikiskip_y_25k.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:19:45.380862Z",
     "iopub.status.busy": "2024-07-28T00:19:45.380323Z",
     "iopub.status.idle": "2024-07-28T00:19:45.624691Z",
     "shell.execute_reply": "2024-07-28T00:19:45.623912Z",
     "shell.execute_reply.started": "2024-07-28T00:19:45.380822Z"
    },
    "id": "LXnZMdQVVfrs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load X and y\n",
    "X = np.load('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/datasets/wikiskip_X_25k.npy')\n",
    "y = np.load('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/datasets/wikiskip_y_25k.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8vrxSIcVfrt"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:19:47.973118Z",
     "iopub.status.busy": "2024-07-28T00:19:47.972634Z",
     "iopub.status.idle": "2024-07-28T00:19:47.981638Z",
     "shell.execute_reply": "2024-07-28T00:19:47.981029Z",
     "shell.execute_reply.started": "2024-07-28T00:19:47.973080Z"
    },
    "id": "gnjj1fWUVfrt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the forward pass for SkipGram\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # self.embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # extract context and target from x\n",
    "        context = x[:, :-1]\n",
    "        input = x[:, -1]\n",
    "\n",
    "        context_embedding = self.embeddings(context)\n",
    "        input_embedding = self.embeddings(input)\n",
    "\n",
    "        # Dot product between each context embedding and input embedding to get batch_size*context_size*embedding_dim\n",
    "\n",
    "        dot_products = torch.bmm(context_embedding, input_embedding.unsqueeze(2))  # [batch_size, context_length, 1]\n",
    "        sum_dot_products = torch.sum(dot_products, dim=1)  # [batch_size, 1]\n",
    "\n",
    "        # Squeeze the last dimension to get the final scores\n",
    "        scores = sum_dot_products.squeeze(1)  # [batch_size]\n",
    "\n",
    "        return F.sigmoid(scores)\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        out = self.embeddings.weight.data\n",
    "        return out.cpu().numpy()\n",
    "\n",
    "    def get_word_embedding(self, word):\n",
    "        # If word is not in vocab, return unk\n",
    "        if word not in word_to_idx:\n",
    "            word = '<unk>'\n",
    "        word_tensor = torch.LongTensor([word_to_idx[word]])\n",
    "        word_tensor = word_tensor.to(next(self.parameters()).device)\n",
    "        out = self.embeddings(word_tensor).data\n",
    "        return out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:20:07.763537Z",
     "iopub.status.busy": "2024-07-28T00:20:07.763055Z",
     "iopub.status.idle": "2024-07-28T00:20:07.850734Z",
     "shell.execute_reply": "2024-07-28T00:20:07.849986Z",
     "shell.execute_reply.started": "2024-07-28T00:20:07.763497Z"
    },
    "id": "NwIXaXXUVfru",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 250\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Create model, loss function and optimizer\n",
    "model = SkipGram(vocab_size, embedding_dim)\n",
    "model.to(device)\n",
    "# Cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define dataloader\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(X).long(), torch.from_numpy(y).float())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:26:20.914746Z",
     "iopub.status.busy": "2024-07-28T00:26:20.914257Z",
     "iopub.status.idle": "2024-07-28T00:26:21.135228Z",
     "shell.execute_reply": "2024-07-28T00:26:21.134558Z",
     "shell.execute_reply.started": "2024-07-28T00:26:20.914709Z"
    },
    "id": "n-f6rzzXVfrv",
    "outputId": "95e1d396-4b8b-4e19-b7ac-fbeb4f77e5b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11268, 16953, 18920, 27250, 21304],\n",
      "        [16965, 22225, 15824, 16596, 17581],\n",
      "        [ 9161, 11902,  3957, 25018, 27549],\n",
      "        [10192, 24229, 27316,  1329,  4286],\n",
      "        [28781, 20513,  8527, 15389, 15301],\n",
      "        [17046, 15389, 16309, 20674,  8507],\n",
      "        [ 4937,  5292,  6518,   342,  5290],\n",
      "        [18920, 28850, 21098, 23544, 15917],\n",
      "        [12448,  9552, 24791, 23886, 11121],\n",
      "        [15577,  9556, 23975, 12006, 15533],\n",
      "        [11499,  3228,  8092, 19595, 16339],\n",
      "        [21856, 13590,  2270,  7727, 12303],\n",
      "        [ 3652,  8853,  1467, 28833, 21716],\n",
      "        [18182, 13998,  9713,  1186, 19018],\n",
      "        [19535, 16443, 11077, 28251, 23162],\n",
      "        [22485, 19287, 19993, 15389, 12665],\n",
      "        [15427, 25043, 30003, 26057, 22505],\n",
      "        [  810, 20674, 18783,  3288, 11902],\n",
      "        [25334,  7845,  6090, 25416, 13275],\n",
      "        [20177, 16892, 10816,  5808,   429],\n",
      "        [21167, 25203, 13433, 12665, 12369],\n",
      "        [28456, 29810,  6013,  7208, 21304],\n",
      "        [20089,  3768, 21187,  1641, 24707],\n",
      "        [ 9485, 14190, 23190, 28850, 18567],\n",
      "        [ 9695,  3090,  9695, 15917,  4782],\n",
      "        [ 2373,  9208,  6372, 13504, 12003],\n",
      "        [20340,  8162, 28429,  4063, 25610],\n",
      "        [26584, 28695, 24504, 28346, 15058],\n",
      "        [26407, 15126,  4598,  6439, 18866],\n",
      "        [22072, 28064, 10337, 26611, 24139],\n",
      "        [ 4992,  1479, 12665, 27943, 27524],\n",
      "        [ 5292,  6627, 20226, 15917, 20929],\n",
      "        [15849, 19038, 21203, 14165, 24564],\n",
      "        [ 9523, 22485,  1052,  4217,  9298],\n",
      "        [27366,  8092,  3608,  8795,  1566],\n",
      "        [  179, 22767, 28833,  7440, 11467],\n",
      "        [ 6091, 27943, 16341, 27156, 16485],\n",
      "        [ 3349, 25684, 22119, 27251, 18920],\n",
      "        [10894,  5292,  5639, 20331, 20546],\n",
      "        [ 7192, 13880, 26073, 23868,  5643],\n",
      "        [27770,  4984, 18769, 15917,  6406],\n",
      "        [ 8607,  7322, 26867,  8200, 17963],\n",
      "        [ 2436, 11246, 28010, 23977, 17250],\n",
      "        [24839, 15406,  6048, 13271,  3962],\n",
      "        [ 9595,  5796, 21490,  4439,   413],\n",
      "        [ 2723, 21137, 20226, 20399,   177],\n",
      "        [11370, 23644,  7193,  1365, 21304],\n",
      "        [25602, 30003,  5680, 28951, 15703],\n",
      "        [11145, 18006, 11860, 19407, 27000],\n",
      "        [ 8959,  3061, 15533,  6489, 15917],\n",
      "        [20710, 14983, 19082, 25924, 16016],\n",
      "        [ 7208, 12025,  5326, 14301,  6637],\n",
      "        [13934, 17470,  5315, 11459, 15917],\n",
      "        [ 2584, 10196, 11680, 15580, 18920],\n",
      "        [ 8507,  4309, 20331, 20000, 12450],\n",
      "        [19519, 18388, 24027, 29120, 21120],\n",
      "        [ 4431, 14682, 17305,  6820, 25311],\n",
      "        [30150,   429, 25585, 21139,  7077],\n",
      "        [18182, 29453, 17427, 10202, 21069],\n",
      "        [29046, 26949, 25723,   576, 15917],\n",
      "        [  429, 22421,  6497, 15414, 17305],\n",
      "        [13719,  5717, 13716, 20609, 25174],\n",
      "        [16549, 11370, 25911, 30082, 21304],\n",
      "        [10344,  5522,  8444, 22505,  9161],\n",
      "        [12598,  2331,   881, 18992, 25583],\n",
      "        [ 4901, 18973,  2926, 18182,  5353],\n",
      "        [29046, 24027, 14913, 21373, 23662],\n",
      "        [17953,  3609, 18645, 20865,  6992],\n",
      "        [23379, 13587, 18661,  6771, 17877],\n",
      "        [18920, 24110, 23212,  1076, 19517],\n",
      "        [16467, 15389, 22825, 23527, 20191],\n",
      "        [19456,  5193, 28433, 24094, 29855],\n",
      "        [ 4734,  6993, 17953, 27157, 18681],\n",
      "        [15389, 14844,   889, 28429, 12693],\n",
      "        [  569, 29785,  9907,  7350,  6140],\n",
      "        [18605, 25659,  9552, 22365, 21304],\n",
      "        [  491,  3989, 18297, 28002, 12192],\n",
      "        [13193, 15680, 22719, 21589,  8153],\n",
      "        [ 1124, 12453, 26584,  5027, 21304],\n",
      "        [10568, 27528, 20790, 20712, 22038],\n",
      "        [15277,  5025, 13843, 20609, 22129],\n",
      "        [18565,  4787, 23931, 14994, 16007],\n",
      "        [ 4690,  8276, 17098,  5292, 27877],\n",
      "        [22122, 29046,  5193,  2373, 21304],\n",
      "        [  264, 18636, 24791,  6062, 18161],\n",
      "        [ 7647,  7169, 16892,  6994, 12799],\n",
      "        [  122, 24037, 10339, 23872, 22731],\n",
      "        [ 3425, 16252, 29406,  6820,  6036],\n",
      "        [29680, 11092,  5411, 11262,   429],\n",
      "        [ 5292, 13886,  4088, 13504, 15917],\n",
      "        [24110,  7489,  5067,  6140,  1991],\n",
      "        [16485, 27569, 21174,  8952, 20301],\n",
      "        [ 7102,  4763,  6552,   771, 21304],\n",
      "        [ 3090, 28721, 11610, 11610, 15917],\n",
      "        [17895, 24341,  1125, 16254,  6025],\n",
      "        [22497, 14016, 24332, 24637, 14522],\n",
      "        [27985, 17324,  8624, 14893,  8515],\n",
      "        [19436,  4005,  2410, 14768, 29412],\n",
      "        [20300,  2278, 18080, 22951, 14499],\n",
      "        [12567, 15111,  7970, 21525, 21304],\n",
      "        [18534,  5992,  1875, 27947,  4997],\n",
      "        [22135,  8795, 29157, 15784, 13058],\n",
      "        [ 7465,  8034, 26514, 20910, 18182],\n",
      "        [ 9822,  1991, 19635, 29117, 14602],\n",
      "        [20863, 12182,  7808, 10703, 28111],\n",
      "        [21824, 27747,  8358,  4643, 11840],\n",
      "        [14731,   503, 14994, 14686, 21304],\n",
      "        [ 8629,  3142, 29752,  9360, 27400],\n",
      "        [ 7975,  9614, 11085,   904, 18920],\n",
      "        [ 4898, 10313, 17020,  7195, 20674],\n",
      "        [28275, 24424, 11357, 11502, 12665],\n",
      "        [ 5977, 19948, 18963, 19517, 11123],\n",
      "        [17966, 27939, 17862,  1520,  6780],\n",
      "        [11145,  7931,  9552,  2344, 21304],\n",
      "        [ 3888, 11247, 24373,  4718, 11881],\n",
      "        [29602, 20110,  5894, 16684, 26766],\n",
      "        [ 9714, 24481, 20586, 10703,  3829],\n",
      "        [29057,  5255, 11123,  2863,   177],\n",
      "        [22072, 10013, 25610,  4787, 21304],\n",
      "        [26975, 14835,  7648,  8528,  1260],\n",
      "        [20790, 28275, 15711, 23578, 16892],\n",
      "        [  893,   837, 20000, 18610, 17952],\n",
      "        [15577, 28964,  4402, 17229, 18920],\n",
      "        [16467, 15849, 28901, 10219, 14826],\n",
      "        [21098,  1521, 23727, 18651, 27077],\n",
      "        [21304,  4542, 19804, 11610, 28404],\n",
      "        [11010, 15277, 22473, 29328, 18920],\n",
      "        [22119, 28174, 26501, 26054, 14165]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Check dataset\n",
    "for i, (inputs, targets) in enumerate(dataloader):\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:26:24.401060Z",
     "iopub.status.busy": "2024-07-28T00:26:24.400247Z",
     "iopub.status.idle": "2024-07-28T00:26:24.407745Z",
     "shell.execute_reply": "2024-07-28T00:26:24.407133Z",
     "shell.execute_reply.started": "2024-07-28T00:26:24.401017Z"
    },
    "id": "baDqgCJMVfrw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train SkipGram model\n",
    "def train(model, criterion, optimizer, dataloader, epochs):\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        labels = []\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # get predictions\n",
    "            preds = [1 if x > 0.5 else 0 for x in outputs]\n",
    "            train_preds.extend(preds)\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            labels.extend(targets)\n",
    "        \n",
    "        train_loss /= len(dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Epoch: \", epoch+1, \"Loss: \", train_loss)\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:26:27.673407Z",
     "iopub.status.busy": "2024-07-28T00:26:27.672925Z",
     "iopub.status.idle": "2024-07-28T00:45:26.262161Z",
     "shell.execute_reply": "2024-07-28T00:45:26.261331Z",
     "shell.execute_reply.started": "2024-07-28T00:26:27.673366Z"
    },
    "id": "heiTsqTEVfrw",
    "outputId": "1c2f3430-9fe4-4293-ed21-b86f60608fd3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  24.385125662008598\n",
      "Epoch:  2 Loss:  19.298908373142662\n",
      "Epoch:  3 Loss:  16.720940272188365\n",
      "Epoch:  4 Loss:  14.879664852169416\n",
      "Epoch:  5 Loss:  13.448451541479482\n",
      "Epoch:  6 Loss:  12.278379257172302\n",
      "Epoch:  7 Loss:  11.319328445754028\n",
      "Epoch:  8 Loss:  10.520633085524992\n",
      "Epoch:  9 Loss:  9.856736105785822\n",
      "Epoch:  10 Loss:  9.30305239713838\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_losses = train(model, criterion, optimizer, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:46:36.148233Z",
     "iopub.status.busy": "2024-07-28T00:46:36.147749Z",
     "iopub.status.idle": "2024-07-28T00:46:36.152887Z",
     "shell.execute_reply": "2024-07-28T00:46:36.152305Z",
     "shell.execute_reply.started": "2024-07-28T00:46:36.148193Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot train accuracy\n",
    "def plot_train_losses(train_losses):\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Train Loss')\n",
    "    plt.title('Train Loss vs Epochs')\n",
    "    plt.savefig('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/plots/skip_train_losses.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:46:37.927285Z",
     "iopub.status.busy": "2024-07-28T00:46:37.926814Z",
     "iopub.status.idle": "2024-07-28T00:46:38.164321Z",
     "shell.execute_reply": "2024-07-28T00:46:38.163683Z",
     "shell.execute_reply.started": "2024-07-28T00:46:37.927242Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call function to plot train accuracy\n",
    "plot_train_losses(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:46:42.649663Z",
     "iopub.status.busy": "2024-07-28T00:46:42.648919Z",
     "iopub.status.idle": "2024-07-28T00:46:42.755716Z",
     "shell.execute_reply": "2024-07-28T00:46:42.755052Z",
     "shell.execute_reply.started": "2024-07-28T00:46:42.649628Z"
    },
    "id": "7Zd_ROK9c_Lj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/partA_pth/skipgram_25k_250_001.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:46:59.591267Z",
     "iopub.status.busy": "2024-07-28T00:46:59.590797Z",
     "iopub.status.idle": "2024-07-28T00:46:59.771149Z",
     "shell.execute_reply": "2024-07-28T00:46:59.770537Z",
     "shell.execute_reply.started": "2024-07-28T00:46:59.591230Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipGram(\n",
       "  (embeddings): Embedding(30214, 250)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = SkipGram(vocab_size, embedding_dim)\n",
    "model.load_state_dict(torch.load('/projects/rtelidevara/pk/Part_A_Word_Similarity/skipgram/partA_pth/skipgram_25k_250_001.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:01.398793Z",
     "iopub.status.busy": "2024-07-28T00:47:01.398342Z",
     "iopub.status.idle": "2024-07-28T00:47:01.413088Z",
     "shell.execute_reply": "2024-07-28T00:47:01.412359Z",
     "shell.execute_reply.started": "2024-07-28T00:47:01.398758Z"
    },
    "id": "QsC8hX0WVfrx",
    "outputId": "9e2cf61f-7206-4730-8f2b-7158d489a760",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
      "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
      "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
      "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
      "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
      "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
      "\n",
      "   SimAssoc333  SD(SimLex)  \n",
      "0            1        0.41  \n",
      "1            1        0.67  \n",
      "2            1        1.19  \n",
      "3            1        2.18  \n",
      "4            1        0.93  \n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "# Load into dataframe\n",
    "df = pd.read_csv('./SimLex-999/SimLex-999.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:07.322427Z",
     "iopub.status.busy": "2024-07-28T00:47:07.321926Z",
     "iopub.status.idle": "2024-07-28T00:47:07.326771Z",
     "shell.execute_reply": "2024-07-28T00:47:07.326147Z",
     "shell.execute_reply.started": "2024-07-28T00:47:07.322388Z"
    },
    "id": "_pfU1jobVfry",
    "outputId": "88935fb9-aabe-403b-ff21-f2f65f8663b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart\n"
     ]
    }
   ],
   "source": [
    "# Print 2nd row word1\n",
    "print(df['word1'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:08.309182Z",
     "iopub.status.busy": "2024-07-28T00:47:08.308725Z",
     "iopub.status.idle": "2024-07-28T00:47:08.316568Z",
     "shell.execute_reply": "2024-07-28T00:47:08.315916Z",
     "shell.execute_reply.started": "2024-07-28T00:47:08.309147Z"
    },
    "id": "ACaFnePdVfry",
    "outputId": "6dde4fcb-1ee9-4b27-9ea6-59d16be2372f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 250)\n",
      "(250,)\n",
      "[ 1.2692109   0.6448718  -1.2770371  -1.0032393  -0.04663036  0.5716105\n",
      "  0.01102339  0.8426366  -0.12082065 -0.09747623  0.05491221  0.4300891\n",
      " -1.3494842  -0.68604624 -1.0738425   0.06003275  0.945816   -0.13329424\n",
      "  0.99377465 -0.07391986 -0.8419706   0.6620986   0.8158594  -1.2948194\n",
      " -1.9392476  -0.43477473 -0.7334492   0.6233725  -0.7572609  -0.35110554\n",
      " -0.37123668  1.2258086   0.62752473  1.3677795   0.40141296 -1.6975447\n",
      "  0.3135627   2.4314902  -1.2729555   0.1062961  -2.1058736   0.53765315\n",
      "  0.19034249  1.0796914   0.57777166 -0.7656736  -0.06913087  1.2869861\n",
      " -0.7757156  -1.0124336  -0.46906206  0.4740846  -0.2965532   0.17754413\n",
      "  1.3745841   0.76123494  0.49137858  1.9798849  -0.7485079   0.42995614\n",
      " -0.9676292   1.5967633  -0.2980556   0.41078886 -0.08341699 -1.0374894\n",
      "  0.02161323 -2.1460521   2.329065   -0.8226799  -1.2629492  -0.80171436\n",
      " -1.1717418  -1.7864072  -0.28249106  0.5219608   0.3017752  -0.41393727\n",
      "  0.5673144   0.01853175  0.595203    0.5504871   0.36381665 -0.4800104\n",
      "  0.04175527 -1.3616419  -1.0448141  -0.81134605  0.73136944 -0.24569982\n",
      " -0.51707876 -0.40168154 -0.452406   -0.17107765 -0.49814564  1.0658047\n",
      "  0.08152325  1.1544355  -2.0103219   0.6930172  -0.8505993   0.9600832\n",
      "  0.18648674  0.81723815 -1.6180792  -0.23780058 -1.5134475  -1.768357\n",
      "  0.8593171   0.3761855  -0.23224626  1.2549045   0.1638157  -1.938717\n",
      " -1.021116   -0.31505892 -0.7577218  -1.2662638  -2.3310072   0.23359483\n",
      " -0.9575729  -1.1504828   0.18324943  0.07173051  1.3239461   0.28286088\n",
      " -0.377901   -0.13980156 -0.70679104  0.3411492  -0.36064425 -0.9264237\n",
      " -0.5624061  -0.17873773  0.12546875 -1.3945454   1.884159   -0.44343382\n",
      " -1.5222281   0.68437237  0.1039831  -0.3838704  -0.0385928  -0.6413646\n",
      " -2.5330226  -0.78127164  1.2848829   0.02699188  0.57235324  0.28105688\n",
      " -1.0048863   0.06073136  1.179894   -0.82120335 -1.1861342   0.84269863\n",
      " -1.3113772  -0.28001994  0.25081375 -1.9770565   0.546694   -0.08122378\n",
      "  0.11955295  0.53313386  0.24999255  0.8587142   0.5333085  -0.42107078\n",
      " -0.03547422  0.5102532   1.6393174  -1.6071776   0.27582932 -0.38183573\n",
      "  1.0358742   0.8918869  -0.17609672  0.4169509   0.4894282   0.6868224\n",
      "  0.61120427  2.2754078  -0.7315876   1.2491943  -1.0501838   0.6022609\n",
      "  2.142608   -0.32184604 -1.737856   -0.21578586 -0.7929807  -0.72765523\n",
      " -0.6355581   1.0987924  -1.8208445   1.0508595  -1.0792567  -1.7405921\n",
      "  0.85789436  1.4428678   0.3310689  -0.7180796  -0.4730865  -0.97621703\n",
      " -0.56329346  0.8138244  -0.3049471   0.3491809   1.6676424  -1.367631\n",
      " -2.1541395  -0.3029241  -0.7206274  -1.7355933  -0.8802209   0.23511903\n",
      "  0.33147016 -1.8872755  -0.36228615  0.95933247 -0.95472634 -0.6270292\n",
      "  0.12807217 -0.8890348   0.3432244   3.1933188   0.7587536   0.1628466\n",
      " -0.04587254  0.41321898  0.07517779  0.3022879   1.0959055   0.44365808\n",
      "  0.9381553  -0.628099    0.77166504 -0.9637361  -1.4163923  -0.9335571\n",
      " -0.09858026  0.9056093  -1.3962065  -0.52627206 -0.72551996 -0.37827015\n",
      "  1.4001687   0.8963631   0.20909318  0.8216378 ]\n"
     ]
    }
   ],
   "source": [
    "# Get word embeddings\n",
    "sample_embedding = model.get_word_embedding(df['word1'][1])\n",
    "print(sample_embedding.shape)\n",
    "sample_embedding = sample_embedding.squeeze()\n",
    "print(sample_embedding.shape)\n",
    "print(sample_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:35.910956Z",
     "iopub.status.busy": "2024-07-28T00:47:35.910489Z",
     "iopub.status.idle": "2024-07-28T00:47:35.917894Z",
     "shell.execute_reply": "2024-07-28T00:47:35.917295Z",
     "shell.execute_reply.started": "2024-07-28T00:47:35.910922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check similarity between two words\n",
    "word1 = df['word1'][1]\n",
    "word2 = df['word1'][1]\n",
    "\n",
    "# Use gensim or any other model to get word embeddings\n",
    "w1 = model.get_word_embedding(word1).squeeze()\n",
    "w2 = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "print(type(w1))\n",
    "\n",
    "# Calculate cosine similarity using numpy\n",
    "def unitvec(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "sim = np.dot(unitvec(w1), unitvec(w2))\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:38.403705Z",
     "iopub.status.busy": "2024-07-28T00:47:38.402953Z",
     "iopub.status.idle": "2024-07-28T00:47:38.407173Z",
     "shell.execute_reply": "2024-07-28T00:47:38.406581Z",
     "shell.execute_reply.started": "2024-07-28T00:47:38.403670Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to check if word is in vocab\n",
    "def check_vocab(word):\n",
    "    if word in vocab:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:40.169259Z",
     "iopub.status.busy": "2024-07-28T00:47:40.168793Z",
     "iopub.status.idle": "2024-07-28T00:47:40.174460Z",
     "shell.execute_reply": "2024-07-28T00:47:40.173849Z",
     "shell.execute_reply.started": "2024-07-28T00:47:40.169226Z"
    },
    "id": "XUOiHPqcVfrz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get cosine similarity\n",
    "import numpy as np\n",
    "\n",
    "def cos_similarity(word1_embedding, word2_embedding):\n",
    "    def unitvec(vec):\n",
    "        return vec / np.linalg.norm(vec)\n",
    "\n",
    "    ans = np.dot(unitvec(word1_embedding), unitvec(word2_embedding))\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Function to get Pearson correlation\n",
    "def pearson_correlation(word1_embedding, word2_embedding):\n",
    "    emb1 = np.array(word1_embedding)\n",
    "    emb2 = np.array(word2_embedding)\n",
    "\n",
    "    correlation, _ = pearsonr(emb1, emb2)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:42.800856Z",
     "iopub.status.busy": "2024-07-28T00:47:42.800389Z",
     "iopub.status.idle": "2024-07-28T00:47:42.807208Z",
     "shell.execute_reply": "2024-07-28T00:47:42.806606Z",
     "shell.execute_reply.started": "2024-07-28T00:47:42.800820Z"
    },
    "id": "7upp-39oVfr0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_sim(df, model, lemmatizer, stemmer):\n",
    "    cosine_similarity_scores = []\n",
    "    pearson_correlation_scores = []\n",
    "    simlex_scores = []\n",
    "    not_in_vocab = 0\n",
    "  \n",
    "    for _, row in df.iterrows():\n",
    "        word1 = row['word1']\n",
    "        word2 = row['word2']\n",
    "        form = row['POS']\n",
    "        form = form.lower()\n",
    "       \n",
    "        # Check if word is in vocab\n",
    "        if not check_vocab(word1) or not check_vocab(word2):\n",
    "            not_in_vocab += 1\n",
    "\n",
    "        # Get embeddings\n",
    "        word1_embedding = model.get_word_embedding(word1).squeeze()\n",
    "        word2_embedding = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "        # Get cosine similarity\n",
    "        cosine_similarity_scores.append(cos_similarity(word1_embedding, word2_embedding))\n",
    "        \n",
    "        # Get pearson correlation\n",
    "        pearson_correlation_scores.append(pearson_correlation(word1_embedding, word2_embedding))\n",
    "\n",
    "        # Get simlex score\n",
    "        simlex_scores.append(row['SimLex999'])\n",
    "        \n",
    "    return cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:44.198037Z",
     "iopub.status.busy": "2024-07-28T00:47:44.197591Z",
     "iopub.status.idle": "2024-07-28T00:47:45.642723Z",
     "shell.execute_reply": "2024-07-28T00:47:45.642029Z",
     "shell.execute_reply.started": "2024-07-28T00:47:44.198002Z"
    },
    "id": "017GL4PjVfr0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cosine similarity and pearson correlation scores\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab = test_sim(df, model, lemmatizer, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:45.644366Z",
     "iopub.status.busy": "2024-07-28T00:47:45.644013Z",
     "iopub.status.idle": "2024-07-28T00:47:45.648127Z",
     "shell.execute_reply": "2024-07-28T00:47:45.647576Z",
     "shell.execute_reply.started": "2024-07-28T00:47:45.644338Z"
    },
    "id": "ZzTVRgyvX-Tu",
    "outputId": "5979a4ee-9fe0-4689-fc7f-0a80860c17b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Check cosine similarity and pearson correlation scores\n",
    "print(type(cosine_similarity_scores))\n",
    "print(type(pearson_correlation_scores))\n",
    "print(type(simlex_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:45.649309Z",
     "iopub.status.busy": "2024-07-28T00:47:45.648884Z",
     "iopub.status.idle": "2024-07-28T00:47:45.660161Z",
     "shell.execute_reply": "2024-07-28T00:47:45.659654Z",
     "shell.execute_reply.started": "2024-07-28T00:47:45.649280Z"
    },
    "id": "y09A6xWTYArg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funtcion to get spearman correlation using cosine similarity scores\n",
    "def spearman_correlation(cosine_similarity_scores, simlex_scores):\n",
    "    # Scale cosine similarity scores to 0-10\n",
    "    cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "    cosine_similarity_scores = (1+cosine_similarity_scores)*5\n",
    "    simlex_scores = np.array(simlex_scores)\n",
    "\n",
    "    correlation, _ = spearmanr(cosine_similarity_scores, simlex_scores)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:49.508135Z",
     "iopub.status.busy": "2024-07-28T00:47:49.507670Z",
     "iopub.status.idle": "2024-07-28T00:47:49.515011Z",
     "shell.execute_reply": "2024-07-28T00:47:49.514427Z",
     "shell.execute_reply.started": "2024-07-28T00:47:49.508102Z"
    },
    "id": "kiOl-gKHYDQw",
    "outputId": "af2ae4c8-a077-4630-c9d3-046c3fdf5465",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Spearman correlation Sim:  0.01582396250240331\n"
     ]
    }
   ],
   "source": [
    "# Print the initial spearman correlation\n",
    "spearman_value_sim = spearman_correlation(cosine_similarity_scores, simlex_scores)\n",
    "\n",
    "print(\"Initial Spearman correlation Sim: \", spearman_value_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:47:50.849744Z",
     "iopub.status.busy": "2024-07-28T00:47:50.849269Z",
     "iopub.status.idle": "2024-07-28T00:47:50.853511Z",
     "shell.execute_reply": "2024-07-28T00:47:50.852919Z",
     "shell.execute_reply.started": "2024-07-28T00:47:50.849709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points not in vocab:  128\n"
     ]
    }
   ],
   "source": [
    "# Print the number of data points not in vocab\n",
    "print(\"Number of data points not in vocab: \", not_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:11.554396Z",
     "iopub.status.busy": "2024-07-28T00:48:11.553919Z",
     "iopub.status.idle": "2024-07-28T00:48:11.565739Z",
     "shell.execute_reply": "2024-07-28T00:48:11.565143Z",
     "shell.execute_reply.started": "2024-07-28T00:48:11.554361Z"
    },
    "id": "vmxDwm3gYGWL",
    "outputId": "0a9ffc8e-9e2d-459b-bee1-803b86fe90e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0    old          new   A       1.58        7.25           0.079347   \n",
      "1  smart  intelligent   A       9.20        7.11          -0.083786   \n",
      "2   hard    difficult   A       8.77        5.94           0.095325   \n",
      "3  happy     cheerful   A       9.55        5.85           0.059504   \n",
      "4   hard         easy   A       0.95        5.82          -0.015542   \n",
      "\n",
      "   Pearson Correlation  \n",
      "0             0.078640  \n",
      "1            -0.085301  \n",
      "2             0.095441  \n",
      "3             0.050793  \n",
      "4            -0.015575  \n"
     ]
    }
   ],
   "source": [
    "# Make a dataframe of cosine similarity scores and pearson correlation scores along with Simlex-999 scores and Assoc(USF)\n",
    "simlex_scores = df['SimLex999']\n",
    "assoc_scores = df['Assoc(USF)']\n",
    "cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "pearson_correlation_scores = np.array(pearson_correlation_scores)\n",
    "simlex_scores = np.array(simlex_scores)\n",
    "assoc_scores = np.array(assoc_scores)\n",
    "# print(cosine_similarity_scores.shape)\n",
    "# print(pearson_correlation_scores.shape)\n",
    "\n",
    "# Make a dataframe along with word1, word2, POS, SimLex-999 scores, Assoc(USF), cosine similarity scores and pearson correlation scores\n",
    "datat = {'word1': df['word1'], 'word2': df['word2'], 'POS': df['POS'], 'SimLex999': simlex_scores, 'Assoc(USF)': assoc_scores, 'Cosine Similarity': cosine_similarity_scores, 'Pearson Correlation': pearson_correlation_scores}\n",
    "ndf = pd.DataFrame(data=datat)\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:16.115893Z",
     "iopub.status.busy": "2024-07-28T00:48:16.115437Z",
     "iopub.status.idle": "2024-07-28T00:48:16.125298Z",
     "shell.execute_reply": "2024-07-28T00:48:16.124696Z",
     "shell.execute_reply.started": "2024-07-28T00:48:16.115859Z"
    },
    "id": "Ig5Adsa7YIro",
    "outputId": "4e079f74-c2ab-43dd-b1ae-b70ec8a3c759",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0       old          new   A       1.58        7.25           0.079347   \n",
      "1     smart  intelligent   A       9.20        7.11          -0.083786   \n",
      "2      hard    difficult   A       8.77        5.94           0.095325   \n",
      "3     happy     cheerful   A       9.55        5.85           0.059504   \n",
      "4      hard         easy   A       0.95        5.82          -0.015542   \n",
      "..      ...          ...  ..        ...         ...                ...   \n",
      "994    join      acquire   V       2.85        0.00           0.052917   \n",
      "995    send       attend   V       1.67        0.00           0.029310   \n",
      "996  gather       attend   V       4.80        0.00           0.025605   \n",
      "997  absorb     withdraw   V       2.97        0.00          -0.025037   \n",
      "998  attend       arrive   V       6.08        0.00          -0.037625   \n",
      "\n",
      "     Pearson Correlation  \n",
      "0               0.078640  \n",
      "1              -0.085301  \n",
      "2               0.095441  \n",
      "3               0.050793  \n",
      "4              -0.015575  \n",
      "..                   ...  \n",
      "994             0.050733  \n",
      "995             0.029081  \n",
      "996             0.026345  \n",
      "997            -0.023225  \n",
      "998            -0.038103  \n",
      "\n",
      "[999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print df\n",
    "print(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10G686jpYLa7"
   },
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:21.822156Z",
     "iopub.status.busy": "2024-07-28T00:48:21.821690Z",
     "iopub.status.idle": "2024-07-28T00:48:21.828415Z",
     "shell.execute_reply": "2024-07-28T00:48:21.827805Z",
     "shell.execute_reply.started": "2024-07-28T00:48:21.822119Z"
    },
    "id": "FVuLgyQ5YPiP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "def create_dataset(df, model):\n",
    "    # Create a list of tuples\n",
    "    emb1 = []\n",
    "    emb2 = []\n",
    "    simlex_scores = []\n",
    "    assoc_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "            word1 = row['word1']\n",
    "            word2 = row['word2']\n",
    "            emb1.append(torch.tensor(model.get_word_embedding(word1).squeeze()))\n",
    "            emb2.append(torch.tensor(model.get_word_embedding(word2).squeeze()))\n",
    "            simlex_scores.append(row['SimLex999'])\n",
    "            assoc_scores.append(row['Assoc(USF)'])\n",
    "\n",
    "    # print(emb1[0].shape)\n",
    "    emb1_stack = torch.stack(emb1)\n",
    "    emb2_stack = torch.stack(emb2)\n",
    "\n",
    "    return emb1_stack, emb2_stack, torch.tensor(simlex_scores, dtype=torch.float), torch.tensor(assoc_scores, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:23.768663Z",
     "iopub.status.busy": "2024-07-28T00:48:23.768185Z",
     "iopub.status.idle": "2024-07-28T00:48:24.146181Z",
     "shell.execute_reply": "2024-07-28T00:48:24.145481Z",
     "shell.execute_reply.started": "2024-07-28T00:48:23.768628Z"
    },
    "id": "VX-9UOKGYQq0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call create_dataset\n",
    "train_df, test_df = train_test_split(ndf, test_size=0.1, random_state=42)\n",
    "train_emb1, train_emb2, train_simlex_scores, train_assoc_scores = create_dataset(train_df, model)\n",
    "test_emb1, test_emb2, test_simlex_scores, test_assoc_scores = create_dataset(test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:24.205775Z",
     "iopub.status.busy": "2024-07-28T00:48:24.205406Z",
     "iopub.status.idle": "2024-07-28T00:48:24.209352Z",
     "shell.execute_reply": "2024-07-28T00:48:24.208806Z",
     "shell.execute_reply.started": "2024-07-28T00:48:24.205746Z"
    },
    "id": "wv_-44vYYUrT",
    "outputId": "4d52e675-c1c9-4983-d6a3-67fcec246f31",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([899, 250])\n",
      "torch.Size([899])\n"
     ]
    }
   ],
   "source": [
    "# check train_emb1\n",
    "print(train_emb1.shape)\n",
    "print(train_simlex_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:25.536665Z",
     "iopub.status.busy": "2024-07-28T00:48:25.536197Z",
     "iopub.status.idle": "2024-07-28T00:48:25.540603Z",
     "shell.execute_reply": "2024-07-28T00:48:25.540002Z",
     "shell.execute_reply.started": "2024-07-28T00:48:25.536629Z"
    },
    "id": "I9YI_RUpYZ4F",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creare TensorDataset\n",
    "train_dataset = torch.utils.data.TensorDataset(train_emb1, train_emb2, train_simlex_scores, train_assoc_scores)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_emb1, test_emb2, test_simlex_scores, test_assoc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:27.211285Z",
     "iopub.status.busy": "2024-07-28T00:48:27.210819Z",
     "iopub.status.idle": "2024-07-28T00:48:27.215756Z",
     "shell.execute_reply": "2024-07-28T00:48:27.215156Z",
     "shell.execute_reply.started": "2024-07-28T00:48:27.211239Z"
    },
    "id": "-SLh3kMMYbEM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:27.482288Z",
     "iopub.status.busy": "2024-07-28T00:48:27.481723Z",
     "iopub.status.idle": "2024-07-28T00:48:27.487848Z",
     "shell.execute_reply": "2024-07-28T00:48:27.487300Z",
     "shell.execute_reply.started": "2024-07-28T00:48:27.482250Z"
    },
    "id": "ajZzT_bwYhoC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class that takes CBOW embeddings, and outputs similarity scores: loss is MSE between predicted similarity scores and actual similarity scores(Simlex-999)\n",
    "# We're basically optimizing these weights over here used to produce this score out of 10, minimizing the distance between this score and the simlex score.\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2*embedding_dim, 50)\n",
    "        self.linear2 = nn.Linear(50, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        # emb1 = emb1.squeeze()\n",
    "        # emb2 = emb2.squeeze()\n",
    "        emb = torch.cat((emb1, emb2), dim=1)\n",
    "\n",
    "        out = self.linear1(emb)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # Project the output between 0 and 10\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out*10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:27.724573Z",
     "iopub.status.busy": "2024-07-28T00:48:27.724070Z",
     "iopub.status.idle": "2024-07-28T00:48:27.730053Z",
     "shell.execute_reply": "2024-07-28T00:48:27.729521Z",
     "shell.execute_reply.started": "2024-07-28T00:48:27.724544Z"
    },
    "id": "g-9VMxgiYkWc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dim = 250\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize model\n",
    "lmodel = RegressionModel(embedding_dim).to(device)\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(lmodel.parameters(), lr=learning_rate, weight_decay=0.01) # weight_decay is L2 regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:28.859459Z",
     "iopub.status.busy": "2024-07-28T00:48:28.858711Z",
     "iopub.status.idle": "2024-07-28T00:48:28.865325Z",
     "shell.execute_reply": "2024-07-28T00:48:28.864741Z",
     "shell.execute_reply.started": "2024-07-28T00:48:28.859423Z"
    },
    "id": "6h_RY03MYnhj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train model\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for emb1, emb2, simlex_scores, assoc_scores in train_loader:\n",
    "            emb1 = emb1.to(device)\n",
    "            emb2 = emb2.to(device)\n",
    "            simlex_scores = simlex_scores.to(device)\n",
    "            assoc_scores = assoc_scores.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(emb1, emb2)\n",
    "\n",
    "            simlex_scores = simlex_scores.unsqueeze(1)\n",
    "            # print(outputs[0])\n",
    "            loss = criterion(outputs, simlex_scores)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(\"Epoch: {}, Train_Loss: {}\".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:29.100038Z",
     "iopub.status.busy": "2024-07-28T00:48:29.099713Z",
     "iopub.status.idle": "2024-07-28T00:48:30.278844Z",
     "shell.execute_reply": "2024-07-28T00:48:30.278186Z",
     "shell.execute_reply.started": "2024-07-28T00:48:29.100009Z"
    },
    "id": "-yhHpOiLYswb",
    "outputId": "26d3b0df-260a-4d4e-f540-3c5bd789c0e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_Loss: 7.293842743183005\n",
      "Epoch: 2, Train_Loss: 6.230731181383984\n",
      "Epoch: 3, Train_Loss: 5.319978366366778\n",
      "Epoch: 4, Train_Loss: 4.534791539800295\n",
      "Epoch: 5, Train_Loss: 4.3661002068236\n",
      "Epoch: 6, Train_Loss: 3.452684682499796\n",
      "Epoch: 7, Train_Loss: 3.1964997273029754\n",
      "Epoch: 8, Train_Loss: 2.7494660335756644\n",
      "Epoch: 9, Train_Loss: 2.612806195904391\n",
      "Epoch: 10, Train_Loss: 2.614652053888145\n",
      "Epoch: 11, Train_Loss: 2.2702318435556412\n",
      "Epoch: 12, Train_Loss: 2.3550725805541797\n",
      "Epoch: 13, Train_Loss: 2.351641170690049\n",
      "Epoch: 14, Train_Loss: 1.8797770900462412\n",
      "Epoch: 15, Train_Loss: 1.800576864175873\n",
      "Epoch: 16, Train_Loss: 1.7357747965329295\n",
      "Epoch: 17, Train_Loss: 1.5516720181678678\n",
      "Epoch: 18, Train_Loss: 1.531353152229782\n",
      "Epoch: 19, Train_Loss: 1.4699675494375721\n",
      "Epoch: 20, Train_Loss: 1.4479665100367003\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train(lmodel, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:33.403510Z",
     "iopub.status.busy": "2024-07-28T00:48:33.403034Z",
     "iopub.status.idle": "2024-07-28T00:48:33.410631Z",
     "shell.execute_reply": "2024-07-28T00:48:33.410037Z",
     "shell.execute_reply.started": "2024-07-28T00:48:33.403475Z"
    },
    "id": "iUU1Go8aYwoM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to test model, Calculate test loss and Spearman correlation\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    true_simlex_scores = []\n",
    "    pred_simlex_scores = []\n",
    "    for emb1, emb2, simlex_scores, assoc_scores in test_loader:\n",
    "        emb1 = emb1.to(device)\n",
    "        emb2 = emb2.to(device)\n",
    "        simlex_scores = simlex_scores.to(device)\n",
    "        assoc_scores = assoc_scores.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(emb1, emb2)\n",
    "        simlex_scores = simlex_scores.unsqueeze(1)\n",
    "        loss = criterion(outputs, simlex_scores)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get true labels and predicted labels\n",
    "        true_simlex_scores.extend(simlex_scores.cpu().detach().numpy().tolist())\n",
    "        pred_simlex_scores.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(\"Test_Loss: {}\".format(test_loss))\n",
    "    # Calculate Spearman correlation\n",
    "    # print(\"True Simlex scores: \", true_simlex_scores)\n",
    "    # print(\"Predicted Simlex scores: \", pred_simlex_scores)\n",
    "\n",
    "    true_simlex_scores = np.array(true_simlex_scores)\n",
    "    pred_simlex_scores = np.array(pred_simlex_scores)\n",
    "    spear = spearmanr(true_simlex_scores, pred_simlex_scores)\n",
    "    print(\"Spearman correlation: {}\".format(spear[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-28T00:48:34.623504Z",
     "iopub.status.busy": "2024-07-28T00:48:34.623026Z",
     "iopub.status.idle": "2024-07-28T00:48:34.635192Z",
     "shell.execute_reply": "2024-07-28T00:48:34.634584Z",
     "shell.execute_reply.started": "2024-07-28T00:48:34.623469Z"
    },
    "id": "4vGeq0zhYxSz",
    "outputId": "27d8e53a-ee2f-4e1a-83bc-b5787f66ee37",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Loss: 9.227603435516357\n",
      "Spearman correlation: 0.05957028031427318\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test(lmodel, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
