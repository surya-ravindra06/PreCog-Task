{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTMeYOD4YEmH"
      },
      "outputs": [],
      "source": [
        "# import all necessary packages for CBOW\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import collections\n",
        "import itertools\n",
        "import re\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from torchtext.vocab import GloVe\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kKU7MZluYEmP"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print device name: get_device_name()\n",
        "# print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVjZivZVaHDj",
        "outputId": "23ae1076-f736-4220-a181-83e07a01301a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from gensim import matutils\n",
        "from numpy import dot\n",
        "\n",
        "\n",
        "print(list(api.info()['models'].keys()))\n",
        "\n",
        "# def load_vectors(fname):\n",
        "#     fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "#     n, d = map(int, fin.readline().split())\n",
        "#     data = {}\n",
        "#     for line in fin:\n",
        "#         tokens = line.rstrip().split(' ')\n",
        "#         data[tokens[0]] = map(float, tokens[1:])\n",
        "#     return data\n",
        "\n",
        "# fasttext_data = load_vectors('/content/drive/My Drive/wiki-news-300d-1M.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmiTPflcc8fp",
        "outputId": "f7a2139c-8ab3-442a-9f6e-ad8e71fa82ac"
      },
      "outputs": [],
      "source": [
        "model = api.load('fasttext-wiki-news-subwords-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jj4xQjUxYEmQ"
      },
      "outputs": [],
      "source": [
        "def get_word_embedding(model ,word):\n",
        "    return model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ_MqpnkNSe3",
        "outputId": "33bafd6c-ae30-4f98-b0c1-cf6dd73d0da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "0.34138656\n",
            "0.34138656\n"
          ]
        }
      ],
      "source": [
        "# Cosine similarity between same words\n",
        "w1 = model['survey']\n",
        "w2 = model['generation']\n",
        "print(type(w1))\n",
        "ans1 = dot(matutils.unitvec(w1), matutils.unitvec(w2))\n",
        "print(ans1)\n",
        "\n",
        "ans2 = model.similarity('survey', 'generation')\n",
        "print(ans2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huamuh-FqtEr",
        "outputId": "678d5b5b-3ea0-4ec2-f145-d1ff69d7c200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between king and queen:  0.7606731653213501\n",
            "Cosine similarity between king and queen:  0.7704245448112488\n",
            "New Distance between king and z:  0.6913657188415527\n",
            "New Cosine similarity between king and z:  0.8185327053070068\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Assuming 'model' is your pre-loaded word embedding model\n",
        "x = torch.tensor(model['king'])\n",
        "y = torch.tensor(model['queen'])\n",
        "# z = king - man + woman\n",
        "z = x - torch.tensor(model['man']) + torch.tensor(model['woman'])\n",
        "\n",
        "# Calculating distances and similarities\n",
        "distance_king_queen = torch.norm(x - y).item()\n",
        "cosine_sim_king_queen = F.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0)).item()\n",
        "distance_king_z = torch.norm(x - z).item()\n",
        "cosine_sim_king_z = F.cosine_similarity(x.unsqueeze(0), z.unsqueeze(0)).item()\n",
        "\n",
        "print(\"Distance between king and queen: \", distance_king_queen)\n",
        "print(\"Cosine similarity between king and queen: \", cosine_sim_king_queen)\n",
        "print(\"New Distance between king and z: \", distance_king_z)\n",
        "print(\"New Cosine similarity between king and z: \", cosine_sim_king_z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYGudSyQrdwX",
        "outputId": "ebf0625e-7c45-4146-b253-3140cd7c07fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "print(type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn0VfmbNYEmR",
        "outputId": "13631a24-77e8-4866-b708-dbe546be1db1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Word 1    Word 2  Human (mean)\n",
            "0      love       sex          6.77\n",
            "1     tiger       cat          7.35\n",
            "2     tiger     tiger         10.00\n",
            "3      book     paper          7.46\n",
            "4  computer  keyboard          7.62\n"
          ]
        }
      ],
      "source": [
        "# Load test data\n",
        "\n",
        "# Load into dataframe\n",
        "df = pd.read_csv('./wordsim353/combined.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlvgAnOdYEmR",
        "outputId": "2f16963f-4b2b-4af3-996a-481be6491095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,)\n",
            "(300,)\n",
            "[-0.010743   -0.0084354   0.092938   -0.01284    -0.021971   -0.0032322\n",
            "  0.038068   -0.10577     0.056288    0.0030197   0.05506     0.016761\n",
            "  0.10294     0.02478    -0.035468   -0.0082909   0.073924   -0.20287\n",
            "  0.056451    0.010568    0.04613    -0.028164   -0.010605    0.010803\n",
            " -0.0011941   0.039338    0.018323   -0.00094558  0.039761    0.022547\n",
            "  0.021721    0.0021049   0.092333    0.078911   -0.0025022  -0.025226\n",
            "  0.033931   -0.083757    0.037918    0.036854    0.040416   -0.11903\n",
            "  0.087746   -0.038085    0.025236    0.037645    0.10565     0.011185\n",
            "  0.02687     0.046986    0.04401     0.071783   -0.0093949  -0.088606\n",
            " -0.0076906  -0.11334     0.046087   -0.062826   -0.10398     0.067696\n",
            "  0.077696   -0.091606    0.058478   -0.0049788   0.028417    0.049761\n",
            "  0.015129    0.0077711   0.06533     0.00049186  0.032615   -0.10434\n",
            "  0.032913   -0.086249    0.029265    0.054921   -0.045848   -0.033614\n",
            "  0.034103   -0.05848     0.0074672  -0.064005   -0.015384    0.019051\n",
            "  0.056916   -0.083669   -0.072492   -0.016202    0.02198    -0.018957\n",
            " -0.062649    0.01917    -0.11939    -0.057154    0.10131     0.13806\n",
            "  0.10921    -0.019971    0.12445     0.016068   -0.042782   -0.038983\n",
            "  0.018234    0.0073128  -0.050234   -0.19928    -0.12769    -0.058885\n",
            " -0.057422   -0.0080911  -0.056217    0.060863    0.072536   -0.065503\n",
            " -0.035433    0.059087    0.010612    0.077914   -0.048719    0.0084069\n",
            "  0.053309    0.19461    -0.030752   -0.10939     0.11406     0.11406\n",
            " -0.044528   -0.16544    -0.049756    0.069878   -0.069476   -0.010499\n",
            "  0.036071    0.081475   -0.012086   -0.062586    0.086618    0.09129\n",
            "  0.03017     0.13829    -0.069435   -0.094678    0.074979   -0.020312\n",
            " -0.0029014  -0.062715    0.075754   -0.0061489  -0.020436   -0.084951\n",
            " -0.015225    0.075689    0.029466   -0.013256    0.062603   -0.069061\n",
            " -0.025892    0.0011407   0.010717   -0.021988    0.022494   -0.032557\n",
            " -0.090406   -0.013149   -0.039509   -0.026058   -0.0042405  -0.095528\n",
            " -0.083936    0.097077    0.0071182   0.033413   -0.091971    0.10617\n",
            "  0.0045731   0.067739   -0.035568   -0.083963   -0.084222   -0.019003\n",
            "  0.028039    0.047845   -0.089332   -0.097801   -0.020619   -0.081414\n",
            "  0.0076275   0.148      -0.021893   -0.078694   -0.072851   -0.015765\n",
            " -0.049996   -0.029159   -0.024285   -0.046109    0.050478   -0.022338\n",
            " -0.022276    0.0075972  -0.1914      0.12578    -0.064584   -0.011121\n",
            "  0.012694   -0.0049295  -0.064361   -0.045271    0.092944   -0.04514\n",
            "  0.1687     -0.0021135   0.011203   -0.10351     0.047413   -0.10205\n",
            "  0.036644   -0.048024    0.096963    0.039468   -0.062841    0.00099013\n",
            " -0.080135    0.10347     0.021441   -0.019404   -0.039       0.04467\n",
            "  0.054744   -0.018277   -0.083709   -0.05757    -0.082314    0.0013433\n",
            " -0.014441   -0.013744   -0.044022   -0.069333   -0.029254    0.0098613\n",
            "  0.035343    0.061686   -0.017651    0.010944    0.013254    0.10639\n",
            " -0.047308    0.064784   -0.026801   -0.032312    0.025625   -0.0046599\n",
            " -0.052339   -0.13342     0.085207    0.1169      0.053997   -0.027777\n",
            "  0.0087392  -0.00032659  0.011222   -0.047388    0.040287   -0.020505\n",
            "  0.054466    0.12389     0.07526     0.01384    -0.023496   -0.0024721\n",
            " -0.11258     0.12399    -0.10297    -0.047953    0.059001   -0.079594\n",
            " -0.042394    0.033117   -0.039456    0.0040582   0.13757    -0.0041483\n",
            "  0.084828    0.0015722  -0.079512    0.028027   -0.022389   -0.033654\n",
            " -0.059291   -0.054113   -0.10055     0.057046   -0.16385    -0.0065404\n",
            "  0.0015473   0.013255    0.043591    0.069554   -0.044887    0.057185  ]\n"
          ]
        }
      ],
      "source": [
        "# Get word embeddings\n",
        "sample_embedding = get_word_embedding(model ,df['Word 1'][1])\n",
        "print(sample_embedding.shape)\n",
        "sample_embedding = sample_embedding.squeeze()\n",
        "print(sample_embedding.shape)\n",
        "print(sample_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Check similarity between two words\n",
        "word1 = df['Word 1'][1]\n",
        "word2 = df['Word 1'][1]\n",
        "# Use gensim matutils to calculate cosine similarity\n",
        "w1 = model[word1]\n",
        "w2 = model[word2]\n",
        "\n",
        "print(type(w1))\n",
        "\n",
        "sim = dot(matutils.unitvec(w1), matutils.unitvec(w2))\n",
        "print(sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5VtUjiCFYEmS"
      },
      "outputs": [],
      "source": [
        "# Function to get cosine similarity\n",
        "def cos_similarity(word1_embedding, word2_embedding):\n",
        "    ans = dot(matutils.unitvec(word1_embedding), matutils.unitvec(word2_embedding))\n",
        "    return ans\n",
        "\n",
        "# Function to get Pearson correlation\n",
        "def pearson_correlation(word1_embedding, word2_embedding):\n",
        "    emb1 = np.array(word1_embedding)\n",
        "    emb2 = np.array(word2_embedding)\n",
        "\n",
        "    correlation, _ = pearsonr(emb1, emb2)\n",
        "    return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IS4ZO3nZYEmS"
      },
      "outputs": [],
      "source": [
        "def test_sim(df, lemmatizer, stemmer):\n",
        "    cosine_similarity_scores = []\n",
        "    pearson_correlation_scores = []\n",
        "    scores = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        word1 = row['Word 1']\n",
        "        word2 = row['Word 2']\n",
        "        \n",
        "        # Get embeddings\n",
        "        word1_embedding = get_word_embedding(model,word1).squeeze()\n",
        "        word2_embedding = get_word_embedding(model,word2).squeeze()\n",
        "\n",
        "        # Get cosine similarity\n",
        "        cosine_similarity_scores.append(cos_similarity(word1_embedding, word2_embedding))\n",
        "        \n",
        "        # Get pearson correlation\n",
        "        pearson_correlation_scores.append(pearson_correlation(word1_embedding, word2_embedding))\n",
        "\n",
        "        # Get score\n",
        "        scores.append(row['Human (mean)'])\n",
        "        \n",
        "    return cosine_similarity_scores, pearson_correlation_scores, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yAHRdu3mYEmT"
      },
      "outputs": [],
      "source": [
        "# Get cosine similarity and pearson correlation scores\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "cosine_similarity_scores, pearson_correlation_scores, scores = test_sim(df, lemmatizer, stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGmBkl6HYEmT",
        "outputId": "92fdca3a-a7b3-4260-a7b7-709acc526d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "# Check cosine similarity and pearson correlation scores\n",
        "print(type(cosine_similarity_scores))\n",
        "print(type(pearson_correlation_scores))\n",
        "print(type(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wSAePIQYEmT"
      },
      "source": [
        "### Initial Spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GkScAqhIYEmU"
      },
      "outputs": [],
      "source": [
        "# Funtcion to get spearman correlation using cosine similarity scores\n",
        "def spearman_correlation(cosine_similarity_scores, simlex_scores):\n",
        "    # Scale cosine similarity scores to 0-10\n",
        "    cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
        "    cosine_similarity_scores = (1+cosine_similarity_scores)*5\n",
        "    # cosine_similarity_scores *= 10\n",
        "    simlex_scores = np.array(simlex_scores)\n",
        "\n",
        "    correlation, _ = spearmanr(cosine_similarity_scores, simlex_scores)\n",
        "    return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcwJSCZFYEmU",
        "outputId": "e6fdedb2-5e05-4a4c-c897-2b063dcb5d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Spearman correlation:  0.6943215016552395\n"
          ]
        }
      ],
      "source": [
        "# Print the initial spearman correlation\n",
        "spearman_value_sim = spearman_correlation(cosine_similarity_scores, scores)\n",
        "print(\"Initial Spearman correlation: \", spearman_value_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
