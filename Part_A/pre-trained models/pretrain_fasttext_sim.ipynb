{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTMeYOD4YEmH"
      },
      "outputs": [],
      "source": [
        "# import all necessary packages for CBOW\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import collections\n",
        "import itertools\n",
        "import re\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from torchtext.vocab import GloVe\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kKU7MZluYEmP"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print device name: get_device_name()\n",
        "# print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVjZivZVaHDj",
        "outputId": "23ae1076-f736-4220-a181-83e07a01301a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from gensim import matutils\n",
        "from numpy import dot\n",
        "\n",
        "\n",
        "print(list(api.info()['models'].keys()))\n",
        "\n",
        "# def load_vectors(fname):\n",
        "#     fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "#     n, d = map(int, fin.readline().split())\n",
        "#     data = {}\n",
        "#     for line in fin:\n",
        "#         tokens = line.rstrip().split(' ')\n",
        "#         data[tokens[0]] = map(float, tokens[1:])\n",
        "#     return data\n",
        "\n",
        "# fasttext_data = load_vectors('/content/drive/My Drive/wiki-news-300d-1M.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmiTPflcc8fp",
        "outputId": "f7a2139c-8ab3-442a-9f6e-ad8e71fa82ac"
      },
      "outputs": [],
      "source": [
        "model = api.load('fasttext-wiki-news-subwords-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hwvh57U2fvPR"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "# torch.save(model, './partA_pth/fasttext_subwords300.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jj4xQjUxYEmQ"
      },
      "outputs": [],
      "source": [
        "def get_word_embedding(model ,word):\n",
        "    return model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ_MqpnkNSe3",
        "outputId": "33bafd6c-ae30-4f98-b0c1-cf6dd73d0da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "0.34138656\n",
            "0.34138656\n"
          ]
        }
      ],
      "source": [
        "# Cosine similarity between same words\n",
        "w1 = model['survey']\n",
        "w2 = model['generation']\n",
        "print(type(w1))\n",
        "ans1 = dot(matutils.unitvec(w1), matutils.unitvec(w2))\n",
        "print(ans1)\n",
        "\n",
        "ans2 = model.similarity('survey', 'generation')\n",
        "print(ans2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huamuh-FqtEr",
        "outputId": "678d5b5b-3ea0-4ec2-f145-d1ff69d7c200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between king and queen:  0.7606731653213501\n",
            "Cosine similarity between king and queen:  0.7704245448112488\n",
            "New Distance between king and z:  0.6913657188415527\n",
            "New Cosine similarity between king and z:  0.8185327053070068\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Assuming 'model' is your pre-loaded word embedding model\n",
        "x = torch.tensor(model['king'])\n",
        "y = torch.tensor(model['queen'])\n",
        "# z = king - man + woman\n",
        "z = x - torch.tensor(model['man']) + torch.tensor(model['woman'])\n",
        "\n",
        "# Calculating distances and similarities\n",
        "distance_king_queen = torch.norm(x - y).item()\n",
        "cosine_sim_king_queen = F.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0)).item()\n",
        "distance_king_z = torch.norm(x - z).item()\n",
        "cosine_sim_king_z = F.cosine_similarity(x.unsqueeze(0), z.unsqueeze(0)).item()\n",
        "\n",
        "print(\"Distance between king and queen: \", distance_king_queen)\n",
        "print(\"Cosine similarity between king and queen: \", cosine_sim_king_queen)\n",
        "print(\"New Distance between king and z: \", distance_king_z)\n",
        "print(\"New Cosine similarity between king and z: \", cosine_sim_king_z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYGudSyQrdwX",
        "outputId": "ebf0625e-7c45-4146-b253-3140cd7c07fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "print(type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn0VfmbNYEmR",
        "outputId": "13631a24-77e8-4866-b708-dbe546be1db1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
            "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
            "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
            "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
            "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
            "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
            "\n",
            "   SimAssoc333  SD(SimLex)  \n",
            "0            1        0.41  \n",
            "1            1        0.67  \n",
            "2            1        1.19  \n",
            "3            1        2.18  \n",
            "4            1        0.93  \n"
          ]
        }
      ],
      "source": [
        "# Load test data\n",
        "\n",
        "# Load into dataframe\n",
        "df = pd.read_csv('./SimLex-999/SimLex-999.txt', sep='\\t')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlvgAnOdYEmR",
        "outputId": "2f16963f-4b2b-4af3-996a-481be6491095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300,)\n",
            "(300,)\n",
            "[-0.098387   -0.040395   -0.063524    0.047001   -0.049376    0.011193\n",
            "  0.018136   -0.1185      0.0044093   0.095713    0.0051247   0.043689\n",
            "  0.042151   -0.0049011  -0.064752   -0.064047    0.13787     0.057552\n",
            "  0.10223    -0.010384    0.10026     0.057823   -0.001169    0.062385\n",
            "  0.008071   -0.0072606   0.041832   -0.0215      0.080674    0.0083488\n",
            " -0.018476   -0.06874     0.0059701  -0.050153    0.067923   -0.031816\n",
            "  0.097436    0.050502   -0.027785   -0.022924   -0.019449   -0.1975\n",
            " -0.010258   -0.032903   -0.04815    -0.095292   -0.0098303   0.028774\n",
            "  0.092227   -0.012334   -0.026945   -0.066757    0.012096   -0.026446\n",
            " -0.009822   -0.014377    0.055541    0.011374   -0.045421    0.018927\n",
            " -0.016859   -0.051202    0.065667    0.016558    0.022719    0.026686\n",
            "  0.027099   -0.010242    0.025326   -0.068804    0.059648   -0.05293\n",
            "  0.037331   -0.026011   -0.044675    0.073512   -0.004466   -0.061549\n",
            " -0.024939   -0.06059    -0.020963   -0.092179    0.07017     0.1222\n",
            "  0.066421   -0.027778   -0.059311    0.058259    0.066952   -0.020561\n",
            "  0.033945   -0.029366   -0.14513    -0.059167    0.050733    0.094752\n",
            " -0.03304    -0.046783    0.041046    0.081923    0.03726     0.040919\n",
            " -0.018193   -0.0044806  -0.077842   -0.19023     0.043919    0.052698\n",
            "  0.054283    0.007413   -0.054645    0.028208    0.039316   -0.051226\n",
            " -0.021492   -0.010437   -0.12662    -0.047876   -0.07901     0.039122\n",
            " -0.0022941  -0.046165   -0.0063024  -0.047512    0.14283     0.025698\n",
            " -0.00075288 -0.00195    -0.022772   -0.020317   -0.067267    0.10711\n",
            "  0.053529   -0.034825    0.0025299   0.014775    0.043034    0.017044\n",
            " -0.16418     0.04113     0.09821    -0.043982   -0.0068608  -0.028152\n",
            " -0.013516   -0.0013487  -0.023085    0.089995    0.0079603  -0.001714\n",
            "  0.035721    0.068172    0.022001   -0.093191   -0.062127   -0.037716\n",
            "  0.097513   -0.022418    0.0092425  -0.048937    0.055091    0.0048228\n",
            " -0.0061975  -0.040474    0.010215   -0.074855    0.015019   -0.022322\n",
            "  0.024704    0.071064    0.074467    0.038957   -0.011655    0.0015752\n",
            " -0.051932    0.11072    -0.036666    0.090515   -0.036135    0.0025862\n",
            "  0.020134   -0.02936    -0.08196     0.0069814   0.0457     -0.034443\n",
            " -0.022704    0.13213    -0.07446     0.055898   -0.050292    0.060035\n",
            "  0.018258    0.018632    0.047315    0.002979    0.020472    0.034859\n",
            " -0.00076943  0.018649   -0.14919     0.18358     0.063026    0.067371\n",
            " -0.051357    0.01992    -0.060081   -0.071019   -0.042385   -0.092188\n",
            "  0.054237   -0.01018     0.045651    0.042736    0.031516   -0.039116\n",
            " -0.0091042  -0.057247   -0.13449     0.029908   -0.019895    0.068733\n",
            "  0.013925    0.12615     0.034767   -0.036305    0.10159     0.13027\n",
            " -0.082387   -0.010382    0.055601   -0.029414   -0.05655    -0.056178\n",
            "  0.13965    -0.028431    0.019081   -0.01375    -0.082243    0.0068524\n",
            "  0.1887     -0.0055342   0.0083835   0.055629   -0.16638     0.077831\n",
            " -0.01421     0.0089869   0.075088   -0.088041    0.041938   -0.02508\n",
            " -0.07336    -0.01969     0.036433   -0.036514    0.021585   -0.050104\n",
            "  0.020964    0.071584   -0.016269    0.067191   -0.050347    0.069975\n",
            " -0.021818    0.052963    0.011503    0.038614    0.070191    0.01643\n",
            " -0.09813     0.12542    -0.13547    -0.035608    0.034835   -0.11581\n",
            "  0.036771    0.01222     0.023224   -0.065885    0.076617    0.027859\n",
            " -0.047976   -0.01366    -0.14102    -0.037683   -0.036764   -0.082409\n",
            "  0.0074399  -0.0083583   0.021583    0.038383   -0.020446    0.029659\n",
            "  0.026742   -0.049343    0.011887    0.048145    0.005473    0.010924  ]\n"
          ]
        }
      ],
      "source": [
        "# Get word embeddings\n",
        "sample_embedding = get_word_embedding(model ,df['word1'][1])\n",
        "print(sample_embedding.shape)\n",
        "sample_embedding = sample_embedding.squeeze()\n",
        "print(sample_embedding.shape)\n",
        "print(sample_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Check similarity between two words\n",
        "word1 = df['word1'][1]\n",
        "word2 = df['word1'][1]\n",
        "# Use gensim matutils to calculate cosine similarity\n",
        "w1 = model[word1]\n",
        "w2 = model[word2]\n",
        "\n",
        "print(type(w1))\n",
        "\n",
        "sim = dot(matutils.unitvec(w1), matutils.unitvec(w2))\n",
        "print(sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5VtUjiCFYEmS"
      },
      "outputs": [],
      "source": [
        "# Function to get cosine similarity\n",
        "def cos_similarity(word1_embedding, word2_embedding):\n",
        "    ans = dot(matutils.unitvec(word1_embedding), matutils.unitvec(word2_embedding))\n",
        "    return ans\n",
        "\n",
        "# Function to get Pearson correlation\n",
        "def pearson_correlation(word1_embedding, word2_embedding):\n",
        "    emb1 = np.array(word1_embedding)\n",
        "    emb2 = np.array(word2_embedding)\n",
        "\n",
        "    correlation, _ = pearsonr(emb1, emb2)\n",
        "    return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IS4ZO3nZYEmS"
      },
      "outputs": [],
      "source": [
        "def test_sim(df, lemmatizer, stemmer):\n",
        "    cosine_similarity_scores = []\n",
        "    pearson_correlation_scores = []\n",
        "    simlex_scores = []\n",
        "    assoc_scores = []\n",
        "    for _, row in df.iterrows():\n",
        "        word1 = row['word1']\n",
        "        word2 = row['word2']\n",
        "        form = row['POS']\n",
        "        form = form.lower()\n",
        "       \n",
        "        # Get embeddings\n",
        "        word1_embedding = get_word_embedding(model , word1).squeeze()\n",
        "        word2_embedding = get_word_embedding(model ,word2).squeeze()\n",
        "\n",
        "        # Get cosine similarity\n",
        "        cosine_similarity_scores.append(cos_similarity(word1_embedding, word2_embedding))\n",
        "        # cosine_similarity_scores.append(model.similarity(word1,word2))\n",
        "\n",
        "        # Get pearson correlation\n",
        "        pearson_correlation_scores.append(pearson_correlation(word1_embedding, word2_embedding))\n",
        "\n",
        "        # Get simlex score\n",
        "        simlex_scores.append(row['SimLex999'])\n",
        "\n",
        "        # Get assoc score\n",
        "        assoc_scores.append(row['Assoc(USF)'])\n",
        "\n",
        "    return cosine_similarity_scores, pearson_correlation_scores, simlex_scores, assoc_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yAHRdu3mYEmT"
      },
      "outputs": [],
      "source": [
        "# Get cosine similarity and pearson correlation scores\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "cosine_similarity_scores, pearson_correlation_scores, simlex_scores, assoc_scores = test_sim(df, lemmatizer, stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGmBkl6HYEmT",
        "outputId": "92fdca3a-a7b3-4260-a7b7-709acc526d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "# Check cosine similarity and pearson correlation scores\n",
        "print(type(cosine_similarity_scores))\n",
        "print(type(pearson_correlation_scores))\n",
        "print(type(simlex_scores))\n",
        "print(type(assoc_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wSAePIQYEmT"
      },
      "source": [
        "### Initial Spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GkScAqhIYEmU"
      },
      "outputs": [],
      "source": [
        "# Funtcion to get spearman correlation using cosine similarity scores\n",
        "def spearman_correlation(cosine_similarity_scores, simlex_scores):\n",
        "    # Scale cosine similarity scores to 0-10\n",
        "    cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
        "    cosine_similarity_scores = (1+cosine_similarity_scores)*5\n",
        "    # cosine_similarity_scores *= 10\n",
        "    simlex_scores = np.array(simlex_scores)\n",
        "\n",
        "    correlation, _ = spearmanr(cosine_similarity_scores, simlex_scores)\n",
        "    return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcwJSCZFYEmU",
        "outputId": "e6fdedb2-5e05-4a4c-c897-2b063dcb5d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Spearman correlation Sim:  0.44090807476822663\n",
            "Initial Spearman correlation Assoc:  0.43975997475619183\n"
          ]
        }
      ],
      "source": [
        "# Print the initial spearman correlation\n",
        "spearman_value_sim = spearman_correlation(cosine_similarity_scores, simlex_scores)\n",
        "spearman_value_assoc = spearman_correlation(cosine_similarity_scores, assoc_scores)\n",
        "print(\"Initial Spearman correlation Sim: \", spearman_value_sim)\n",
        "print(\"Initial Spearman correlation Assoc: \", spearman_value_assoc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get df for verbs, adjectives and nouns separately\n",
        "def get_pos_df(df):\n",
        "    verb_df = df[df['POS'] == 'V']\n",
        "    adj_df = df[df['POS'] == 'A']\n",
        "    noun_df = df[df['POS'] == 'N']\n",
        "\n",
        "    return verb_df, adj_df, noun_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get dfs for verbs, adjectives and nouns\n",
        "verb_df, adj_df, noun_df = get_pos_df(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cosine similarity and pearson correlation scores for verbs, adjectives and nouns\n",
        "verb_cosine_similarity_scores, verb_pearson_correlation_scores, verb_simlex_scores, verb_assoc_scores = test_sim(verb_df, lemmatizer, stemmer)\n",
        "adj_cosine_similarity_scores, adj_pearson_correlation_scores, adj_simlex_scores, adj_assoc_scores = test_sim(adj_df, lemmatizer, stemmer)\n",
        "noun_cosine_similarity_scores, noun_pearson_correlation_scores, noun_simlex_scores, noun_assoc_scores = test_sim(noun_df, lemmatizer, stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman correlation Sim for verbs:  0.25777445566511625\n",
            "Spearman correlation Sim for adjectives:  0.5781412840320306\n",
            "Spearman correlation Sim for nouns:  0.495787237895295\n"
          ]
        }
      ],
      "source": [
        "# Get spearman correlation for verbs, adjectives and nouns\n",
        "verb_spearman_value_sim = spearman_correlation(verb_cosine_similarity_scores, verb_simlex_scores)\n",
        "adj_spearman_value_sim = spearman_correlation(adj_cosine_similarity_scores, adj_simlex_scores)\n",
        "noun_spearman_value_sim = spearman_correlation(noun_cosine_similarity_scores, noun_simlex_scores)\n",
        "\n",
        "# Print spearman correlation for verbs, adjectives and nouns\n",
        "print(\"Spearman correlation Sim for verbs: \", verb_spearman_value_sim)\n",
        "print(\"Spearman correlation Sim for adjectives: \", adj_spearman_value_sim)\n",
        "print(\"Spearman correlation Sim for nouns: \", noun_spearman_value_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPFbnvRhYEmU",
        "outputId": "c2f25a18-a0a3-4ffd-ea83-e872b1d59a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
            "0    old          new   A       1.58        7.25           0.733461   \n",
            "1  smart  intelligent   A       9.20        7.11           0.772989   \n",
            "2   hard    difficult   A       8.77        5.94           0.729391   \n",
            "3  happy     cheerful   A       9.55        5.85           0.684763   \n",
            "4   hard         easy   A       0.95        5.82           0.676172   \n",
            "\n",
            "   Pearson Correlation  \n",
            "0             0.732009  \n",
            "1             0.772902  \n",
            "2             0.729263  \n",
            "3             0.685333  \n",
            "4             0.676259  \n"
          ]
        }
      ],
      "source": [
        "# Make a dataframe of cosine similarity scores and pearson correlation scores along with Simlex-999 scores and Assoc(USF)\n",
        "simlex_scores = df['SimLex999']\n",
        "assoc_scores = df['Assoc(USF)']\n",
        "cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
        "pearson_correlation_scores = np.array(pearson_correlation_scores)\n",
        "simlex_scores = np.array(simlex_scores)\n",
        "assoc_scores = np.array(assoc_scores)\n",
        "# print(cosine_similarity_scores.shape)\n",
        "# print(pearson_correlation_scores.shape)\n",
        "\n",
        "# Make a dataframe along with word1, word2, POS, SimLex-999 scores, Assoc(USF), cosine similarity scores and pearson correlation scores\n",
        "datat = {'word1': df['word1'], 'word2': df['word2'], 'POS': df['POS'], 'SimLex999': simlex_scores, 'Assoc(USF)': assoc_scores, 'Cosine Similarity': cosine_similarity_scores, 'Pearson Correlation': pearson_correlation_scores}\n",
        "ndf = pd.DataFrame(data=datat)\n",
        "print(ndf.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CFskrMFYEmV",
        "outputId": "d7f0dc1a-caf9-4ad6-96e7-be3e46814220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
            "0       old          new   A       1.58        7.25           0.733461   \n",
            "1     smart  intelligent   A       9.20        7.11           0.772989   \n",
            "2      hard    difficult   A       8.77        5.94           0.729391   \n",
            "3     happy     cheerful   A       9.55        5.85           0.684763   \n",
            "4      hard         easy   A       0.95        5.82           0.676172   \n",
            "..      ...          ...  ..        ...         ...                ...   \n",
            "994    join      acquire   V       2.85        0.00           0.452802   \n",
            "995    send       attend   V       1.67        0.00           0.536103   \n",
            "996  gather       attend   V       4.80        0.00           0.552808   \n",
            "997  absorb     withdraw   V       2.97        0.00           0.447016   \n",
            "998  attend       arrive   V       6.08        0.00           0.559992   \n",
            "\n",
            "     Pearson Correlation  \n",
            "0               0.732009  \n",
            "1               0.772902  \n",
            "2               0.729263  \n",
            "3               0.685333  \n",
            "4               0.676259  \n",
            "..                   ...  \n",
            "994             0.454957  \n",
            "995             0.536426  \n",
            "996             0.552408  \n",
            "997             0.446165  \n",
            "998             0.559620  \n",
            "\n",
            "[999 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "# Print df\n",
        "print(ndf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUrIXdB8YEmV"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QgQ3ZYNNYEmV"
      },
      "outputs": [],
      "source": [
        "# Create Dataset\n",
        "def create_dataset(df, model):\n",
        "    # Create a list of tuples\n",
        "    emb1 = []\n",
        "    emb2 = []\n",
        "    simlex_scores = []\n",
        "    assoc_scores = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        word1 = row['word1']\n",
        "        word2 = row['word2']\n",
        "        emb1.append(torch.tensor(get_word_embedding(model ,word1)))\n",
        "        emb2.append(torch.tensor(get_word_embedding(model, word2)))\n",
        "        simlex_scores.append(row['SimLex999'])\n",
        "        assoc_scores.append(row['Assoc(USF)'])\n",
        "\n",
        "    # print(emb1[0].shape)\n",
        "    emb1_stack = torch.stack(emb1)\n",
        "    emb2_stack = torch.stack(emb2)\n",
        "\n",
        "    return emb1_stack, emb2_stack, torch.tensor(simlex_scores, dtype=torch.float), torch.tensor(assoc_scores, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6QIqgpanYEmV"
      },
      "outputs": [],
      "source": [
        "# Call create_dataset\n",
        "train_df, test_df = train_test_split(ndf, test_size=0.1, random_state=42)\n",
        "train_emb1, train_emb2, train_simlex_scores, train_assoc_scores = create_dataset(train_df, model)\n",
        "test_emb1, test_emb2, test_simlex_scores, test_assoc_scores = create_dataset(test_df, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZPokpiVYEmV",
        "outputId": "0ae3293d-67bb-42ce-9d16-721211b6707d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([899, 300])\n",
            "torch.Size([899])\n"
          ]
        }
      ],
      "source": [
        "# check train_emb1\n",
        "print(train_emb1.shape)\n",
        "print(train_simlex_scores.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P5kAt8SvYEmV"
      },
      "outputs": [],
      "source": [
        "# Creare TensorDataset\n",
        "train_dataset = torch.utils.data.TensorDataset(train_emb1, train_emb2, train_simlex_scores, train_assoc_scores)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_emb1, test_emb2, test_simlex_scores, test_assoc_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "21mivCSlYEmV"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ONe7J_7TYEmV"
      },
      "outputs": [],
      "source": [
        "# Class that takes CBOW embeddings, and outputs similarity scores: loss is MSE between predicted similarity scores and actual similarity scores(Simlex-999)\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(2*embedding_dim, 50)\n",
        "        self.linear2 = nn.Linear(50, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, emb1, emb2):\n",
        "        # emb1 = emb1.squeeze()\n",
        "        # emb2 = emb2.squeeze()\n",
        "        emb = torch.cat((emb1, emb2), dim=1)\n",
        "\n",
        "        out = self.linear1(emb)\n",
        "        out = F.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        # Project the output between 0 and 10\n",
        "        out = torch.sigmoid(out)\n",
        "        out = out*10\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xWPQHgkIYEmW"
      },
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "embedding_dim = 300\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Initialize model\n",
        "model = RegressionModel(embedding_dim).to(device)\n",
        "# Define loss function\n",
        "criterion = nn.MSELoss()\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01) # weight_decay is L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzH7IVtJYEmW"
      },
      "outputs": [],
      "source": [
        "# Function to train model\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        for emb1, emb2, simlex_scores, assoc_scores in train_loader:\n",
        "            emb1 = emb1.to(device)\n",
        "            emb2 = emb2.to(device)\n",
        "            simlex_scores = simlex_scores.to(device)\n",
        "            assoc_scores = assoc_scores.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(emb1, emb2)\n",
        "\n",
        "            simlex_scores = simlex_scores.unsqueeze(1)\n",
        "            # print(outputs[0])\n",
        "            loss = criterion(outputs, simlex_scores)\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        print(\"Epoch: {}, Train_Loss: {}\".format(epoch+1, train_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVP5LkXYYEmW",
        "outputId": "e0c79a51-a67f-4e8d-c2dd-b3d1bd556fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train_Loss: 6.877282257737784\n",
            "Epoch: 2, Train_Loss: 6.677323201465267\n",
            "Epoch: 3, Train_Loss: 6.511966030459557\n",
            "Epoch: 4, Train_Loss: 6.238854689182254\n",
            "Epoch: 5, Train_Loss: 6.121467920650745\n",
            "Epoch: 6, Train_Loss: 5.827177930580805\n",
            "Epoch: 7, Train_Loss: 5.6249357088101055\n",
            "Epoch: 8, Train_Loss: 5.694390595725529\n",
            "Epoch: 9, Train_Loss: 5.340702848214232\n",
            "Epoch: 10, Train_Loss: 5.307537023931341\n",
            "Epoch: 11, Train_Loss: 5.2304604116770586\n",
            "Epoch: 12, Train_Loss: 4.971509925468533\n",
            "Epoch: 13, Train_Loss: 4.92602253754741\n",
            "Epoch: 14, Train_Loss: 4.828319475842552\n",
            "Epoch: 15, Train_Loss: 4.715968417223603\n",
            "Epoch: 16, Train_Loss: 4.567144403755539\n",
            "Epoch: 17, Train_Loss: 4.380131288160533\n",
            "Epoch: 18, Train_Loss: 4.335268984025568\n",
            "Epoch: 19, Train_Loss: 4.150991686794464\n",
            "Epoch: 20, Train_Loss: 4.055382589109098\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "train(model, train_loader, criterion, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZv8YlEYEmW"
      },
      "outputs": [],
      "source": [
        "# Function to test model, Calculate test loss and Spearman correlation\n",
        "def test(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    true_simlex_scores = []\n",
        "    pred_simlex_scores = []\n",
        "    for emb1, emb2, simlex_scores, assoc_scores in test_loader:\n",
        "        emb1 = emb1.to(device)\n",
        "        emb2 = emb2.to(device)\n",
        "        simlex_scores = simlex_scores.to(device)\n",
        "        assoc_scores = assoc_scores.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(emb1, emb2)\n",
        "        simlex_scores = simlex_scores.unsqueeze(1)\n",
        "        loss = criterion(outputs, simlex_scores)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Get true labels and predicted labels\n",
        "        true_simlex_scores.extend(simlex_scores.cpu().detach().numpy().tolist())\n",
        "        pred_simlex_scores.extend(outputs.cpu().detach().numpy().tolist())\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    print(\"Test_Loss: {}\".format(test_loss))\n",
        "    # Calculate Spearman correlation\n",
        "    # print(\"True Simlex scores: \", true_simlex_scores)\n",
        "    # print(\"Predicted Simlex scores: \", pred_simlex_scores)\n",
        "\n",
        "    true_simlex_scores = np.array(true_simlex_scores)\n",
        "    pred_simlex_scores = np.array(pred_simlex_scores)\n",
        "    spear = spearmanr(true_simlex_scores, pred_simlex_scores)\n",
        "    print(\"Spearman correlation: {}\".format(spear[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j18dnwohYEmW",
        "outputId": "9fb413e6-b30a-4579-bfee-4f147103a5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_Loss: 6.341392397880554\n",
            "Spearman correlation: 0.2820332028297094\n"
          ]
        }
      ],
      "source": [
        "# Test model\n",
        "test(model, test_loader, criterion)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
