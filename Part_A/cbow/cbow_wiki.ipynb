{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:20.887951Z",
     "iopub.status.busy": "2024-07-29T06:26:20.887064Z",
     "iopub.status.idle": "2024-07-29T06:26:20.900052Z",
     "shell.execute_reply": "2024-07-29T06:26:20.899187Z",
     "shell.execute_reply.started": "2024-07-29T06:26:20.887915Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mImportError\u001b[0m\u001b[0;31m:\u001b[0m cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages for CBOW\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from torchtext.vocab import GloVe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import matutils\n",
    "from numpy import dot\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:22.259975Z",
     "iopub.status.busy": "2024-07-29T06:26:22.259524Z",
     "iopub.status.idle": "2024-07-29T06:26:22.329202Z",
     "shell.execute_reply": "2024-07-29T06:26:22.328402Z",
     "shell.execute_reply.started": "2024-07-29T06:26:22.259940Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print device name: get_device_name()\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:22.941477Z",
     "iopub.status.busy": "2024-07-29T06:26:22.940708Z",
     "iopub.status.idle": "2024-07-29T06:26:22.946606Z",
     "shell.execute_reply": "2024-07-29T06:26:22.945915Z",
     "shell.execute_reply.started": "2024-07-29T06:26:22.941444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from file and store list of sentences where sentences are list of words\n",
    "class MakeSentences():\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.sentences = self.read_file()\n",
    "\n",
    "    def read_file(self):\n",
    "        sentences = []\n",
    "        with open(self.file_name, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                sentences += ([x for x in line.strip().split('.') if x!=''])\n",
    "                i+=1\n",
    "                if i==10000:\n",
    "                    break\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:23.297267Z",
     "iopub.status.busy": "2024-07-29T06:26:23.296550Z",
     "iopub.status.idle": "2024-07-29T06:26:23.329780Z",
     "shell.execute_reply": "2024-07-29T06:26:23.329044Z",
     "shell.execute_reply.started": "2024-07-29T06:26:23.297235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25137\n"
     ]
    }
   ],
   "source": [
    "sentences = MakeSentences('../wikitext-2-raw-v1/wikitext-2-raw/wiki.train.raw').sentences\n",
    "print(len(sentences))\n",
    "# for sentence in sentences:\n",
    "#     print(type(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:23.577478Z",
     "iopub.status.busy": "2024-07-29T06:26:23.576753Z",
     "iopub.status.idle": "2024-07-29T06:26:23.581018Z",
     "shell.execute_reply": "2024-07-29T06:26:23.580309Z",
     "shell.execute_reply.started": "2024-07-29T06:26:23.577445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Valkyria Chronicles III =\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:24.195863Z",
     "iopub.status.busy": "2024-07-29T06:26:24.195483Z",
     "iopub.status.idle": "2024-07-29T06:26:24.207596Z",
     "shell.execute_reply": "2024-07-29T06:26:24.206897Z",
     "shell.execute_reply.started": "2024-07-29T06:26:24.195833Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class Preprocess():\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def tokenize(self):\n",
    "        # Split sentences into words using regex to handle various punctuation\n",
    "        self.sentences = [re.findall(r'\\b\\w+\\b', sentence.lower()) for sentence in self.sentences]\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.sentences = [[word.lower() for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_stop_words(self):\n",
    "        # Common English stop words; expand as necessary\n",
    "        stop_words = set([\"the\", \"is\", \"at\", \"which\", \"on\", \"and\", \"a\", \"an\"])\n",
    "        self.sentences = [[word for word in sentence if word not in stop_words] for sentence in self.sentences]\n",
    "\n",
    "    def stemmer(self):\n",
    "        # Simple stemming using suffix stripping, can be improved\n",
    "        def simple_stem(word):\n",
    "            suffixes = [\"ing\", \"ly\", \"ed\", \"ious\", \"ies\", \"ive\", \"es\", \"s\", \"ment\"]\n",
    "            for suffix in sorted(suffixes, key=len, reverse=True):\n",
    "                if word.endswith(suffix):\n",
    "                    return word[:-len(suffix)]\n",
    "            return word\n",
    "        self.sentences = [[simple_stem(word) for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        self.sentences = [[word for word in sentence if word.isalpha()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        self.sentences = [[word for word in sentence if not word.isdigit()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_single_letter(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 1] for sentence in self.sentences]\n",
    "\n",
    "    def remove_extra_spaces(self):\n",
    "        self.sentences = [[word for word in sentence if word.strip()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_less_than_3(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 2] for sentence in self.sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:24.529464Z",
     "iopub.status.busy": "2024-07-29T06:26:24.528893Z",
     "iopub.status.idle": "2024-07-29T06:26:25.745473Z",
     "shell.execute_reply": "2024-07-29T06:26:25.744593Z",
     "shell.execute_reply.started": "2024-07-29T06:26:24.529432Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done\n",
      "25137\n"
     ]
    }
   ],
   "source": [
    "# preprocess\n",
    "preprocess = Preprocess(sentences)\n",
    "preprocess.tokenize()\n",
    "# print(preprocess.sentences)\n",
    "preprocess.lowercase()\n",
    "preprocess.remove_stop_words()\n",
    "# preprocess.stemmer()\n",
    "preprocess.remove_punctuation()\n",
    "preprocess.remove_numbers()\n",
    "preprocess.remove_single_letter()\n",
    "preprocess.remove_extra_spaces()\n",
    "preprocess.remove_less_than_3()\n",
    "\n",
    "print(\"Preprocessing done\")\n",
    "# print(preprocess.sentences)\n",
    "sentences = preprocess.sentences\n",
    "print(len(sentences))\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:25.747472Z",
     "iopub.status.busy": "2024-07-29T06:26:25.747092Z",
     "iopub.status.idle": "2024-07-29T06:26:25.886459Z",
     "shell.execute_reply": "2024-07-29T06:26:25.885620Z",
     "shell.execute_reply.started": "2024-07-29T06:26:25.747442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab:  30214\n",
      "Most common words:  [('was', 5340), ('that', 3928), ('for', 3841), ('with', 3758), ('from', 2329), ('his', 2328), ('were', 1987), ('had', 1638), ('are', 1262), ('her', 1248)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten list of sentences into list of words\n",
    "word_list = list(itertools.chain.from_iterable(sentences))\n",
    "# print(word_list)\n",
    "\n",
    "# Create a vocabulary of words\n",
    "word_freq = Counter(word_list)\n",
    "\n",
    "# Remove words that occur less than 5 times\n",
    "vocab = set(word if word_freq[word] > 0 else '<unk>' for word in word_list)\n",
    "# print(vocab)\n",
    "\n",
    "# Add padding and unknown token to vocab\n",
    "vocab.add('<pad>')\n",
    "vocab.add('<unk>')\n",
    "# Add start and end token to vocab\n",
    "vocab.add('<start>')\n",
    "vocab.add('<end>')\n",
    "\n",
    "# Print length of vocab\n",
    "print(\"Size of vocab: \", len(vocab))\n",
    "\n",
    "# Create word to index and index to word mapping\n",
    "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx:word for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Print most common words\n",
    "print(\"Most common words: \", word_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:25.887981Z",
     "iopub.status.busy": "2024-07-29T06:26:25.887523Z",
     "iopub.status.idle": "2024-07-29T06:26:25.891432Z",
     "shell.execute_reply": "2024-07-29T06:26:25.890725Z",
     "shell.execute_reply.started": "2024-07-29T06:26:25.887951Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20982\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(word_to_idx['intelligent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:25.893123Z",
     "iopub.status.busy": "2024-07-29T06:26:25.892826Z",
     "iopub.status.idle": "2024-07-29T06:26:25.918013Z",
     "shell.execute_reply": "2024-07-29T06:26:25.917334Z",
     "shell.execute_reply.started": "2024-07-29T06:26:25.893094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define constants\n",
    "window_size = 2\n",
    "sliding_window = 2 * window_size + 1\n",
    "num_neg_samples = 1\n",
    "\n",
    "# sentences = [sentences[0]]\n",
    "# print(sentences)\n",
    "\n",
    "def get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_sample):\n",
    "    X = []\n",
    "    y = [] \n",
    "    for sentence in sentences:\n",
    "        # add start and end token to sentence\n",
    "        sentence = ['<start>'] + sentence + ['<end>']\n",
    "        for i in range(len(sentence)):\n",
    "            target_word = sentence[i]\n",
    "            # print(\"target word: \", target_word)\n",
    "            context_words = []\n",
    "            temp1 = max(0,i - window_size)\n",
    "            temp2 = min(len(sentence)-1,i + window_size + 1)\n",
    "            # print(\"temp1: \", temp1)\n",
    "            # print(\"temp2: \", temp2)\n",
    "            for j in range(max(0,i - window_size),min(len(sentence)-1,i + window_size)+1):\n",
    "                if j != i:\n",
    "                    # print(sentence[j])\n",
    "                    context_words.append(sentence[j])\n",
    "                # print(\"context words: \", context_words)\n",
    "\n",
    "            \n",
    "            # pad context words if length is less than sliding window\n",
    "            if len(context_words) < sliding_window:\n",
    "                context_words += ['<pad>'] * (sliding_window - len(context_words)-1)\n",
    "            \n",
    "            context_words.append(target_word)\n",
    "            # print(\"length of context words: \", len(context_words))\n",
    "\n",
    "            # get positive samples \n",
    "            positive_samples = [word_to_idx[word] if word in vocab else word_to_idx['<unk>'] for word in context_words]\n",
    "            # print(\"lenght of positive samples: \", len(positive_samples))\n",
    "            \n",
    "            X.append(positive_samples)\n",
    "            y.append(1)\n",
    "\n",
    "\n",
    "            # get negative samples\n",
    "            for _ in range(num_neg_samples):\n",
    "                negative_samples = positive_samples[:-1]  # Start with the same context\n",
    "                neg_sample = random.choice(list(vocab))\n",
    "                while neg_sample in context_words:  # Ensure the negative sample is not in the context\n",
    "                    neg_sample = random.choice(list(vocab))\n",
    "                \n",
    "                negative_samples.append(word_to_idx[neg_sample])  # Add a random negative sample\n",
    "                X.append(negative_samples)\n",
    "                y.append(0)\n",
    "                \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:26:26.041400Z",
     "iopub.status.busy": "2024-07-29T06:26:26.040983Z",
     "iopub.status.idle": "2024-07-29T06:32:02.182666Z",
     "shell.execute_reply": "2024-07-29T06:32:02.181806Z",
     "shell.execute_reply.started": "2024-07-29T06:26:26.041372Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating samples\n",
      "Samples created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating samples\")\n",
    "X = []\n",
    "y = []\n",
    "X,y = get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_samples)\n",
    "print(\"Samples created\")\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:02.184853Z",
     "iopub.status.busy": "2024-07-29T06:32:02.184342Z",
     "iopub.status.idle": "2024-07-29T06:32:06.924432Z",
     "shell.execute_reply": "2024-07-29T06:32:06.923719Z",
     "shell.execute_reply.started": "2024-07-29T06:32:02.184822Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "data = list(zip(X,y))\n",
    "random.shuffle(data)\n",
    "X,y = zip(*data)\n",
    "\n",
    "# Turn into numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:06.925984Z",
     "iopub.status.busy": "2024-07-29T06:32:06.925464Z",
     "iopub.status.idle": "2024-07-29T06:32:07.010131Z",
     "shell.execute_reply": "2024-07-29T06:32:07.009492Z",
     "shell.execute_reply.started": "2024-07-29T06:32:06.925953Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save X and y\n",
    "np.save('./datasets/wiki_X_25k.npy', X)\n",
    "np.save('./datasets/wiki_y_25k.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:07.012341Z",
     "iopub.status.busy": "2024-07-29T06:32:07.011858Z",
     "iopub.status.idle": "2024-07-29T06:32:07.106626Z",
     "shell.execute_reply": "2024-07-29T06:32:07.105771Z",
     "shell.execute_reply.started": "2024-07-29T06:32:07.012311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load X and y\n",
    "X = np.load('./datasets/wiki_X_25k.npy')\n",
    "y = np.load('./datasets/wiki_y_25k.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:07.107889Z",
     "iopub.status.busy": "2024-07-29T06:32:07.107625Z",
     "iopub.status.idle": "2024-07-29T06:32:07.115515Z",
     "shell.execute_reply": "2024-07-29T06:32:07.114936Z",
     "shell.execute_reply.started": "2024-07-29T06:32:07.107860Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the forward pass for CBOW\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # self.embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # extract context and target from x\n",
    "        context = x[:, :-1]\n",
    "        target = x[:, -1]\n",
    "\n",
    "        context_embedding = self.embeddings(context)\n",
    "        context_embedding = torch.mean(context_embedding, dim=1)\n",
    "        target_embedding = self.embeddings(target)\n",
    "\n",
    "        # take dot product of context embedding and target embedding\n",
    "        score = torch.sum(context_embedding * target_embedding, dim=1)\n",
    "        return F.sigmoid(score)\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        out = self.embeddings.weight.data\n",
    "        return out.cpu().numpy()\n",
    "    \n",
    "    def get_word_embedding(self, word):\n",
    "        # If word is not in vocab, return unk\n",
    "        if word not in word_to_idx:\n",
    "            word = '<unk>'\n",
    "        word_tensor = torch.LongTensor([word_to_idx[word]])\n",
    "        word_tensor = word_tensor.to(next(self.parameters()).device)\n",
    "        out = self.embeddings(word_tensor).data\n",
    "        return out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:07.116584Z",
     "iopub.status.busy": "2024-07-29T06:32:07.116346Z",
     "iopub.status.idle": "2024-07-29T06:32:08.106999Z",
     "shell.execute_reply": "2024-07-29T06:32:08.106318Z",
     "shell.execute_reply.started": "2024-07-29T06:32:07.116557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Create model, loss function and optimizer\n",
    "model = CBOW(vocab_size, embedding_dim)\n",
    "model.to(device)\n",
    "# Cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define dataloader\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(X).long(), torch.from_numpy(y).float())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:08.108422Z",
     "iopub.status.busy": "2024-07-29T06:32:08.107931Z",
     "iopub.status.idle": "2024-07-29T06:32:08.184820Z",
     "shell.execute_reply": "2024-07-29T06:32:08.184185Z",
     "shell.execute_reply.started": "2024-07-29T06:32:08.108392Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1283, 29797, 14955, 23826,  1008],\n",
      "        [21967, 28168,  9344,  9344,  2282],\n",
      "        [ 9493, 14488,  9344,  9344, 28596],\n",
      "        [ 2282,  6226,  6404, 17017, 16856],\n",
      "        [25702,  3649,  7377, 28596, 27949],\n",
      "        [15682, 14583,  9344,  9344, 28596],\n",
      "        [ 7866, 15179, 28168, 28596, 21554],\n",
      "        [25870,  2549,  9344,  9344,  2282],\n",
      "        [ 2907,  5948,  5666,  7231, 15575],\n",
      "        [ 2282, 15071, 27501, 27142, 12812],\n",
      "        [15599,  2550, 25617, 14390, 20976],\n",
      "        [ 2554, 12389, 23688, 28669,  7608],\n",
      "        [ 6882, 28596,  9344,  9344,  2282],\n",
      "        [26932,  2347, 25364, 22827,  7162],\n",
      "        [ 3063, 19985,  6016, 19058,  7947],\n",
      "        [23078, 22155, 21109,  8327, 21539],\n",
      "        [12075, 18473, 19823,  5205, 18427],\n",
      "        [ 2282,  8892, 27303, 20498, 25376],\n",
      "        [ 2282,  8154,  4626, 15906, 10092],\n",
      "        [ 2079,  5072, 21840,  4932, 10783],\n",
      "        [16810, 13205,  9526,  1573, 16444],\n",
      "        [ 2077, 29935, 28596,  9344, 16921],\n",
      "        [ 6509,  9764, 10972, 12827, 13913],\n",
      "        [ 2282, 30158, 22539,  1576, 17602],\n",
      "        [ 2282, 15689,  1227, 17086,  4788],\n",
      "        [21269,  7357, 23981,  9279,  8764],\n",
      "        [21109, 17415, 27142,  4498,  1121],\n",
      "        [ 3051,  9972, 27580, 30177, 20982],\n",
      "        [13912, 21109, 10571, 10286, 16031],\n",
      "        [ 2282, 29122,  6143,  9344,  1790],\n",
      "        [ 5712, 29602,  5712, 29602,  4279],\n",
      "        [ 3155, 15960,  7944, 18994, 16967],\n",
      "        [ 9481, 12493, 24472, 24866, 29132],\n",
      "        [21109, 22742,  7884,  9526, 21089],\n",
      "        [ 2282,  9344,  9344,  9344, 28596],\n",
      "        [25698, 28799, 28527,  8448, 29398],\n",
      "        [29947,  3521, 25620,  4539,  7271],\n",
      "        [ 6792, 12724, 22034, 27142,  4056],\n",
      "        [ 5634,  1841, 17425,  9526, 10699],\n",
      "        [ 1599,  9764, 22405, 13156,  1481],\n",
      "        [14933,  4932, 27142, 22891, 14024],\n",
      "        [29935, 23837,  6730, 28596, 17452],\n",
      "        [22827, 20305,  9344,  9344,  2282],\n",
      "        [ 3281, 27780, 13967,  9291, 13918],\n",
      "        [27323, 23694, 16107, 28596, 17988],\n",
      "        [10413, 21012,  4033,  8594, 27142],\n",
      "        [13097, 16041, 15242, 29457, 15179],\n",
      "        [25620,  5666, 10387,  7434, 20785],\n",
      "        [12389, 10271, 27886, 18997, 14634],\n",
      "        [ 2282, 23208, 27504, 17689, 14508],\n",
      "        [21457, 16644, 20090, 12389, 25133],\n",
      "        [15531, 28811,  8164, 11566, 14279],\n",
      "        [17906,    57, 23961,  3136, 13821],\n",
      "        [10331,  9667,  6747, 12493, 26204],\n",
      "        [ 2282,    57, 20248,  9344, 20339],\n",
      "        [ 8145, 10320, 13607,  6114, 13879],\n",
      "        [25544, 13035, 29391, 13097,  5634],\n",
      "        [20291, 12389, 15582, 16471, 23114],\n",
      "        [ 2282, 26226, 16672, 12724,  5948],\n",
      "        [14389, 25458,  7344, 12304, 11028],\n",
      "        [27207,   458, 12649, 23961, 11478],\n",
      "        [ 9348, 10706, 26440, 20921, 18643],\n",
      "        [22592, 27434, 28016, 16791,   850],\n",
      "        [  777, 28168,  9344,  9344, 28596],\n",
      "        [ 2907, 24601,  9344,  9344,  4524],\n",
      "        [14280, 27397, 16471,  8823, 19926],\n",
      "        [ 2282, 14558, 27142, 16583, 12903],\n",
      "        [10649,  7227,  8247, 29227, 26204],\n",
      "        [ 2282, 14831,    78, 26204,  5134],\n",
      "        [11634,  5505,  6060, 28596, 17736],\n",
      "        [21109, 14989, 18739, 28596, 23774],\n",
      "        [18750,  4007,  2577, 16031, 22364],\n",
      "        [ 6256, 25635,  9344,  9344, 18455],\n",
      "        [17242,  7716,  9344,  9344, 17283],\n",
      "        [ 2368, 27142,  9344,  9344, 27027],\n",
      "        [12350,  3377, 20749, 21695, 22183],\n",
      "        [ 2282, 27142, 28457,  9344,  3820],\n",
      "        [20287, 19506, 13712,  3457,  4649],\n",
      "        [10889, 21828, 22018,  3457, 29995],\n",
      "        [13097,   965, 27048, 26653,  7162],\n",
      "        [18115, 23454,  3457, 20281,  8218],\n",
      "        [24674,  4328, 25681, 19693, 16909],\n",
      "        [ 7329, 24974,   696, 23078, 22794],\n",
      "        [ 7783, 24974, 24619, 18025,  8171],\n",
      "        [11561, 12389, 20296, 22155,  1262],\n",
      "        [ 8029, 12389, 25104, 27823, 12724],\n",
      "        [16734, 12812,  5634, 20248,  3664],\n",
      "        [24704, 25620, 23888, 27142,  7015],\n",
      "        [19241,  7944, 27099, 29935, 16084],\n",
      "        [13927, 16723, 25641, 24437,  5438],\n",
      "        [21502, 14640,  6824, 18809, 26014],\n",
      "        [23078, 12724,  8783, 24073, 13528],\n",
      "        [ 9458, 17267, 15071,  3457,  9140],\n",
      "        [ 7700, 11386,  9344,  9344, 10969],\n",
      "        [14348,   514, 11666,  8083, 29144],\n",
      "        [ 8892, 20873, 17110, 17959, 18983],\n",
      "        [ 1225,  2601, 10371, 17839, 16689],\n",
      "        [16126, 27123,  9526,  4643, 14738],\n",
      "        [ 9846, 14977, 30107, 25013, 10420],\n",
      "        [ 1053, 22218, 10324, 21269,  4845],\n",
      "        [ 1624,  2813,  7916, 21520, 27142],\n",
      "        [20961, 23504,  1249, 26826, 23560],\n",
      "        [ 1413, 11797,  9344,  9344, 18764],\n",
      "        [ 2282, 20248, 14175,  9344, 20577],\n",
      "        [ 4932, 28603, 22590, 21340,  8860],\n",
      "        [ 2282,  9526, 11936,  3995, 19011],\n",
      "        [11168, 12221,  6277, 14436, 12230],\n",
      "        [12880, 25012, 11815, 25012, 22496],\n",
      "        [ 7120,  5666, 28596,  9344,  4541],\n",
      "        [16637, 21109, 19282,   720, 19736],\n",
      "        [10493, 15207,  4932,  5404, 24776],\n",
      "        [23087, 24384,  9344,  9344, 22414],\n",
      "        [21247, 19970, 28078, 20994, 12724],\n",
      "        [22363, 12976, 15019, 13473, 30032],\n",
      "        [ 2079,  7231,   892,  4313, 22357],\n",
      "        [ 4932, 11805, 28596,  9344, 21665],\n",
      "        [23760,  5997,  9344,  9344, 28596],\n",
      "        [26479, 10070, 14716, 17017, 10578],\n",
      "        [19895,  4895, 13230, 15289, 29283],\n",
      "        [ 2282,  8154,  5666,  5997, 22222],\n",
      "        [23190, 23794, 15778,  1673, 16145],\n",
      "        [ 7015,  4670, 18703, 12221,  1053],\n",
      "        [ 4307, 11206, 24379, 14192, 12724],\n",
      "        [23297,   820, 28331, 23323, 22162],\n",
      "        [27142, 18357, 25902, 26282,  9526],\n",
      "        [12389, 10362,   120,  9962,  5865],\n",
      "        [28216, 24619, 11106, 18371,  2556],\n",
      "        [ 1990,   733, 14075, 28596,  9764]])\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Check dataset\n",
    "for i, (inputs, targets) in enumerate(dataloader):\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:08.186238Z",
     "iopub.status.busy": "2024-07-29T06:32:08.185781Z",
     "iopub.status.idle": "2024-07-29T06:32:08.192181Z",
     "shell.execute_reply": "2024-07-29T06:32:08.191644Z",
     "shell.execute_reply.started": "2024-07-29T06:32:08.186208Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train CBOW model\n",
    "def train(model, criterion, optimizer, dataloader, epochs):\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        labels = []\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # get predictions\n",
    "            preds = [1 if x > 0.5 else 0 for x in outputs]\n",
    "            train_preds.extend(preds)\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            labels.extend(targets)\n",
    "        \n",
    "        train_loss /= len(dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Epoch: \", epoch+1, \"Loss: \", train_loss)\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:32:08.193458Z",
     "iopub.status.busy": "2024-07-29T06:32:08.193013Z",
     "iopub.status.idle": "2024-07-29T07:21:00.857020Z",
     "shell.execute_reply": "2024-07-29T07:21:00.856236Z",
     "shell.execute_reply.started": "2024-07-29T06:32:08.193430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  1.6703441132051722\n",
      "Epoch:  2 Loss:  0.9770192268287687\n",
      "Epoch:  3 Loss:  0.5859222202866192\n",
      "Epoch:  4 Loss:  0.35667586990830297\n",
      "Epoch:  5 Loss:  0.22294173784611\n",
      "Epoch:  6 Loss:  0.14377712813414562\n",
      "Epoch:  7 Loss:  0.09533475181223858\n",
      "Epoch:  8 Loss:  0.06442792588742566\n",
      "Epoch:  9 Loss:  0.0441177036195167\n",
      "Epoch:  10 Loss:  0.030405725501183038\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_losses = train(model, criterion, optimizer, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:00.860651Z",
     "iopub.status.busy": "2024-07-29T07:21:00.860272Z",
     "iopub.status.idle": "2024-07-29T07:21:00.864773Z",
     "shell.execute_reply": "2024-07-29T07:21:00.864238Z",
     "shell.execute_reply.started": "2024-07-29T07:21:00.860617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot train accuracy\n",
    "def plot_train_losses(train_losses):\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Train Loss')\n",
    "    plt.title('Train Loss vs Epochs')\n",
    "    plt.savefig('./plots/cbow_train_losses_wiki.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:00.865761Z",
     "iopub.status.busy": "2024-07-29T07:21:00.865538Z",
     "iopub.status.idle": "2024-07-29T07:21:01.142256Z",
     "shell.execute_reply": "2024-07-29T07:21:01.141690Z",
     "shell.execute_reply.started": "2024-07-29T07:21:00.865737Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call function to plot train accuracy\n",
    "plot_train_losses(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.143635Z",
     "iopub.status.busy": "2024-07-29T07:21:01.143106Z",
     "iopub.status.idle": "2024-07-29T07:21:01.197471Z",
     "shell.execute_reply": "2024-07-29T07:21:01.196833Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.143607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), './partA_pth/cbow_25k_100_001.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.198617Z",
     "iopub.status.busy": "2024-07-29T07:21:01.198374Z",
     "iopub.status.idle": "2024-07-29T07:21:01.273252Z",
     "shell.execute_reply": "2024-07-29T07:21:01.272722Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.198590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embeddings): Embedding(30214, 100)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = CBOW(vocab_size, embedding_dim)\n",
    "model.load_state_dict(torch.load('./partA_pth/cbow_25k_100_001.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with Simlex-999 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.274549Z",
     "iopub.status.busy": "2024-07-29T07:21:01.274110Z",
     "iopub.status.idle": "2024-07-29T07:21:01.289444Z",
     "shell.execute_reply": "2024-07-29T07:21:01.288892Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.274521Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
      "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
      "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
      "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
      "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
      "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
      "\n",
      "   SimAssoc333  SD(SimLex)  \n",
      "0            1        0.41  \n",
      "1            1        0.67  \n",
      "2            1        1.19  \n",
      "3            1        2.18  \n",
      "4            1        0.93  \n"
     ]
    }
   ],
   "source": [
    "# Load into dataframe\n",
    "df = pd.read_csv('../SimLex-999/SimLex-999.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.290612Z",
     "iopub.status.busy": "2024-07-29T07:21:01.290219Z",
     "iopub.status.idle": "2024-07-29T07:21:01.293672Z",
     "shell.execute_reply": "2024-07-29T07:21:01.293145Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.290585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart\n"
     ]
    }
   ],
   "source": [
    "# Print 2nd row word1\n",
    "print(df['word1'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.294795Z",
     "iopub.status.busy": "2024-07-29T07:21:01.294405Z",
     "iopub.status.idle": "2024-07-29T07:21:01.309820Z",
     "shell.execute_reply": "2024-07-29T07:21:01.309300Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.294769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "(100,)\n",
      "[-1.5223694  -0.65027565 -1.4857079   1.3918842   1.8701047   0.7215483\n",
      " -0.6215084   1.6533986  -1.1424847   0.3306601  -0.43718126  0.14082624\n",
      " -2.4336784  -0.19068076 -0.81786454  2.2453246  -1.651325   -0.40267983\n",
      " -0.572672    0.5155817  -1.8070221   0.4256793  -0.69953936  1.733409\n",
      "  2.5494952  -2.2094095  -0.06201757  1.527326   -0.1765274   0.5563047\n",
      " -0.55198807 -0.33231288  0.5766455   1.0058451  -1.5552499  -0.4011858\n",
      " -0.8503942  -0.25572988 -0.15025643  0.8423749  -0.11061324  0.25455567\n",
      " -1.4207321  -0.7237979  -0.1651687  -3.1175578  -0.5036788   0.38765582\n",
      "  0.6141823  -2.331313    0.74677265 -1.0180441   0.04572301  1.1243033\n",
      "  1.2277482  -0.84091854  0.39875066 -2.8026376   0.87219507 -0.47247913\n",
      "  0.59060854  0.7631294   0.4590155  -0.9644022   0.49451363 -2.0101974\n",
      "  0.21438755  1.4998289  -0.5564162  -1.084384   -1.9870195  -0.5478069\n",
      " -1.2180061   0.4641117  -1.0830886  -0.48794308  0.31363127  0.71587753\n",
      "  1.6454402   1.4649979  -0.0530734   1.9236692  -1.6619824  -1.6827914\n",
      "  0.701441    0.20183404 -0.0954761   0.9762216   0.681824    1.1400007\n",
      "  0.7779498   0.1654607   1.0797045   0.30914837  1.8263639  -0.8180203\n",
      " -0.10798558  1.1626847  -0.8943584  -0.6883706 ]\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "# Get word embeddings\n",
    "sample_embedding = model.get_word_embedding(df['word1'][1])\n",
    "print(sample_embedding.shape)\n",
    "sample_embedding = sample_embedding.squeeze()\n",
    "print(sample_embedding.shape)\n",
    "print(sample_embedding)\n",
    "sample_embedding = sample_embedding.reshape(1,-1)\n",
    "print(sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.310889Z",
     "iopub.status.busy": "2024-07-29T07:21:01.310556Z",
     "iopub.status.idle": "2024-07-29T07:21:01.319196Z",
     "shell.execute_reply": "2024-07-29T07:21:01.318680Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.310864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check similarity between two words\n",
    "word1 = df['word1'][1]\n",
    "word2 = df['word1'][1]\n",
    "\n",
    "# Use gensim or any other model to get word embeddings\n",
    "w1 = model.get_word_embedding(word1).squeeze()\n",
    "w2 = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "print(type(w1))\n",
    "\n",
    "# Calculate cosine similarity using numpy\n",
    "def unitvec(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "sim = np.dot(unitvec(w1), unitvec(w2))\n",
    "print(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.320271Z",
     "iopub.status.busy": "2024-07-29T07:21:01.319936Z",
     "iopub.status.idle": "2024-07-29T07:21:01.329561Z",
     "shell.execute_reply": "2024-07-29T07:21:01.329049Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.320245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to check if word is in vocab\n",
    "def check_vocab(word):\n",
    "    if word in vocab:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.330622Z",
     "iopub.status.busy": "2024-07-29T07:21:01.330289Z",
     "iopub.status.idle": "2024-07-29T07:21:01.341357Z",
     "shell.execute_reply": "2024-07-29T07:21:01.340848Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.330596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get cosine similarity\n",
    "def cos_similarity(word1_embedding, word2_embedding):\n",
    "    def unitvec(vec):\n",
    "        return vec / np.linalg.norm(vec)\n",
    "\n",
    "    ans = np.dot(unitvec(word1_embedding), unitvec(word2_embedding))\n",
    "    return ans\n",
    "\n",
    "# Function to get Pearson correlation\n",
    "def pearson_correlation(word1_embedding, word2_embedding):\n",
    "    emb1 = np.array(word1_embedding)\n",
    "    emb2 = np.array(word2_embedding)\n",
    "\n",
    "    correlation, _ = pearsonr(emb1, emb2)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.342522Z",
     "iopub.status.busy": "2024-07-29T07:21:01.342100Z",
     "iopub.status.idle": "2024-07-29T07:21:01.354620Z",
     "shell.execute_reply": "2024-07-29T07:21:01.354108Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.342496Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_sim(df, model, lemmatizer, stemmer):\n",
    "    cosine_similarity_scores = []\n",
    "    pearson_correlation_scores = []\n",
    "    simlex_scores = []\n",
    "    not_in_vocab = 0\n",
    "  \n",
    "    for _, row in df.iterrows():\n",
    "        word1 = row['word1']\n",
    "        word2 = row['word2']\n",
    "        form = row['POS']\n",
    "        form = form.lower()\n",
    "       \n",
    "        # Check if word is in vocab\n",
    "        if not check_vocab(word1) or not check_vocab(word2):\n",
    "            not_in_vocab += 1\n",
    "\n",
    "        # Get embeddings\n",
    "        word1_embedding = model.get_word_embedding(word1).squeeze()\n",
    "        word2_embedding = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "        # Get cosine similarity\n",
    "        cosine_similarity_scores.append(cos_similarity(word1_embedding, word2_embedding))\n",
    "        \n",
    "        # Get pearson correlation\n",
    "        pearson_correlation_scores.append(pearson_correlation(word1_embedding, word2_embedding))\n",
    "\n",
    "        # Get simlex score\n",
    "        simlex_scores.append(row['SimLex999'])\n",
    "        \n",
    "    return cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:01.355681Z",
     "iopub.status.busy": "2024-07-29T07:21:01.355346Z",
     "iopub.status.idle": "2024-07-29T07:21:03.191988Z",
     "shell.execute_reply": "2024-07-29T07:21:03.191318Z",
     "shell.execute_reply.started": "2024-07-29T07:21:01.355655Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cosine similarity and pearson correlation scores\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab = test_sim(df, model, lemmatizer, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.193320Z",
     "iopub.status.busy": "2024-07-29T07:21:03.192966Z",
     "iopub.status.idle": "2024-07-29T07:21:03.196971Z",
     "shell.execute_reply": "2024-07-29T07:21:03.196427Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.193291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Check cosine similarity and pearson correlation scores\n",
    "print(type(cosine_similarity_scores))\n",
    "print(type(pearson_correlation_scores))\n",
    "print(type(simlex_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.198240Z",
     "iopub.status.busy": "2024-07-29T07:21:03.197769Z",
     "iopub.status.idle": "2024-07-29T07:21:03.210428Z",
     "shell.execute_reply": "2024-07-29T07:21:03.209914Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.198212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funtcion to get spearman correlation using cosine similarity scores\n",
    "def spearman_correlation(cosine_similarity_scores, simlex_scores):\n",
    "    # Scale cosine similarity scores to 0-10\n",
    "    cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "    cosine_similarity_scores = (1+cosine_similarity_scores)*5\n",
    "    simlex_scores = np.array(simlex_scores)\n",
    "\n",
    "    correlation, _ = spearmanr(cosine_similarity_scores, simlex_scores)\n",
    "    return correlation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.211385Z",
     "iopub.status.busy": "2024-07-29T07:21:03.211155Z",
     "iopub.status.idle": "2024-07-29T07:21:03.224797Z",
     "shell.execute_reply": "2024-07-29T07:21:03.224280Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.211360Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Spearman correlation Sim:  -0.006987339942729407\n"
     ]
    }
   ],
   "source": [
    "# Print the initial spearman correlation\n",
    "spearman_value_sim = spearman_correlation(cosine_similarity_scores, simlex_scores)\n",
    "\n",
    "print(\"Initial Spearman correlation Sim: \", spearman_value_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.226015Z",
     "iopub.status.busy": "2024-07-29T07:21:03.225552Z",
     "iopub.status.idle": "2024-07-29T07:21:03.235667Z",
     "shell.execute_reply": "2024-07-29T07:21:03.235150Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.225990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points not in vocab:  128\n"
     ]
    }
   ],
   "source": [
    "# Print the number of data points not in vocab\n",
    "print(\"Number of data points not in vocab: \", not_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.236630Z",
     "iopub.status.busy": "2024-07-29T07:21:03.236408Z",
     "iopub.status.idle": "2024-07-29T07:21:03.252566Z",
     "shell.execute_reply": "2024-07-29T07:21:03.252043Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.236606Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0    old          new   A       1.58        7.25           0.274194   \n",
      "1  smart  intelligent   A       9.20        7.11          -0.076309   \n",
      "2   hard    difficult   A       8.77        5.94          -0.002455   \n",
      "3  happy     cheerful   A       9.55        5.85          -0.294940   \n",
      "4   hard         easy   A       0.95        5.82          -0.020678   \n",
      "\n",
      "   Pearson Correlation  \n",
      "0             0.272373  \n",
      "1            -0.070417  \n",
      "2             0.001258  \n",
      "3            -0.312593  \n",
      "4            -0.021289  \n"
     ]
    }
   ],
   "source": [
    "# Make a dataframe of cosine similarity scores and pearson correlation scores along with Simlex-999 scores and Assoc(USF)\n",
    "simlex_scores = df['SimLex999']\n",
    "assoc_scores = df['Assoc(USF)']\n",
    "cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "pearson_correlation_scores = np.array(pearson_correlation_scores)\n",
    "simlex_scores = np.array(simlex_scores)\n",
    "assoc_scores = np.array(assoc_scores)\n",
    "# print(cosine_similarity_scores.shape)\n",
    "# print(pearson_correlation_scores.shape)\n",
    "\n",
    "# Make a dataframe along with word1, word2, POS, SimLex-999 scores, Assoc(USF), cosine similarity scores and pearson correlation scores\n",
    "datat = {'word1': df['word1'], 'word2': df['word2'], 'POS': df['POS'], 'SimLex999': simlex_scores, 'Assoc(USF)': assoc_scores, 'Cosine Similarity': cosine_similarity_scores, 'Pearson Correlation': pearson_correlation_scores}\n",
    "ndf = pd.DataFrame(data=datat)\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.253804Z",
     "iopub.status.busy": "2024-07-29T07:21:03.253302Z",
     "iopub.status.idle": "2024-07-29T07:21:03.265950Z",
     "shell.execute_reply": "2024-07-29T07:21:03.265429Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.253778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0       old          new   A       1.58        7.25           0.274194   \n",
      "1     smart  intelligent   A       9.20        7.11          -0.076309   \n",
      "2      hard    difficult   A       8.77        5.94          -0.002455   \n",
      "3     happy     cheerful   A       9.55        5.85          -0.294940   \n",
      "4      hard         easy   A       0.95        5.82          -0.020678   \n",
      "..      ...          ...  ..        ...         ...                ...   \n",
      "994    join      acquire   V       2.85        0.00          -0.089147   \n",
      "995    send       attend   V       1.67        0.00           0.252353   \n",
      "996  gather       attend   V       4.80        0.00           0.010724   \n",
      "997  absorb     withdraw   V       2.97        0.00           0.029040   \n",
      "998  attend       arrive   V       6.08        0.00           0.151032   \n",
      "\n",
      "     Pearson Correlation  \n",
      "0               0.272373  \n",
      "1              -0.070417  \n",
      "2               0.001258  \n",
      "3              -0.312593  \n",
      "4              -0.021289  \n",
      "..                   ...  \n",
      "994            -0.098081  \n",
      "995             0.252322  \n",
      "996             0.010103  \n",
      "997             0.025283  \n",
      "998             0.161534  \n",
      "\n",
      "[999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print df\n",
    "print(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.269561Z",
     "iopub.status.busy": "2024-07-29T07:21:03.269330Z",
     "iopub.status.idle": "2024-07-29T07:21:03.278069Z",
     "shell.execute_reply": "2024-07-29T07:21:03.277562Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.269537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "def create_dataset(df, model):\n",
    "    # Create a list of tuples\n",
    "    emb1 = []\n",
    "    emb2 = []\n",
    "    simlex_scores = []\n",
    "    assoc_scores = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word1 = row['word1']\n",
    "        word2 = row['word2']\n",
    "        emb1.append(torch.tensor(model.get_word_embedding(word1).squeeze()))\n",
    "        emb2.append(torch.tensor(model.get_word_embedding(word2).squeeze()))\n",
    "        simlex_scores.append(row['SimLex999'])\n",
    "        assoc_scores.append(row['Assoc(USF)'])\n",
    "    \n",
    "    # print(emb1[0].shape)\n",
    "    emb1_stack = torch.stack(emb1)\n",
    "    emb2_stack = torch.stack(emb2)\n",
    "    \n",
    "    return emb1_stack, emb2_stack, torch.tensor(simlex_scores, dtype=torch.float), torch.tensor(assoc_scores, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:03.279197Z",
     "iopub.status.busy": "2024-07-29T07:21:03.278781Z",
     "iopub.status.idle": "2024-07-29T07:21:04.007237Z",
     "shell.execute_reply": "2024-07-29T07:21:04.006548Z",
     "shell.execute_reply.started": "2024-07-29T07:21:03.279171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call create_dataset\n",
    "train_df, test_df = train_test_split(ndf, test_size=0.1, random_state=42)\n",
    "train_emb1, train_emb2, train_simlex_scores, train_assoc_scores = create_dataset(train_df, model)\n",
    "test_emb1, test_emb2, test_simlex_scores, test_assoc_scores = create_dataset(test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.008726Z",
     "iopub.status.busy": "2024-07-29T07:21:04.008217Z",
     "iopub.status.idle": "2024-07-29T07:21:04.012071Z",
     "shell.execute_reply": "2024-07-29T07:21:04.011527Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.008695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([899, 100])\n",
      "torch.Size([899])\n"
     ]
    }
   ],
   "source": [
    "# check train_emb1\n",
    "print(train_emb1.shape)\n",
    "print(train_simlex_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.013148Z",
     "iopub.status.busy": "2024-07-29T07:21:04.012857Z",
     "iopub.status.idle": "2024-07-29T07:21:04.025064Z",
     "shell.execute_reply": "2024-07-29T07:21:04.024532Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.013122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creare TensorDataset\n",
    "train_dataset = torch.utils.data.TensorDataset(train_emb1, train_emb2, train_simlex_scores, train_assoc_scores)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_emb1, test_emb2, test_simlex_scores, test_assoc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.026266Z",
     "iopub.status.busy": "2024-07-29T07:21:04.025842Z",
     "iopub.status.idle": "2024-07-29T07:21:04.037773Z",
     "shell.execute_reply": "2024-07-29T07:21:04.037257Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.026240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.038740Z",
     "iopub.status.busy": "2024-07-29T07:21:04.038516Z",
     "iopub.status.idle": "2024-07-29T07:21:04.051032Z",
     "shell.execute_reply": "2024-07-29T07:21:04.050528Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.038716Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class that takes CBOW embeddings, and outputs similarity scores: loss is MSE between predicted similarity scores and actual similarity scores(Simlex-999)\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2*embedding_dim, 50)\n",
    "        self.linear2 = nn.Linear(50, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        # emb1 = emb1.squeeze()\n",
    "        # emb2 = emb2.squeeze()\n",
    "        emb = torch.cat((emb1, emb2), dim=1)\n",
    "\n",
    "        out = self.linear1(emb)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # Project the output between 0 and 10\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out*10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.052000Z",
     "iopub.status.busy": "2024-07-29T07:21:04.051776Z",
     "iopub.status.idle": "2024-07-29T07:21:04.066369Z",
     "shell.execute_reply": "2024-07-29T07:21:04.065807Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.051976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize model\n",
    "lmodel = RegressionModel(embedding_dim).to(device)\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(lmodel.parameters(), lr=learning_rate, weight_decay=0.01) # weight_decay is L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.067352Z",
     "iopub.status.busy": "2024-07-29T07:21:04.067121Z",
     "iopub.status.idle": "2024-07-29T07:21:04.081376Z",
     "shell.execute_reply": "2024-07-29T07:21:04.080798Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.067328Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train model\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for emb1, emb2, simlex_scores, assoc_scores in train_loader:\n",
    "            emb1 = emb1.to(device)\n",
    "            emb2 = emb2.to(device)\n",
    "            simlex_scores = simlex_scores.to(device)\n",
    "            assoc_scores = assoc_scores.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(emb1, emb2)\n",
    "            \n",
    "            simlex_scores = simlex_scores.unsqueeze(1)\n",
    "            # print(outputs[0])\n",
    "            loss = criterion(outputs, simlex_scores)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        print(\"Epoch: {}, Train_Loss: {}\".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:04.082353Z",
     "iopub.status.busy": "2024-07-29T07:21:04.082118Z",
     "iopub.status.idle": "2024-07-29T07:21:11.559175Z",
     "shell.execute_reply": "2024-07-29T07:21:11.558559Z",
     "shell.execute_reply.started": "2024-07-29T07:21:04.082328Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_Loss: 7.3547451413910965\n",
      "Epoch: 2, Train_Loss: 6.796426238401325\n",
      "Epoch: 3, Train_Loss: 6.400849907623749\n",
      "Epoch: 4, Train_Loss: 5.923739814519438\n",
      "Epoch: 5, Train_Loss: 5.512992058120909\n",
      "Epoch: 6, Train_Loss: 5.341512315366554\n",
      "Epoch: 7, Train_Loss: 4.989583537252947\n",
      "Epoch: 8, Train_Loss: 4.597049673578938\n",
      "Epoch: 9, Train_Loss: 4.453263577379776\n",
      "Epoch: 10, Train_Loss: 4.2860122486283725\n",
      "Epoch: 11, Train_Loss: 3.9687024833290407\n",
      "Epoch: 12, Train_Loss: 3.8498627169431234\n",
      "Epoch: 13, Train_Loss: 3.564707440286878\n",
      "Epoch: 14, Train_Loss: 3.5496970758407285\n",
      "Epoch: 15, Train_Loss: 3.3227385417674085\n",
      "Epoch: 16, Train_Loss: 3.2286488192384755\n",
      "Epoch: 17, Train_Loss: 3.0323282390391184\n",
      "Epoch: 18, Train_Loss: 2.9594991820624346\n",
      "Epoch: 19, Train_Loss: 2.800743261348142\n",
      "Epoch: 20, Train_Loss: 2.780055803792605\n",
      "Epoch: 21, Train_Loss: 2.480822551275702\n",
      "Epoch: 22, Train_Loss: 2.5586875128343674\n",
      "Epoch: 23, Train_Loss: 2.4086081469456184\n",
      "Epoch: 24, Train_Loss: 2.3306342345695383\n",
      "Epoch: 25, Train_Loss: 2.345495861091219\n",
      "Epoch: 26, Train_Loss: 2.379710975779816\n",
      "Epoch: 27, Train_Loss: 2.2617505687233264\n",
      "Epoch: 28, Train_Loss: 2.3713146259653035\n",
      "Epoch: 29, Train_Loss: 2.29699703677724\n",
      "Epoch: 30, Train_Loss: 2.099949551938673\n",
      "Epoch: 31, Train_Loss: 2.1476244951568355\n",
      "Epoch: 32, Train_Loss: 1.9071860540368168\n",
      "Epoch: 33, Train_Loss: 1.9422426580987373\n",
      "Epoch: 34, Train_Loss: 1.9921935603522773\n",
      "Epoch: 35, Train_Loss: 1.9679585277537626\n",
      "Epoch: 36, Train_Loss: 1.7837611561174371\n",
      "Epoch: 37, Train_Loss: 1.8044904063664469\n",
      "Epoch: 38, Train_Loss: 1.6959773863544498\n",
      "Epoch: 39, Train_Loss: 1.7074844568803065\n",
      "Epoch: 40, Train_Loss: 1.8071449122546535\n",
      "Epoch: 41, Train_Loss: 1.8618400005147322\n",
      "Epoch: 42, Train_Loss: 1.91263807404879\n",
      "Epoch: 43, Train_Loss: 1.728270737463319\n",
      "Epoch: 44, Train_Loss: 1.5478909652169437\n",
      "Epoch: 45, Train_Loss: 1.8248881986796714\n",
      "Epoch: 46, Train_Loss: 1.6143740117243648\n",
      "Epoch: 47, Train_Loss: 1.474981249405364\n",
      "Epoch: 48, Train_Loss: 1.6494203374657623\n",
      "Epoch: 49, Train_Loss: 1.6241067961915936\n",
      "Epoch: 50, Train_Loss: 1.5538447099035657\n",
      "Epoch: 51, Train_Loss: 1.575446807780162\n",
      "Epoch: 52, Train_Loss: 1.5432386652984253\n",
      "Epoch: 53, Train_Loss: 1.7252668849913486\n",
      "Epoch: 54, Train_Loss: 1.4182362323940767\n",
      "Epoch: 55, Train_Loss: 1.3540109840136183\n",
      "Epoch: 56, Train_Loss: 1.5341970504258604\n",
      "Epoch: 57, Train_Loss: 1.522986295514184\n",
      "Epoch: 58, Train_Loss: 1.5012668372123021\n",
      "Epoch: 59, Train_Loss: 1.4254095389957009\n",
      "Epoch: 60, Train_Loss: 1.3409369654166108\n",
      "Epoch: 61, Train_Loss: 1.4730003129021443\n",
      "Epoch: 62, Train_Loss: 1.3582974989201013\n",
      "Epoch: 63, Train_Loss: 1.5686780821283157\n",
      "Epoch: 64, Train_Loss: 1.4802574063546339\n",
      "Epoch: 65, Train_Loss: 1.3423467365667974\n",
      "Epoch: 66, Train_Loss: 1.2909280496348106\n",
      "Epoch: 67, Train_Loss: 1.4080828504915526\n",
      "Epoch: 68, Train_Loss: 1.2713618227193941\n",
      "Epoch: 69, Train_Loss: 1.3193959663940236\n",
      "Epoch: 70, Train_Loss: 1.2522312836764626\n",
      "Epoch: 71, Train_Loss: 1.4891061489503905\n",
      "Epoch: 72, Train_Loss: 1.4304752380845236\n",
      "Epoch: 73, Train_Loss: 1.3982058723466058\n",
      "Epoch: 74, Train_Loss: 1.4048809510527551\n",
      "Epoch: 75, Train_Loss: 1.1310955978058483\n",
      "Epoch: 76, Train_Loss: 1.271276854566537\n",
      "Epoch: 77, Train_Loss: 1.3339802486832046\n",
      "Epoch: 78, Train_Loss: 1.288857954888286\n",
      "Epoch: 79, Train_Loss: 1.2478463409326797\n",
      "Epoch: 80, Train_Loss: 1.45131345370029\n",
      "Epoch: 81, Train_Loss: 1.2256504981608962\n",
      "Epoch: 82, Train_Loss: 1.2557855785882739\n",
      "Epoch: 83, Train_Loss: 1.3225357859333229\n",
      "Epoch: 84, Train_Loss: 1.3920593745715313\n",
      "Epoch: 85, Train_Loss: 1.31624285992263\n",
      "Epoch: 86, Train_Loss: 1.3551226479624463\n",
      "Epoch: 87, Train_Loss: 1.2919647935060754\n",
      "Epoch: 88, Train_Loss: 1.2895467289666611\n",
      "Epoch: 89, Train_Loss: 1.198088259561241\n",
      "Epoch: 90, Train_Loss: 1.2467330540412933\n",
      "Epoch: 91, Train_Loss: 1.2004413106153555\n",
      "Epoch: 92, Train_Loss: 1.4002344282814487\n",
      "Epoch: 93, Train_Loss: 1.1534535447151792\n",
      "Epoch: 94, Train_Loss: 1.3560735794298653\n",
      "Epoch: 95, Train_Loss: 1.1823916648050585\n",
      "Epoch: 96, Train_Loss: 1.210870720923017\n",
      "Epoch: 97, Train_Loss: 1.1989256608753394\n",
      "Epoch: 98, Train_Loss: 1.1816259967467873\n",
      "Epoch: 99, Train_Loss: 1.1982590753017544\n",
      "Epoch: 100, Train_Loss: 1.2480825726950946\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train(lmodel, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:11.560497Z",
     "iopub.status.busy": "2024-07-29T07:21:11.560157Z",
     "iopub.status.idle": "2024-07-29T07:21:11.567019Z",
     "shell.execute_reply": "2024-07-29T07:21:11.566501Z",
     "shell.execute_reply.started": "2024-07-29T07:21:11.560468Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to test model, Calculate test loss and Spearman correlation\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    true_simlex_scores = []\n",
    "    pred_simlex_scores = []\n",
    "    for emb1, emb2, simlex_scores, assoc_scores in test_loader:\n",
    "        emb1 = emb1.to(device)\n",
    "        emb2 = emb2.to(device)\n",
    "        simlex_scores = simlex_scores.to(device)\n",
    "        assoc_scores = assoc_scores.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(emb1, emb2)\n",
    "        simlex_scores = simlex_scores.unsqueeze(1)\n",
    "        loss = criterion(outputs, simlex_scores)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get true labels and predicted labels\n",
    "        true_simlex_scores.extend(simlex_scores.cpu().detach().numpy().tolist())\n",
    "        pred_simlex_scores.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(\"Test_Loss: {}\".format(test_loss))\n",
    "    # Calculate Spearman correlation\n",
    "    # print(\"True Simlex scores: \", true_simlex_scores)\n",
    "    # print(\"Predicted Simlex scores: \", pred_simlex_scores)\n",
    "\n",
    "    true_simlex_scores = np.array(true_simlex_scores)\n",
    "    pred_simlex_scores = np.array(pred_simlex_scores)\n",
    "    spear = spearmanr(true_simlex_scores, pred_simlex_scores)\n",
    "    print(\"Spearman correlation: {}\".format(spear[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:21:11.568202Z",
     "iopub.status.busy": "2024-07-29T07:21:11.567775Z",
     "iopub.status.idle": "2024-07-29T07:21:11.589577Z",
     "shell.execute_reply": "2024-07-29T07:21:11.589044Z",
     "shell.execute_reply.started": "2024-07-29T07:21:11.568175Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Loss: 8.936299324035645\n",
      "Spearman correlation: 0.06636322453868712\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test(lmodel, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T08:24:35.491403Z",
     "iopub.status.busy": "2024-07-29T08:24:35.490639Z",
     "iopub.status.idle": "2024-07-29T08:24:35.807082Z",
     "shell.execute_reply": "2024-07-29T08:24:35.806077Z",
     "shell.execute_reply.started": "2024-07-29T08:24:35.491359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152dd3aa50844124b75f7c4407efb1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/subprocess.py:941: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "Host key verification failed.\n",
      "Connection closed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a914764ae4434f35bcc874bc36c00f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DownloadWidget(children=(HBox(children=(Password(description='Dropzone Password:', style=DescriptionStyle(desc"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:publish_metrics_list failed due to SigFxClient_client is none...\n"
     ]
    }
   ],
   "source": [
    "%dropzone -p -src 'cbow_wiki.ipynb' -tgt 'cbow_wiki.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
