{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:17.445179Z",
     "iopub.status.busy": "2024-07-27T23:23:17.444423Z",
     "iopub.status.idle": "2024-07-27T23:23:17.454757Z",
     "shell.execute_reply": "2024-07-27T23:23:17.454010Z",
     "shell.execute_reply.started": "2024-07-27T23:23:17.445146Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mImportError\u001b[0m\u001b[0;31m:\u001b[0m cannot import name 'triu' from 'scipy.linalg' (/opt/conda/lib/python3.9/site-packages/scipy/linalg/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# import all necessary packages for CBOW\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from torchtext.vocab import GloVe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import matutils\n",
    "from numpy import dot\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:20.655319Z",
     "iopub.status.busy": "2024-07-27T23:23:20.654859Z",
     "iopub.status.idle": "2024-07-27T23:23:20.659673Z",
     "shell.execute_reply": "2024-07-27T23:23:20.658969Z",
     "shell.execute_reply.started": "2024-07-27T23:23:20.655286Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print device name: get_device_name()\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:22.847574Z",
     "iopub.status.busy": "2024-07-27T23:23:22.847106Z",
     "iopub.status.idle": "2024-07-27T23:23:22.852944Z",
     "shell.execute_reply": "2024-07-27T23:23:22.852370Z",
     "shell.execute_reply.started": "2024-07-27T23:23:22.847540Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from file and store list of sentences where sentences are list of words\n",
    "class MakeSentences():\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.sentences = self.read_file()\n",
    "\n",
    "    def read_file(self):\n",
    "        sentences = []\n",
    "        with open(self.file_name, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                sentences += ([x for x in line.strip().split('.') if x!=''])\n",
    "                i+=1\n",
    "                if i==10000:\n",
    "                    break\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:32.387701Z",
     "iopub.status.busy": "2024-07-27T23:23:32.386962Z",
     "iopub.status.idle": "2024-07-27T23:23:32.413545Z",
     "shell.execute_reply": "2024-07-27T23:23:32.412935Z",
     "shell.execute_reply.started": "2024-07-27T23:23:32.387668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25137\n"
     ]
    }
   ],
   "source": [
    "sentences = MakeSentences('../wikitext-2-raw-v1/wikitext-2-raw/wiki.train.raw').sentences\n",
    "print(len(sentences))\n",
    "# for sentence in sentences:\n",
    "#     print(type(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:23:34.591727Z",
     "iopub.status.busy": "2024-07-27T23:23:34.590982Z",
     "iopub.status.idle": "2024-07-27T23:23:34.595244Z",
     "shell.execute_reply": "2024-07-27T23:23:34.594679Z",
     "shell.execute_reply.started": "2024-07-27T23:23:34.591693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Valkyria Chronicles III =\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:17:52.062769Z",
     "iopub.status.busy": "2024-07-27T15:17:52.062392Z",
     "iopub.status.idle": "2024-07-27T15:17:52.074068Z",
     "shell.execute_reply": "2024-07-27T15:17:52.073506Z",
     "shell.execute_reply.started": "2024-07-27T15:17:52.062738Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class Preprocess():\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def tokenize(self):\n",
    "        # Split sentences into words using regex to handle various punctuation\n",
    "        self.sentences = [re.findall(r'\\b\\w+\\b', sentence.lower()) for sentence in self.sentences]\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.sentences = [[word.lower() for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_stop_words(self):\n",
    "        # Common English stop words; expand as necessary\n",
    "        stop_words = set([\"the\", \"is\", \"at\", \"which\", \"on\", \"and\", \"a\", \"an\"])\n",
    "        self.sentences = [[word for word in sentence if word not in stop_words] for sentence in self.sentences]\n",
    "\n",
    "    def stemmer(self):\n",
    "        # Simple stemming using suffix stripping, can be improved\n",
    "        def simple_stem(word):\n",
    "            suffixes = [\"ing\", \"ly\", \"ed\", \"ious\", \"ies\", \"ive\", \"es\", \"s\", \"ment\"]\n",
    "            for suffix in sorted(suffixes, key=len, reverse=True):\n",
    "                if word.endswith(suffix):\n",
    "                    return word[:-len(suffix)]\n",
    "            return word\n",
    "        self.sentences = [[simple_stem(word) for word in sentence] for sentence in self.sentences]\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        self.sentences = [[word for word in sentence if word.isalpha()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        self.sentences = [[word for word in sentence if not word.isdigit()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_single_letter(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 1] for sentence in self.sentences]\n",
    "\n",
    "    def remove_extra_spaces(self):\n",
    "        self.sentences = [[word for word in sentence if word.strip()] for sentence in self.sentences]\n",
    "\n",
    "    def remove_less_than_3(self):\n",
    "        self.sentences = [[word for word in sentence if len(word) > 2] for sentence in self.sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:17:52.370585Z",
     "iopub.status.busy": "2024-07-27T15:17:52.370112Z",
     "iopub.status.idle": "2024-07-27T15:17:53.121860Z",
     "shell.execute_reply": "2024-07-27T15:17:53.121207Z",
     "shell.execute_reply.started": "2024-07-27T15:17:52.370556Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done\n",
      "25137\n"
     ]
    }
   ],
   "source": [
    "# preprocess\n",
    "preprocess = Preprocess(sentences)\n",
    "preprocess.tokenize()\n",
    "# print(preprocess.sentences)\n",
    "preprocess.lowercase()\n",
    "preprocess.remove_stop_words()\n",
    "# preprocess.stemmer()\n",
    "preprocess.remove_punctuation()\n",
    "preprocess.remove_numbers()\n",
    "preprocess.remove_single_letter()\n",
    "preprocess.remove_extra_spaces()\n",
    "preprocess.remove_less_than_3()\n",
    "\n",
    "print(\"Preprocessing done\")\n",
    "# print(preprocess.sentences)\n",
    "sentences = preprocess.sentences\n",
    "print(len(sentences))\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:17:53.123707Z",
     "iopub.status.busy": "2024-07-27T15:17:53.123370Z",
     "iopub.status.idle": "2024-07-27T15:17:53.284498Z",
     "shell.execute_reply": "2024-07-27T15:17:53.283838Z",
     "shell.execute_reply.started": "2024-07-27T15:17:53.123677Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab:  30214\n",
      "Most common words:  [('was', 5340), ('that', 3928), ('for', 3841), ('with', 3758), ('from', 2329), ('his', 2328), ('were', 1987), ('had', 1638), ('are', 1262), ('her', 1248)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten list of sentences into list of words\n",
    "word_list = list(itertools.chain.from_iterable(sentences))\n",
    "# print(word_list)\n",
    "\n",
    "# Create a vocabulary of words\n",
    "word_freq = Counter(word_list)\n",
    "\n",
    "# Remove words that occur less than 5 times\n",
    "vocab = set(word if word_freq[word] > 0 else '<unk>' for word in word_list)\n",
    "# print(vocab)\n",
    "\n",
    "# Add padding and unknown token to vocab\n",
    "vocab.add('<pad>')\n",
    "vocab.add('<unk>')\n",
    "# Add start and end token to vocab\n",
    "vocab.add('<start>')\n",
    "vocab.add('<end>')\n",
    "\n",
    "# Print length of vocab\n",
    "print(\"Size of vocab: \", len(vocab))\n",
    "\n",
    "# Create word to index and index to word mapping\n",
    "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx:word for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Print most common words\n",
    "print(\"Most common words: \", word_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:17:53.285808Z",
     "iopub.status.busy": "2024-07-27T15:17:53.285530Z",
     "iopub.status.idle": "2024-07-27T15:17:53.289211Z",
     "shell.execute_reply": "2024-07-27T15:17:53.288667Z",
     "shell.execute_reply.started": "2024-07-27T15:17:53.285779Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21018\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(word_to_idx['intelligent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T21:21:28.773385Z",
     "iopub.status.busy": "2024-07-27T21:21:28.772940Z",
     "iopub.status.idle": "2024-07-27T21:21:28.782663Z",
     "shell.execute_reply": "2024-07-27T21:21:28.782088Z",
     "shell.execute_reply.started": "2024-07-27T21:21:28.773353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define constants\n",
    "window_size = 2\n",
    "sliding_window = 2 * window_size + 1\n",
    "num_neg_samples = 5\n",
    "\n",
    "# sentences = [sentences[0]]\n",
    "# print(sentences)\n",
    "\n",
    "def get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_sample):\n",
    "    X = []\n",
    "    y = [] \n",
    "    for sentence in sentences:\n",
    "        # add start and end token to sentence\n",
    "        sentence = ['<start>'] + sentence + ['<end>']\n",
    "        for i in range(len(sentence)):\n",
    "            target_word = sentence[i]\n",
    "            # print(\"target word: \", target_word)\n",
    "            context_words = []\n",
    "            temp1 = max(0,i - window_size)\n",
    "            temp2 = min(len(sentence)-1,i + window_size + 1)\n",
    "            # print(\"temp1: \", temp1)\n",
    "            # print(\"temp2: \", temp2)\n",
    "            for j in range(max(0,i - window_size),min(len(sentence)-1,i + window_size)+1):\n",
    "                if j != i:\n",
    "                    # print(sentence[j])\n",
    "                    context_words.append(sentence[j])\n",
    "                # print(\"context words: \", context_words)\n",
    "\n",
    "            \n",
    "            # pad context words if length is less than sliding window\n",
    "            if len(context_words) < sliding_window:\n",
    "                context_words += ['<pad>'] * (sliding_window - len(context_words)-1)\n",
    "            \n",
    "            context_words.append(target_word)\n",
    "            # print(\"length of context words: \", len(context_words))\n",
    "\n",
    "            # get positive samples \n",
    "            positive_samples = [word_to_idx[word] if word in vocab else word_to_idx['<unk>'] for word in context_words]\n",
    "            # print(\"lenght of positive samples: \", len(positive_samples))\n",
    "            \n",
    "            X.append(positive_samples)\n",
    "            y.append(1)\n",
    "\n",
    "\n",
    "            # get negative samples\n",
    "            for _ in range(num_neg_samples):\n",
    "                negative_samples = positive_samples[:-1]  # Start with the same context\n",
    "                neg_sample = random.choice(list(vocab))\n",
    "                while neg_sample in context_words:  # Ensure the negative sample is not in the context\n",
    "                    neg_sample = random.choice(list(vocab))\n",
    "                \n",
    "                negative_samples.append(word_to_idx[neg_sample])  # Add a random negative sample\n",
    "                X.append(negative_samples)\n",
    "                y.append(0)\n",
    "                \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T21:21:34.261122Z",
     "iopub.status.busy": "2024-07-27T21:21:34.260393Z",
     "iopub.status.idle": "2024-07-27T21:46:06.399094Z",
     "shell.execute_reply": "2024-07-27T21:46:06.398294Z",
     "shell.execute_reply.started": "2024-07-27T21:21:34.261087Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating samples\n",
      "Samples created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating samples\")\n",
    "X = []\n",
    "y = []\n",
    "X,y = get_samples(sentences, word_to_idx, idx_to_word, window_size, sliding_window, num_neg_samples)\n",
    "print(\"Samples created\")\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:55:50.572126Z",
     "iopub.status.busy": "2024-07-27T22:55:50.571672Z",
     "iopub.status.idle": "2024-07-27T22:56:02.093054Z",
     "shell.execute_reply": "2024-07-27T22:56:02.092330Z",
     "shell.execute_reply.started": "2024-07-27T22:55:50.572093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "data = list(zip(X,y))\n",
    "random.shuffle(data)\n",
    "X,y = zip(*data)\n",
    "\n",
    "# Turn into numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:56:02.094695Z",
     "iopub.status.busy": "2024-07-27T22:56:02.094335Z",
     "iopub.status.idle": "2024-07-27T22:56:02.304549Z",
     "shell.execute_reply": "2024-07-27T22:56:02.303861Z",
     "shell.execute_reply.started": "2024-07-27T22:56:02.094665Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save X and y\n",
    "np.save('./datasets/wiki_X_25k.npy', X)\n",
    "np.save('./datasets/wiki_y_25k.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T15:23:35.280333Z",
     "iopub.status.busy": "2024-07-27T15:23:35.280053Z",
     "iopub.status.idle": "2024-07-27T15:23:35.376286Z",
     "shell.execute_reply": "2024-07-27T15:23:35.375661Z",
     "shell.execute_reply.started": "2024-07-27T15:23:35.280303Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load X and y\n",
    "X = np.load('./datasets/wiki_X_25k.npy')\n",
    "y = np.load('./datasets/wiki_y_25k.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:56:08.913500Z",
     "iopub.status.busy": "2024-07-27T22:56:08.912727Z",
     "iopub.status.idle": "2024-07-27T22:56:08.921089Z",
     "shell.execute_reply": "2024-07-27T22:56:08.920514Z",
     "shell.execute_reply.started": "2024-07-27T22:56:08.913466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the forward pass for CBOW\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # self.embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # extract context and target from x\n",
    "        context = x[:, :-1]\n",
    "        target = x[:, -1]\n",
    "\n",
    "        context_embedding = self.embeddings(context)\n",
    "        context_embedding = torch.mean(context_embedding, dim=1)\n",
    "        target_embedding = self.embeddings(target)\n",
    "\n",
    "        # take dot product of context embedding and target embedding\n",
    "        score = torch.sum(context_embedding * target_embedding, dim=1)\n",
    "        return F.sigmoid(score)\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        out = self.embeddings.weight.data\n",
    "        return out.cpu().numpy()\n",
    "    \n",
    "    def get_word_embedding(self, word):\n",
    "        # If word is not in vocab, return unk\n",
    "        if word not in word_to_idx:\n",
    "            word = '<unk>'\n",
    "        word_tensor = torch.LongTensor([word_to_idx[word]])\n",
    "        word_tensor = word_tensor.to(next(self.parameters()).device)\n",
    "        out = self.embeddings(word_tensor).data\n",
    "        return out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:56:11.072860Z",
     "iopub.status.busy": "2024-07-27T22:56:11.072126Z",
     "iopub.status.idle": "2024-07-27T22:56:11.109835Z",
     "shell.execute_reply": "2024-07-27T22:56:11.109192Z",
     "shell.execute_reply.started": "2024-07-27T22:56:11.072826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Create model, loss function and optimizer\n",
    "model = CBOW(vocab_size, embedding_dim)\n",
    "model.to(device)\n",
    "# Cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define dataloader\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(X).long(), torch.from_numpy(y).float())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:56:12.826527Z",
     "iopub.status.busy": "2024-07-27T22:56:12.826063Z",
     "iopub.status.idle": "2024-07-27T22:56:13.042108Z",
     "shell.execute_reply": "2024-07-27T22:56:13.041469Z",
     "shell.execute_reply.started": "2024-07-27T22:56:12.826492Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28437, 17253, 12515, 20086, 29746],\n",
      "        [14359, 27241,  1083, 29134, 28787],\n",
      "        [23778, 19936, 14158,  8998, 25219],\n",
      "        [27187,  7654,  8554,  8554, 21163],\n",
      "        [28296, 17837,  7983, 28664,  7343],\n",
      "        [17669,  3672, 22943, 28460, 13725],\n",
      "        [ 4324,  6850,  9511, 14158, 22129],\n",
      "        [23612, 17426,  8554,  8554, 29378],\n",
      "        [24159, 12770, 23046, 28634, 12205],\n",
      "        [25610,  9684, 24840, 16840,  6855],\n",
      "        [28550, 17012,  8554,  8554, 25530],\n",
      "        [ 5912, 12111, 12162, 25669, 12076],\n",
      "        [ 3251,  9941,  1954,  3960, 11171],\n",
      "        [ 7109,  4500,  9955, 21716, 22198],\n",
      "        [21209, 25822, 16396, 24350, 26722],\n",
      "        [14975,  8575, 19055, 22943, 20408],\n",
      "        [27491, 21286, 13842,   673,   704],\n",
      "        [12125,  5566, 19528,  6758, 20288],\n",
      "        [ 9910,  1295,  7293,  3646, 27956],\n",
      "        [29953, 11331, 19528, 14330,  2469],\n",
      "        [16380,   723,  8554,  8554,  7654],\n",
      "        [27187, 24926,  3286,  1304, 27506],\n",
      "        [ 8706,  6151, 23940,  7269,  3885],\n",
      "        [27187,  7367, 21704,  8554, 22322],\n",
      "        [27187,  7654,  8554,  8554, 23561],\n",
      "        [28110, 22018,  9910,  4052, 28893],\n",
      "        [ 3655,  5522, 24279,  8831,  2110],\n",
      "        [11253, 21577, 24681, 16669, 13717],\n",
      "        [27187, 16840, 14581,  8554,  5866],\n",
      "        [16016, 10118, 12507, 30010,  6244],\n",
      "        [ 3628, 25972, 15913,  3265, 20229],\n",
      "        [18377, 19046,  8554,  8554,  7654],\n",
      "        [12507, 13142, 12575,  7109, 11242],\n",
      "        [17619, 22002, 28836, 12309, 30093],\n",
      "        [24071, 25190, 21577, 17820, 28753],\n",
      "        [27187,  6344,  4849, 23957, 17325],\n",
      "        [ 3249,  8076,   358, 11501, 17287],\n",
      "        [ 1144, 14827,  6595, 29308, 21368],\n",
      "        [ 1762, 26334,  8554,  8554, 26047],\n",
      "        [29864, 29015,   824, 11145, 13142],\n",
      "        [27141,  4213,  9482,  7654,  7572],\n",
      "        [ 5905,  6405, 25783, 12488,  6521],\n",
      "        [ 7171,  7261,   254, 11524,  8798],\n",
      "        [27187,  8255,   826, 11266, 28260],\n",
      "        [ 4983, 14710, 21275,  6907, 29089],\n",
      "        [29963,   826,  7467, 19401,  4874],\n",
      "        [19806, 17982, 12759,  7803,  7678],\n",
      "        [21035, 20253,  6907,  8042,  2160],\n",
      "        [22359,  5153,  8554,  8554, 20475],\n",
      "        [29637,  9181,  7654,  8554, 24953],\n",
      "        [  482,  7983, 27054, 18452,  1876],\n",
      "        [17590, 19146, 23063,   945, 26233],\n",
      "        [27187,  9223,  7654,  8554, 20055],\n",
      "        [ 8255, 11793,  8554,  8554, 13863],\n",
      "        [22078, 28826, 21704,  5975,  3974],\n",
      "        [23778,  1818, 23922, 14897,  9606],\n",
      "        [17428, 29058,  9507, 21863,  6995],\n",
      "        [28373, 11524, 21730, 17776, 19286],\n",
      "        [14219,  6627,  7654,  8554,  9121],\n",
      "        [14526, 13074,  8554,  8554, 27187],\n",
      "        [22153,  6528, 18076, 15352, 26304],\n",
      "        [ 7179,  4349,  8593, 16323, 27673],\n",
      "        [27187, 24412, 13939,  8554,  7102],\n",
      "        [27187, 22861, 16052,  8554,  8852],\n",
      "        [27187, 25351, 24631, 14881,  9089],\n",
      "        [27187,  4224,   945,   525,  6880],\n",
      "        [18382, 21578,  5361, 29244, 22090],\n",
      "        [ 6619, 13302, 30149,  5059, 24233],\n",
      "        [ 6456, 15146,  8554,  8554,  1512],\n",
      "        [10220, 23304, 13074, 17979,  9910],\n",
      "        [11492, 27953,  8554,  8554,  1159],\n",
      "        [14814, 24361,  8554,  8554, 20855],\n",
      "        [21014, 13218,  6319, 13218,  6811],\n",
      "        [ 8548, 21545,  3891,  4519,  7269],\n",
      "        [25430, 28460,  1252, 20838, 28543],\n",
      "        [ 2049, 25537, 24974,  6595, 18439],\n",
      "        [27427, 25816, 20808, 27258, 17465],\n",
      "        [11319, 13914,  8554,  8554,  7595],\n",
      "        [10654, 22094, 21577,  6086, 30102],\n",
      "        [  891, 23940, 24773, 27940,  7405],\n",
      "        [22614, 19257,  8554,  8554, 10853],\n",
      "        [21577, 10619, 14898, 12507, 28031],\n",
      "        [27187,  4132, 12155,  8554, 22887],\n",
      "        [ 7467, 23724, 28826, 15526, 12503],\n",
      "        [ 4580, 25042,  8554,  8554, 27187],\n",
      "        [26199, 21704, 29811, 25617, 12598],\n",
      "        [ 7654,  8554,  8554,  8554, 13228],\n",
      "        [  826, 10887, 24926, 12478, 13588],\n",
      "        [12507, 27019, 24458,  6595, 26175],\n",
      "        [27187,  1086, 18244,  8554,  4505],\n",
      "        [13873, 11072, 15913, 11007,  4500],\n",
      "        [28826, 17675, 29678, 11641, 28657],\n",
      "        [29646, 28577,   308, 17622, 12213],\n",
      "        [19605, 21286, 16333, 28105,  9690],\n",
      "        [29537, 21730,  8554,  8554, 27187],\n",
      "        [ 3056, 10740,  8554,  8554, 11357],\n",
      "        [28710, 16160,  8554,  8554,  3225],\n",
      "        [27187, 20566,  8554,  8554,  7654],\n",
      "        [ 5147, 12611, 23632,  7284, 27184],\n",
      "        [27187, 16451, 24982, 10347, 14986],\n",
      "        [27187,  4389, 11928, 29398,  4343],\n",
      "        [ 8255,  8575, 29934,  6511, 12838],\n",
      "        [15026,  4976, 25169,  9104, 21157],\n",
      "        [ 7654,  8554,  8554,  8554, 27187],\n",
      "        [ 9467,  8766, 16339, 29201, 12024],\n",
      "        [22031, 18975, 15681,  7654,  5652],\n",
      "        [15818,  8757,  8554,  8554, 12283],\n",
      "        [ 3960,  8485,  7160,  7654, 10718],\n",
      "        [ 8237,  6491, 18032, 12575,  5064],\n",
      "        [25702, 27210, 14415,  7654,  5088],\n",
      "        [28180,   322, 23781, 23000,  2257],\n",
      "        [ 5276, 22153,  4324, 24429, 20289],\n",
      "        [ 4118, 19365,  9611, 26334, 22938],\n",
      "        [14043, 12230,  7654,  8554, 17810],\n",
      "        [29194,  8255, 22128, 27243, 10857],\n",
      "        [19921,  5609, 25006, 10539, 19539],\n",
      "        [ 6382, 18719,  8554,  8554,  4926],\n",
      "        [27878,  8255,  6591,  1705, 17125],\n",
      "        [12507, 19528, 22510, 12694,  1795],\n",
      "        [22489, 18315,  8554,  8554, 16678],\n",
      "        [27187, 26594,  8310,  8554, 14417],\n",
      "        [ 7137,  2990, 28634, 18658, 25372],\n",
      "        [ 6564, 12684,  6071, 25652,  5736],\n",
      "        [29514, 25773,  7654,  8554, 25965],\n",
      "        [29472, 20585, 11287,  4148, 22130],\n",
      "        [21381,  7002, 18313, 26058, 29424],\n",
      "        [14266, 16300,   786, 23310,  5779],\n",
      "        [ 1436, 12046,  8554,  8554,  8327]])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Check dataset\n",
    "for i, (inputs, targets) in enumerate(dataloader):\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:56:18.674506Z",
     "iopub.status.busy": "2024-07-27T22:56:18.674045Z",
     "iopub.status.idle": "2024-07-27T22:56:18.681185Z",
     "shell.execute_reply": "2024-07-27T22:56:18.680613Z",
     "shell.execute_reply.started": "2024-07-27T22:56:18.674472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train CBOW model\n",
    "def train(model, criterion, optimizer, dataloader, epochs):\n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        labels = []\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # get predictions\n",
    "            preds = [1 if x > 0.5 else 0 for x in outputs]\n",
    "            train_preds.extend(preds)\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            labels.extend(targets)\n",
    "        \n",
    "        train_loss /= len(dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Epoch: \", epoch+1, \"Loss: \", train_loss)\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T22:56:20.604781Z",
     "iopub.status.busy": "2024-07-27T22:56:20.604039Z",
     "iopub.status.idle": "2024-07-27T23:13:38.657663Z",
     "shell.execute_reply": "2024-07-27T23:13:38.656854Z",
     "shell.execute_reply.started": "2024-07-27T22:56:20.604747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  1.5487368080934487\n",
      "Epoch:  2 Loss:  0.7147097371412823\n",
      "Epoch:  3 Loss:  0.48186506135796714\n",
      "Epoch:  4 Loss:  0.34102914712845983\n",
      "Epoch:  5 Loss:  0.25357255654399274\n",
      "Epoch:  6 Loss:  0.19777458181323537\n",
      "Epoch:  7 Loss:  0.16000686758339525\n",
      "Epoch:  8 Loss:  0.1314980441478241\n",
      "Epoch:  9 Loss:  0.10914813846768555\n",
      "Epoch:  10 Loss:  0.09137655042016879\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_losses = train(model, criterion, optimizer, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:23.013400Z",
     "iopub.status.busy": "2024-07-27T23:15:23.012597Z",
     "iopub.status.idle": "2024-07-27T23:15:23.017853Z",
     "shell.execute_reply": "2024-07-27T23:15:23.017266Z",
     "shell.execute_reply.started": "2024-07-27T23:15:23.013362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot train accuracy\n",
    "def plot_train_losses(train_losses):\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Train Loss')\n",
    "    plt.title('Train Loss vs Epochs')\n",
    "    plt.savefig('./plots/cbow_train_losses.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:24.103603Z",
     "iopub.status.busy": "2024-07-27T23:15:24.102873Z",
     "iopub.status.idle": "2024-07-27T23:15:24.338513Z",
     "shell.execute_reply": "2024-07-27T23:15:24.337944Z",
     "shell.execute_reply.started": "2024-07-27T23:15:24.103569Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call function to plot train accuracy\n",
    "plot_train_losses(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:28.341370Z",
     "iopub.status.busy": "2024-07-27T23:15:28.340611Z",
     "iopub.status.idle": "2024-07-27T23:15:28.393170Z",
     "shell.execute_reply": "2024-07-27T23:15:28.392525Z",
     "shell.execute_reply.started": "2024-07-27T23:15:28.341337Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), './partA_pth/cbow_25k_100_001.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:29.145169Z",
     "iopub.status.busy": "2024-07-27T23:15:29.144719Z",
     "iopub.status.idle": "2024-07-27T23:15:29.219871Z",
     "shell.execute_reply": "2024-07-27T23:15:29.219287Z",
     "shell.execute_reply.started": "2024-07-27T23:15:29.145134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embeddings): Embedding(30214, 100)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = CBOW(vocab_size, embedding_dim)\n",
    "model.load_state_dict(torch.load('./partA_pth/cbow_25k_100_001.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with Simlex-999 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:30.942612Z",
     "iopub.status.busy": "2024-07-27T23:15:30.942159Z",
     "iopub.status.idle": "2024-07-27T23:15:30.956535Z",
     "shell.execute_reply": "2024-07-27T23:15:30.955935Z",
     "shell.execute_reply.started": "2024-07-27T23:15:30.942576Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
      "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
      "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
      "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
      "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
      "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
      "\n",
      "   SimAssoc333  SD(SimLex)  \n",
      "0            1        0.41  \n",
      "1            1        0.67  \n",
      "2            1        1.19  \n",
      "3            1        2.18  \n",
      "4            1        0.93  \n"
     ]
    }
   ],
   "source": [
    "# Load into dataframe\n",
    "df = pd.read_csv('../SimLex-999/SimLex-999.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:31.459265Z",
     "iopub.status.busy": "2024-07-27T23:15:31.458717Z",
     "iopub.status.idle": "2024-07-27T23:15:31.462853Z",
     "shell.execute_reply": "2024-07-27T23:15:31.462302Z",
     "shell.execute_reply.started": "2024-07-27T23:15:31.459235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart\n"
     ]
    }
   ],
   "source": [
    "# Print 2nd row word1\n",
    "print(df['word1'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:31.856607Z",
     "iopub.status.busy": "2024-07-27T23:15:31.856031Z",
     "iopub.status.idle": "2024-07-27T23:15:31.862680Z",
     "shell.execute_reply": "2024-07-27T23:15:31.862134Z",
     "shell.execute_reply.started": "2024-07-27T23:15:31.856577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "(100,)\n",
      "[ 1.9412293   0.11605427 -2.2209508   0.5340961   0.7378831   1.9899021\n",
      "  2.254759   -1.0373343   1.1846137  -0.14329128  1.628146    1.2206916\n",
      " -0.8875681   1.1265922   1.8681338   0.23468089  0.94627666  0.63567644\n",
      " -0.20323817 -0.37857583  0.2655662   0.35207102 -0.8308767  -0.33993202\n",
      "  0.638669    1.0608739   0.91731757  0.7358315  -0.741361   -0.9073067\n",
      " -0.696368    0.70298994 -0.26988354 -1.0455412   1.0905441  -2.979014\n",
      "  0.75139123  0.34386507 -0.30365926 -1.4719915   0.20742598  1.1183194\n",
      "  0.36206487 -0.13762552 -0.2471756  -0.00875324  0.34635076  0.2854899\n",
      " -0.37301642 -0.848179   -0.7384633  -0.5456998   1.1673884  -0.15451601\n",
      " -0.7656123  -0.04498933  1.232315   -0.89139265 -1.5616233   0.16665357\n",
      " -0.67014045  2.1286283  -0.23586886 -1.4925405  -0.35967806 -1.9485229\n",
      "  0.5035584   1.2687955  -0.61090946  0.37603247  1.2119037  -1.3263006\n",
      "  0.603825   -0.5725347   0.84702635  1.2913193  -0.6237146  -0.75433886\n",
      "  0.0631416  -0.7076939   0.33291715  0.73713285  0.9379057   0.52029675\n",
      "  1.6935734  -0.90171444 -1.3148531  -1.0026206  -1.3366511  -0.6498557\n",
      " -1.1606629  -1.0882998  -0.17604806  1.0250032   1.2235835  -0.7534956\n",
      " -1.7329717  -0.01379028  2.336298    1.2934223 ]\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "# Get word embeddings\n",
    "sample_embedding = model.get_word_embedding(df['word1'][1])\n",
    "print(sample_embedding.shape)\n",
    "sample_embedding = sample_embedding.squeeze()\n",
    "print(sample_embedding.shape)\n",
    "print(sample_embedding)\n",
    "sample_embedding = sample_embedding.reshape(1,-1)\n",
    "print(sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:32.223525Z",
     "iopub.status.busy": "2024-07-27T23:15:32.223061Z",
     "iopub.status.idle": "2024-07-27T23:15:32.229252Z",
     "shell.execute_reply": "2024-07-27T23:15:32.228720Z",
     "shell.execute_reply.started": "2024-07-27T23:15:32.223496Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check similarity between two words\n",
    "word1 = df['word1'][1]\n",
    "word2 = df['word1'][1]\n",
    "\n",
    "# Use gensim or any other model to get word embeddings\n",
    "w1 = model.get_word_embedding(word1).squeeze()\n",
    "w2 = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "print(type(w1))\n",
    "\n",
    "# Calculate cosine similarity using numpy\n",
    "def unitvec(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "sim = np.dot(unitvec(w1), unitvec(w2))\n",
    "print(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:32.531802Z",
     "iopub.status.busy": "2024-07-27T23:15:32.531118Z",
     "iopub.status.idle": "2024-07-27T23:15:32.534996Z",
     "shell.execute_reply": "2024-07-27T23:15:32.534442Z",
     "shell.execute_reply.started": "2024-07-27T23:15:32.531769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to check if word is in vocab\n",
    "def check_vocab(word):\n",
    "    if word in vocab:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:33.132644Z",
     "iopub.status.busy": "2024-07-27T23:15:33.131941Z",
     "iopub.status.idle": "2024-07-27T23:15:33.137218Z",
     "shell.execute_reply": "2024-07-27T23:15:33.136651Z",
     "shell.execute_reply.started": "2024-07-27T23:15:33.132610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get cosine similarity\n",
    "def cos_similarity(word1_embedding, word2_embedding):\n",
    "    def unitvec(vec):\n",
    "        return vec / np.linalg.norm(vec)\n",
    "\n",
    "    ans = np.dot(unitvec(word1_embedding), unitvec(word2_embedding))\n",
    "    return ans\n",
    "\n",
    "# Function to get Pearson correlation\n",
    "def pearson_correlation(word1_embedding, word2_embedding):\n",
    "    emb1 = np.array(word1_embedding)\n",
    "    emb2 = np.array(word2_embedding)\n",
    "\n",
    "    correlation, _ = pearsonr(emb1, emb2)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:33.462050Z",
     "iopub.status.busy": "2024-07-27T23:15:33.461443Z",
     "iopub.status.idle": "2024-07-27T23:15:33.467822Z",
     "shell.execute_reply": "2024-07-27T23:15:33.467265Z",
     "shell.execute_reply.started": "2024-07-27T23:15:33.462016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_sim(df, model, lemmatizer, stemmer):\n",
    "    cosine_similarity_scores = []\n",
    "    pearson_correlation_scores = []\n",
    "    simlex_scores = []\n",
    "    not_in_vocab = 0\n",
    "  \n",
    "    for _, row in df.iterrows():\n",
    "        word1 = row['word1']\n",
    "        word2 = row['word2']\n",
    "        form = row['POS']\n",
    "        form = form.lower()\n",
    "       \n",
    "        # Check if word is in vocab\n",
    "        if not check_vocab(word1) or not check_vocab(word2):\n",
    "            not_in_vocab += 1\n",
    "\n",
    "        # Get embeddings\n",
    "        word1_embedding = model.get_word_embedding(word1).squeeze()\n",
    "        word2_embedding = model.get_word_embedding(word2).squeeze()\n",
    "\n",
    "        # Get cosine similarity\n",
    "        cosine_similarity_scores.append(cos_similarity(word1_embedding, word2_embedding))\n",
    "        \n",
    "        # Get pearson correlation\n",
    "        pearson_correlation_scores.append(pearson_correlation(word1_embedding, word2_embedding))\n",
    "\n",
    "        # Get simlex score\n",
    "        simlex_scores.append(row['SimLex999'])\n",
    "        \n",
    "    return cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:33.722257Z",
     "iopub.status.busy": "2024-07-27T23:15:33.721649Z",
     "iopub.status.idle": "2024-07-27T23:15:33.725839Z",
     "shell.execute_reply": "2024-07-27T23:15:33.725292Z",
     "shell.execute_reply.started": "2024-07-27T23:15:33.722225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "print(len(cosine_similarity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:34.096468Z",
     "iopub.status.busy": "2024-07-27T23:15:34.096165Z",
     "iopub.status.idle": "2024-07-27T23:15:35.528705Z",
     "shell.execute_reply": "2024-07-27T23:15:35.528020Z",
     "shell.execute_reply.started": "2024-07-27T23:15:34.096438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cosine similarity and pearson correlation scores\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "cosine_similarity_scores, pearson_correlation_scores, simlex_scores, not_in_vocab = test_sim(df, model, lemmatizer, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:35.530381Z",
     "iopub.status.busy": "2024-07-27T23:15:35.529911Z",
     "iopub.status.idle": "2024-07-27T23:15:35.533995Z",
     "shell.execute_reply": "2024-07-27T23:15:35.533460Z",
     "shell.execute_reply.started": "2024-07-27T23:15:35.530349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Check cosine similarity and pearson correlation scores\n",
    "print(type(cosine_similarity_scores))\n",
    "print(type(pearson_correlation_scores))\n",
    "print(type(simlex_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:35.630925Z",
     "iopub.status.busy": "2024-07-27T23:15:35.630563Z",
     "iopub.status.idle": "2024-07-27T23:15:35.634398Z",
     "shell.execute_reply": "2024-07-27T23:15:35.633885Z",
     "shell.execute_reply.started": "2024-07-27T23:15:35.630897Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funtcion to get spearman correlation using cosine similarity scores\n",
    "def spearman_correlation(cosine_similarity_scores, simlex_scores):\n",
    "    # Scale cosine similarity scores to 0-10\n",
    "    cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "    cosine_similarity_scores = (1+cosine_similarity_scores)*5\n",
    "    simlex_scores = np.array(simlex_scores)\n",
    "\n",
    "    correlation, _ = spearmanr(cosine_similarity_scores, simlex_scores)\n",
    "    return correlation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:36.608164Z",
     "iopub.status.busy": "2024-07-27T23:15:36.607499Z",
     "iopub.status.idle": "2024-07-27T23:15:36.614531Z",
     "shell.execute_reply": "2024-07-27T23:15:36.613956Z",
     "shell.execute_reply.started": "2024-07-27T23:15:36.608132Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Spearman correlation Sim:  -0.02789865991001853\n"
     ]
    }
   ],
   "source": [
    "# Print the initial spearman correlation\n",
    "spearman_value_sim = spearman_correlation(cosine_similarity_scores, simlex_scores)\n",
    "\n",
    "print(\"Initial Spearman correlation Sim: \", spearman_value_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:41.072678Z",
     "iopub.status.busy": "2024-07-27T23:15:41.071943Z",
     "iopub.status.idle": "2024-07-27T23:15:41.076080Z",
     "shell.execute_reply": "2024-07-27T23:15:41.075520Z",
     "shell.execute_reply.started": "2024-07-27T23:15:41.072646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points not in vocab:  128\n"
     ]
    }
   ],
   "source": [
    "# Print the number of data points not in vocab\n",
    "print(\"Number of data points not in vocab: \", not_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:42.034568Z",
     "iopub.status.busy": "2024-07-27T23:15:42.034167Z",
     "iopub.status.idle": "2024-07-27T23:15:42.045441Z",
     "shell.execute_reply": "2024-07-27T23:15:42.044874Z",
     "shell.execute_reply.started": "2024-07-27T23:15:42.034537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0    old          new   A       1.58        7.25           0.181259   \n",
      "1  smart  intelligent   A       9.20        7.11          -0.040457   \n",
      "2   hard    difficult   A       8.77        5.94           0.058442   \n",
      "3  happy     cheerful   A       9.55        5.85           0.000313   \n",
      "4   hard         easy   A       0.95        5.82          -0.070251   \n",
      "\n",
      "   Pearson Correlation  \n",
      "0             0.172996  \n",
      "1            -0.041156  \n",
      "2             0.081995  \n",
      "3            -0.012830  \n",
      "4            -0.044441  \n"
     ]
    }
   ],
   "source": [
    "# Make a dataframe of cosine similarity scores and pearson correlation scores along with Simlex-999 scores and Assoc(USF)\n",
    "simlex_scores = df['SimLex999']\n",
    "assoc_scores = df['Assoc(USF)']\n",
    "cosine_similarity_scores = np.array(cosine_similarity_scores)\n",
    "pearson_correlation_scores = np.array(pearson_correlation_scores)\n",
    "simlex_scores = np.array(simlex_scores)\n",
    "assoc_scores = np.array(assoc_scores)\n",
    "# print(cosine_similarity_scores.shape)\n",
    "# print(pearson_correlation_scores.shape)\n",
    "\n",
    "# Make a dataframe along with word1, word2, POS, SimLex-999 scores, Assoc(USF), cosine similarity scores and pearson correlation scores\n",
    "datat = {'word1': df['word1'], 'word2': df['word2'], 'POS': df['POS'], 'SimLex999': simlex_scores, 'Assoc(USF)': assoc_scores, 'Cosine Similarity': cosine_similarity_scores, 'Pearson Correlation': pearson_correlation_scores}\n",
    "ndf = pd.DataFrame(data=datat)\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:43.247180Z",
     "iopub.status.busy": "2024-07-27T23:15:43.246732Z",
     "iopub.status.idle": "2024-07-27T23:15:43.256354Z",
     "shell.execute_reply": "2024-07-27T23:15:43.255780Z",
     "shell.execute_reply.started": "2024-07-27T23:15:43.247145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word1        word2 POS  SimLex999  Assoc(USF)  Cosine Similarity  \\\n",
      "0       old          new   A       1.58        7.25           0.181259   \n",
      "1     smart  intelligent   A       9.20        7.11          -0.040457   \n",
      "2      hard    difficult   A       8.77        5.94           0.058442   \n",
      "3     happy     cheerful   A       9.55        5.85           0.000313   \n",
      "4      hard         easy   A       0.95        5.82          -0.070251   \n",
      "..      ...          ...  ..        ...         ...                ...   \n",
      "994    join      acquire   V       2.85        0.00          -0.156924   \n",
      "995    send       attend   V       1.67        0.00          -0.019999   \n",
      "996  gather       attend   V       4.80        0.00          -0.047546   \n",
      "997  absorb     withdraw   V       2.97        0.00           0.059406   \n",
      "998  attend       arrive   V       6.08        0.00           0.075377   \n",
      "\n",
      "     Pearson Correlation  \n",
      "0               0.172996  \n",
      "1              -0.041156  \n",
      "2               0.081995  \n",
      "3              -0.012830  \n",
      "4              -0.044441  \n",
      "..                   ...  \n",
      "994            -0.172534  \n",
      "995            -0.034910  \n",
      "996            -0.047768  \n",
      "997             0.053159  \n",
      "998             0.080111  \n",
      "\n",
      "[999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print df\n",
    "print(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:44.556075Z",
     "iopub.status.busy": "2024-07-27T23:15:44.555639Z",
     "iopub.status.idle": "2024-07-27T23:15:44.562039Z",
     "shell.execute_reply": "2024-07-27T23:15:44.561479Z",
     "shell.execute_reply.started": "2024-07-27T23:15:44.556042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "def create_dataset(df, model):\n",
    "    # Create a list of tuples\n",
    "    emb1 = []\n",
    "    emb2 = []\n",
    "    simlex_scores = []\n",
    "    assoc_scores = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        word1 = row['word1']\n",
    "        word2 = row['word2']\n",
    "        emb1.append(torch.tensor(model.get_word_embedding(word1).squeeze()))\n",
    "        emb2.append(torch.tensor(model.get_word_embedding(word2).squeeze()))\n",
    "        simlex_scores.append(row['SimLex999'])\n",
    "        assoc_scores.append(row['Assoc(USF)'])\n",
    "    \n",
    "    # print(emb1[0].shape)\n",
    "    emb1_stack = torch.stack(emb1)\n",
    "    emb2_stack = torch.stack(emb2)\n",
    "    \n",
    "    return emb1_stack, emb2_stack, torch.tensor(simlex_scores, dtype=torch.float), torch.tensor(assoc_scores, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:45.457546Z",
     "iopub.status.busy": "2024-07-27T23:15:45.457075Z",
     "iopub.status.idle": "2024-07-27T23:15:45.826848Z",
     "shell.execute_reply": "2024-07-27T23:15:45.826239Z",
     "shell.execute_reply.started": "2024-07-27T23:15:45.457511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call create_dataset\n",
    "train_df, test_df = train_test_split(ndf, test_size=0.1, random_state=42)\n",
    "train_emb1, train_emb2, train_simlex_scores, train_assoc_scores = create_dataset(train_df, model)\n",
    "test_emb1, test_emb2, test_simlex_scores, test_assoc_scores = create_dataset(test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:46.223344Z",
     "iopub.status.busy": "2024-07-27T23:15:46.222762Z",
     "iopub.status.idle": "2024-07-27T23:15:46.226806Z",
     "shell.execute_reply": "2024-07-27T23:15:46.226262Z",
     "shell.execute_reply.started": "2024-07-27T23:15:46.223312Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([899, 100])\n",
      "torch.Size([899])\n"
     ]
    }
   ],
   "source": [
    "# check train_emb1\n",
    "print(train_emb1.shape)\n",
    "print(train_simlex_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:46.894179Z",
     "iopub.status.busy": "2024-07-27T23:15:46.893770Z",
     "iopub.status.idle": "2024-07-27T23:15:46.897963Z",
     "shell.execute_reply": "2024-07-27T23:15:46.897393Z",
     "shell.execute_reply.started": "2024-07-27T23:15:46.894148Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creare TensorDataset\n",
    "train_dataset = torch.utils.data.TensorDataset(train_emb1, train_emb2, train_simlex_scores, train_assoc_scores)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_emb1, test_emb2, test_simlex_scores, test_assoc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:47.477090Z",
     "iopub.status.busy": "2024-07-27T23:15:47.476658Z",
     "iopub.status.idle": "2024-07-27T23:15:47.481570Z",
     "shell.execute_reply": "2024-07-27T23:15:47.480985Z",
     "shell.execute_reply.started": "2024-07-27T23:15:47.477057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:48.030620Z",
     "iopub.status.busy": "2024-07-27T23:15:48.030046Z",
     "iopub.status.idle": "2024-07-27T23:15:48.036440Z",
     "shell.execute_reply": "2024-07-27T23:15:48.035879Z",
     "shell.execute_reply.started": "2024-07-27T23:15:48.030589Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class that takes CBOW embeddings, and outputs similarity scores: loss is MSE between predicted similarity scores and actual similarity scores(Simlex-999)\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2*embedding_dim, 50)\n",
    "        self.linear2 = nn.Linear(50, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        # emb1 = emb1.squeeze()\n",
    "        # emb2 = emb2.squeeze()\n",
    "        emb = torch.cat((emb1, emb2), dim=1)\n",
    "\n",
    "        out = self.linear1(emb)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # Project the output between 0 and 10\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out*10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:48.611110Z",
     "iopub.status.busy": "2024-07-27T23:15:48.610663Z",
     "iopub.status.idle": "2024-07-27T23:15:48.616868Z",
     "shell.execute_reply": "2024-07-27T23:15:48.616260Z",
     "shell.execute_reply.started": "2024-07-27T23:15:48.611077Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize model\n",
    "lmodel = RegressionModel(embedding_dim).to(device)\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(lmodel.parameters(), lr=learning_rate, weight_decay=0.01) # weight_decay is L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:49.162724Z",
     "iopub.status.busy": "2024-07-27T23:15:49.162066Z",
     "iopub.status.idle": "2024-07-27T23:15:49.168384Z",
     "shell.execute_reply": "2024-07-27T23:15:49.167814Z",
     "shell.execute_reply.started": "2024-07-27T23:15:49.162691Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train model\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for emb1, emb2, simlex_scores, assoc_scores in train_loader:\n",
    "            emb1 = emb1.to(device)\n",
    "            emb2 = emb2.to(device)\n",
    "            simlex_scores = simlex_scores.to(device)\n",
    "            assoc_scores = assoc_scores.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(emb1, emb2)\n",
    "            \n",
    "            simlex_scores = simlex_scores.unsqueeze(1)\n",
    "            # print(outputs[0])\n",
    "            loss = criterion(outputs, simlex_scores)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        print(\"Epoch: {}, Train_Loss: {}\".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:15:51.424678Z",
     "iopub.status.busy": "2024-07-27T23:15:51.423944Z",
     "iopub.status.idle": "2024-07-27T23:15:57.060656Z",
     "shell.execute_reply": "2024-07-27T23:15:57.060038Z",
     "shell.execute_reply.started": "2024-07-27T23:15:51.424645Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_Loss: 7.448724672712129\n",
      "Epoch: 2, Train_Loss: 6.596330492164802\n",
      "Epoch: 3, Train_Loss: 6.381306215554343\n",
      "Epoch: 4, Train_Loss: 5.762072328843942\n",
      "Epoch: 5, Train_Loss: 5.363976684250992\n",
      "Epoch: 6, Train_Loss: 4.936061874444408\n",
      "Epoch: 7, Train_Loss: 4.641077272351279\n",
      "Epoch: 8, Train_Loss: 4.43932778233275\n",
      "Epoch: 9, Train_Loss: 4.342255323301097\n",
      "Epoch: 10, Train_Loss: 3.801723211975287\n",
      "Epoch: 11, Train_Loss: 3.6849190479712717\n",
      "Epoch: 12, Train_Loss: 3.842996759271475\n",
      "Epoch: 13, Train_Loss: 3.5938975866860305\n",
      "Epoch: 14, Train_Loss: 3.3658795440889846\n",
      "Epoch: 15, Train_Loss: 3.2110970434262063\n",
      "Epoch: 16, Train_Loss: 2.931224421580337\n",
      "Epoch: 17, Train_Loss: 3.049713585428798\n",
      "Epoch: 18, Train_Loss: 2.6821996992227817\n",
      "Epoch: 19, Train_Loss: 2.7326236340691215\n",
      "Epoch: 20, Train_Loss: 2.6618079583305376\n",
      "Epoch: 21, Train_Loss: 2.5213084571678688\n",
      "Epoch: 22, Train_Loss: 2.295337448014333\n",
      "Epoch: 23, Train_Loss: 2.291489930313672\n",
      "Epoch: 24, Train_Loss: 2.2018441527520736\n",
      "Epoch: 25, Train_Loss: 2.264542141760338\n",
      "Epoch: 26, Train_Loss: 2.1538722405216113\n",
      "Epoch: 27, Train_Loss: 2.1485377423015852\n",
      "Epoch: 28, Train_Loss: 2.0573172441571868\n",
      "Epoch: 29, Train_Loss: 2.0098168270048395\n",
      "Epoch: 30, Train_Loss: 1.8424364020641402\n",
      "Epoch: 31, Train_Loss: 2.087226034204904\n",
      "Epoch: 32, Train_Loss: 1.7948945987156322\n",
      "Epoch: 33, Train_Loss: 1.9716233947767994\n",
      "Epoch: 34, Train_Loss: 1.8276323399971757\n",
      "Epoch: 35, Train_Loss: 1.7158584893504467\n",
      "Epoch: 36, Train_Loss: 1.5875371211587685\n",
      "Epoch: 37, Train_Loss: 1.8350890364928467\n",
      "Epoch: 38, Train_Loss: 1.7744861535871284\n",
      "Epoch: 39, Train_Loss: 1.6468408282208862\n",
      "Epoch: 40, Train_Loss: 1.5837265855129028\n",
      "Epoch: 41, Train_Loss: 1.6180503985184893\n",
      "Epoch: 42, Train_Loss: 1.554801490871723\n",
      "Epoch: 43, Train_Loss: 1.5555214911688544\n",
      "Epoch: 44, Train_Loss: 1.5713364092118924\n",
      "Epoch: 45, Train_Loss: 1.4977746469111533\n",
      "Epoch: 46, Train_Loss: 1.6240158322978682\n",
      "Epoch: 47, Train_Loss: 1.6427502455503389\n",
      "Epoch: 48, Train_Loss: 1.6483249103275888\n",
      "Epoch: 49, Train_Loss: 1.5653861618427296\n",
      "Epoch: 50, Train_Loss: 1.5469135575472208\n",
      "Epoch: 51, Train_Loss: 1.574655174979461\n",
      "Epoch: 52, Train_Loss: 1.4017270042899317\n",
      "Epoch: 53, Train_Loss: 1.385939225501038\n",
      "Epoch: 54, Train_Loss: 1.3276710854503688\n",
      "Epoch: 55, Train_Loss: 1.378753013554432\n",
      "Epoch: 56, Train_Loss: 1.2519964023274668\n",
      "Epoch: 57, Train_Loss: 1.3249001340065965\n",
      "Epoch: 58, Train_Loss: 1.333821203640119\n",
      "Epoch: 59, Train_Loss: 1.2743044196302526\n",
      "Epoch: 60, Train_Loss: 1.3060756491389591\n",
      "Epoch: 61, Train_Loss: 1.2684515268184904\n",
      "Epoch: 62, Train_Loss: 1.3024337625728877\n",
      "Epoch: 63, Train_Loss: 1.3623390949191267\n",
      "Epoch: 64, Train_Loss: 1.4155553481922123\n",
      "Epoch: 65, Train_Loss: 1.2637779108133316\n",
      "Epoch: 66, Train_Loss: 1.3875325959011275\n",
      "Epoch: 67, Train_Loss: 1.3195270116338933\n",
      "Epoch: 68, Train_Loss: 1.1777571340922988\n",
      "Epoch: 69, Train_Loss: 1.1622546725421272\n",
      "Epoch: 70, Train_Loss: 1.2181752338250105\n",
      "Epoch: 71, Train_Loss: 1.2537985526769997\n",
      "Epoch: 72, Train_Loss: 1.3128659830807599\n",
      "Epoch: 73, Train_Loss: 1.2200969810674895\n",
      "Epoch: 74, Train_Loss: 1.282930295204946\n",
      "Epoch: 75, Train_Loss: 1.2964023858834899\n",
      "Epoch: 76, Train_Loss: 1.2396684162593765\n",
      "Epoch: 77, Train_Loss: 1.2869184238909883\n",
      "Epoch: 78, Train_Loss: 1.2850414511910773\n",
      "Epoch: 79, Train_Loss: 1.0987369700661735\n",
      "Epoch: 80, Train_Loss: 1.3907617031993242\n",
      "Epoch: 81, Train_Loss: 1.13124949048121\n",
      "Epoch: 82, Train_Loss: 1.212343682609125\n",
      "Epoch: 83, Train_Loss: 1.1938451000932346\n",
      "Epoch: 84, Train_Loss: 1.1262643216289443\n",
      "Epoch: 85, Train_Loss: 1.0538702911283688\n",
      "Epoch: 86, Train_Loss: 1.19732489156362\n",
      "Epoch: 87, Train_Loss: 1.1390986963139311\n",
      "Epoch: 88, Train_Loss: 1.214403080268928\n",
      "Epoch: 89, Train_Loss: 1.2453994273907916\n",
      "Epoch: 90, Train_Loss: 1.162679259529631\n",
      "Epoch: 91, Train_Loss: 1.1602325523225372\n",
      "Epoch: 92, Train_Loss: 1.1131847408630653\n",
      "Epoch: 93, Train_Loss: 1.069203508764225\n",
      "Epoch: 94, Train_Loss: 1.1522246583052653\n",
      "Epoch: 95, Train_Loss: 1.291277710678071\n",
      "Epoch: 96, Train_Loss: 1.1409568890785997\n",
      "Epoch: 97, Train_Loss: 1.102653733974407\n",
      "Epoch: 98, Train_Loss: 1.1609685726578793\n",
      "Epoch: 99, Train_Loss: 1.1903598781550608\n",
      "Epoch: 100, Train_Loss: 1.0879297211119658\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train(lmodel, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:16:00.353379Z",
     "iopub.status.busy": "2024-07-27T23:16:00.352933Z",
     "iopub.status.idle": "2024-07-27T23:16:00.360521Z",
     "shell.execute_reply": "2024-07-27T23:16:00.359943Z",
     "shell.execute_reply.started": "2024-07-27T23:16:00.353348Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to test model, Calculate test loss and Spearman correlation\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    true_simlex_scores = []\n",
    "    pred_simlex_scores = []\n",
    "    for emb1, emb2, simlex_scores, assoc_scores in test_loader:\n",
    "        emb1 = emb1.to(device)\n",
    "        emb2 = emb2.to(device)\n",
    "        simlex_scores = simlex_scores.to(device)\n",
    "        assoc_scores = assoc_scores.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(emb1, emb2)\n",
    "        simlex_scores = simlex_scores.unsqueeze(1)\n",
    "        loss = criterion(outputs, simlex_scores)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get true labels and predicted labels\n",
    "        true_simlex_scores.extend(simlex_scores.cpu().detach().numpy().tolist())\n",
    "        pred_simlex_scores.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(\"Test_Loss: {}\".format(test_loss))\n",
    "    # Calculate Spearman correlation\n",
    "    # print(\"True Simlex scores: \", true_simlex_scores)\n",
    "    # print(\"Predicted Simlex scores: \", pred_simlex_scores)\n",
    "\n",
    "    true_simlex_scores = np.array(true_simlex_scores)\n",
    "    pred_simlex_scores = np.array(pred_simlex_scores)\n",
    "    spear = spearmanr(true_simlex_scores, pred_simlex_scores)\n",
    "    print(\"Spearman correlation: {}\".format(spear[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T23:16:01.713492Z",
     "iopub.status.busy": "2024-07-27T23:16:01.712783Z",
     "iopub.status.idle": "2024-07-27T23:16:01.724831Z",
     "shell.execute_reply": "2024-07-27T23:16:01.724253Z",
     "shell.execute_reply.started": "2024-07-27T23:16:01.713456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Loss: 8.937212109565735\n",
      "Spearman correlation: 0.061790588938860774\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test(lmodel, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
