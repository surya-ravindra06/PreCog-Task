{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1.42M/1.42M [00:02<00:00, 585kB/s]\n",
      "Downloading data: 100%|██████████| 202k/202k [00:00<00:00, 268kB/s]\n",
      "Downloading data: 100%|██████████| 403k/403k [00:00<00:00, 484kB/s]\n",
      "Generating train split: 7004 examples [00:00, 25054.93 examples/s]\n",
      "Generating validation split: 1000 examples [00:00, 268487.01 examples/s]\n",
      "Generating test split: 2000 examples [00:00, 246643.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the PiC/phrase dataset\n",
    "dataset = load_dataset(\"PiC/phrase_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "val_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if every phrase is a substring of the corresponding sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to check if every phrase is a substring of the corresponding sentence\n",
    "def check_substring(dataset):\n",
    "    fidx = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[\"sentence1\"][i].find(dataset[\"phrase1\"][i]) == -1 or dataset[\"sentence2\"][i].find(dataset[\"phrase2\"][i]) == -1:\n",
    "            fidx.append(i)\n",
    "    return fidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for all datasets\n",
    "train_fidx = check_substring(train_dataset)\n",
    "test_fidx = check_substring(test_dataset)\n",
    "val_fidx = check_substring(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_fidx))\n",
    "print(len(test_fidx))\n",
    "print(len(val_fidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the sentences and phrases that are not substrings\n",
    "def print_sentences(dataset, fidx):\n",
    "    for i in fidx:\n",
    "        # Print the sentence and phrase side by side\n",
    "        print(\"Sentence 1: \", dataset[\"sentence1\"][i], \"\\tPhrase 1: \", dataset[\"phrase1\"][i])\n",
    "        print(\"Sentence 2: \", dataset[\"sentence2\"][i], \"\\tPhrase 2: \", dataset[\"phrase2\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:  Around 1906, Menelik became incapacitated and \"Itege\" Taytu Betul became the \"de facto\" power behind the throne. \tPhrase 1:  de facto power\n",
      "Sentence 2:  Around 1906, Menelik became incapacitated and \"Itege\" Taytu Betul became the effective ruler behind the throne. \tPhrase 2:  effective ruler\n",
      "Sentence 1:  The early history of juries supports the recognition of the \"de facto\" power of nullification. \tPhrase 1:  de facto power\n",
      "Sentence 2:  The early history of juries supports the recognition of the actual (though unacknowledged) ability of nullification. \tPhrase 2:  actual (though unacknowledged) ability\n",
      "Sentence 1:  the wharf was designed to allow for double deck boarding on the \"a\" side of the wharf. \tPhrase 1:  a side\n",
      "Sentence 2:  the wharf was designed to allow for double deck boarding on the primary side of the wharf of the wharf. \tPhrase 2:  primary side of the wharf\n",
      "Sentence 1:  the \"a\" side of the 45 was \"don't know where i'm going,\" and the \"b\" side was \"marble eyes.\" \tPhrase 1:  a side\n",
      "Sentence 2:  the main half of an album of the 45 was \"don't know where i'm going,\" and the \"b\" side was \"marble eyes.\" \tPhrase 2:  main half of an album\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "print_sentences(train_dataset, train_fidx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
